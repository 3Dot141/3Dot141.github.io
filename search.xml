<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[serendipity -- 0714]]></title>
    <url>%2Fblogs%2Ff5134600.html</url>
    <content type="text"><![CDATA[定投基金想要从工资之外，通过投资获得收益，必然要学习一些金融学的知识。但是金融业又变化莫测，没有长久的投入精力取学习，很难收获到成长，这个时候，基金就出现了。基金公司可以用你买基金的钱取买卖股票，从而用他们的专业知识去获得收益，从你手中赚取服务费。这是一种最为简单，且收获必然能够跑赢银行利息的投资方式。下面就介绍一下。 基金种类首先了解一下基金的种类。 管理方式按管理方式的不同，可以分为主动管理型基金和被动管理型基金分类的标准：是否进行主动管理。最典型的指数型基金就是被动管理型基金，只拟合指数，并不进行主动管理。分类的意义：投资方法和投资理念不同，是两种完全不同的投资方法。主动管理型基金通过主动管理获取收益。被动管理型基金具有工具属性，通过拟合指数获取市场上涨的平均收益。 结论： 就我的了解，是分为 指数基金 和 增强型指数基金。 投资性质投资股票资产高于80％的为股票型基金，投资债券资产高于80％的为债券型基金，介于两者之间的为混合型基金。 投资区域分类的标准：投资于A股市场的是境内基金，投资于海外市场的是境外基金（QDII基金）。另外，随着陆港通的开通，这两年也出现了可同时投资于A股和H股市场的沪港深基金。严格的来说，沪港深基金也是属于境内基金。分类的意义：QDII基金需使用外汇额度，而且受汇率影响较大。QDII基金可使资产配置多元化，分散单一市场的风险。 投资原则 定投 指数基金 。 并且使用支付宝的 智投 高位少买，低位多买。亏多少买多少；赚多少撤多少。 解释一下就是比如一个星期定投 500 ， 第二个星期你发现，你亏到了 250 ， 那这个星期，你就需要投资 750 ， 把这两周的投资补到 1000； 买什么？ 沪深300指数基金，和上证500指数基金。 三个原则： 走势越贴合大盘越好。比如在挑选沪深300指数基金时，判断的第一个标准就是它是否紧跟沪深300指数，越贴切越好，不要想着基金要跑赢大盘。 发行时间不低于三年。长期运作的股票，有更明确的投资思路；我们也能够通过历史数据判断基金经理的风格和水平，因此更具有参考意义。 费用越低越好。买基金有很多费用，买入要申购费、持有要管理费和托管费、卖出要赎回费，这些费用都是买基金的成本。因此如果同时看中了两支同类型基金，选费用更低的那支。 买卖原则 选基金，通过 晨星网 http://cn.morningstar.com/quickrank/default.aspx 买基金，在 支付宝， 选择智投。 以大盘 3000 为分界线， 回落 10 % 止盈]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mood -- 190224 - 选择困难症]]></title>
    <url>%2Fblogs%2F1adfb541.html</url>
    <content type="text"><![CDATA[选择困难症的解决方法相信很多人都会有选择困难症。这种症的发作症状是，在一大批想要的东西里面琢磨不定，不光想要物美价廉的，光是物美价廉的话，还可以选择。但是，他们不光会满足于这个，他们还会想要能满足他们所有的要求。一个加湿器，不光要静音，还要有追光，还要节能。一个转接头，要能满足自己的心头好，在满足自己要求的情况下，要让这个转接头尽可能的小。不占地方。 这种东西是最令人头疼的。如果没有完全满足的，你就需要不断的查找。心里会有着侥幸，万一下一个有呢。这种不断的怀揣希望，并不断失望的过程是最令人丧失精力的。 我经常会被这个病症烦恼。有时候为了挑一个自己心满意足的东西，会熬夜，甚至一晚上都不睡觉。这种症状让我困扰很久。 我怎么才能解决这个呢？ 我想了想，想了一个适应于我的替代的方法来解决这个问题。 比如，在每次想买东西，但是会不断的比较的时候，从不同的地方去搜索资料。但是每个地方的占用时间需要有一个规范，比如每次最多花多长时间。对于我来说，半个小时是可以接受的。从哪里去找建议呢？去我保存的那些网站看。 放心买 - 知乎 - 有调 - 豆瓣。 那么需要考虑一个最坏的情况了，如果找不到最合适的怎么办，就找一个所有备选里面售后最好的 &gt; 最便宜的。 售后最好是容易修 + 最便宜是即便是有问题也不心疼。 如果这个结果不满意的话，那就果断放弃。然后心里还要给自己一个刺激，为什么自己会琢磨不定，因为自己害怕买到差的，害怕浪费钱。 == 钱不够。 == 自己穷。 所以，自己需要好好的加油，需要学习很多有用的技能来让自己变得更加的有竞争力，从而能够在之后抓住该有的机会。 这是写给自己的解决方法的问题。也希望自己能够完全的摆脱这个问题 == 变有钱。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mood -- 19接续18]]></title>
    <url>%2Fblogs%2F3e5d6152.html</url>
    <content type="text"><![CDATA[起始又是一年起始。18年匆匆而过。有些人还是走丢了。有些事还是没完成。想说些什么。但似乎又不知从何说起。 这一年，自己过的还好吗？身体依旧是不好。工作还可以，身边的人也都挺好的。还遇到了一个自己喜欢的姑娘，虽然之后还是分手了。 恋爱好像自己不适合恋爱。每次恋爱都是以失败告终。而且最长的那个，也不过是 1 年。虽然那个女孩还喜欢自己。但是，自己不能再继续了。 我也希望。自己能够奋不顾身的投入一段恋情当中。陪着这个姑娘从咫尺到天涯。又奈何自己孑然一身，哪里有资本去追求爱情这种飘渺的东西。在一起时开心就好。不在一起。那也祝你安好。 这两天，父上大人帮我找了一个相亲对象。我还挺开心的。竟然没有抵触的情绪。可能真的是不想折腾了吧。 从过年到现在，两件事情对自己的冲击最大。一个是我的堂妹告诉我，其实别看我爸表面上不着急，其实可希望我找到一个女孩子了。另一个就是我的同事说，今年要找到一个女朋友，我问他为什么这么着急。他说，他父亲身体不是很好。我父亲的身体又何尝好呢。从我记事起，我父亲就是一个病秧子。可能，我身体不好，一部分就是遗传的我父亲吧。 虽然我知道，自己如果想要恋爱，还是找得到女朋友的。但是。自己想恋爱吗？ Code至于代码上的进步。。。如果有，那应该是对整个代码的设计上的吧。从一开始的不断的修改 bug, 然后自己开始接受模块，对模块中的一部分进行优化。然后，现在可以往其中加入一些自己的模块。甚至于说重构了一些底层模块。这种进步是显而易见的。除此之外，还有的就是经验上的积累。不过是对代码的熟悉程度，还有的就是对架构的熟悉程度。 但是，总体而言还是不满意的，因为自己想做一个数据工程师，而非单纯的开发工程师。 前两天看的一篇文章中，讲的很有道理。很多能够成功的人，都有一个共通的素质。或者说能力。那就是能够看穿一件事务的本质。 就像我的领路人 ju , 每次我和他交流的时候，他都会说，这个东西，我的理解，他的本质是什么什么。你应该这样去解决。而不是怎么怎么样。这些话有时候，我需要自己去慢慢琢磨，甚至琢磨不透。我想，这是我最应该学习的本领。 友情1.21 - 06：26 分， 冷艇哥的女儿冷诺晨出生了。 艇哥的媳妇叫做朱晓佳。 也是一个温婉如水的女孩子呢。借着去看冷诺晨的机会，我们大学的几个朋友又聚到了一起。说说笑笑，好不热闹。让我感到欣慰的是，大家能够在一起敞开的谈论自己的近况。月薪吖，年终吖，而不是藏着掖着。这种感觉让我知道，你们还是你们，没变。真好。年假的时候，在家里，也匆匆忙忙的见了几个好友。但真的也就是匆匆一面。然后就是各种琐事。一恍神，就是 2019 。我还没有和你们痛快地喝酒聊天。你们和我就各奔东西。原先重逢的喜悦一瞬间就被离别的悲愁搅浑了池水。原先的镜面上的光洁，现在只有涟漪。看不见你们，也看不见自己。 结语所以说啊，人生呢，就是要和自己喜欢的人，做喜欢的事情。不要管太多。不要想太多。不爱了，就分手。累了，就出去走走。年轻人，不要有压力。死后一捧黄土。谁能逃得过。开心一点。嗯，我说的是每天。 今年的目标： Coding upupup, 看完去年屯的书。 找到可以一起吃喝玩乐的你。 存一点点钱。嗯。3万就可以。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java 内置序列化的三种方式]]></title>
    <url>%2Fblogs%2F38ecb4b6.html</url>
    <content type="text"><![CDATA[Java序列化就是把Java对象按照一定的格式存到文件或者磁盘当中，那么Java内置的序列化有几种方式呢？每种方式的相同点和不同点是什么呢？ 序列化的进阶：即三种方式，任何一种方式都可以进行序列化和反序列化 第一种使用默认的序列化机制，即实现Serializable接口即可，不需要实现任何方法。 该接口没有任何方法，只是一个标记而已，告诉Java虚拟机该类可以被序列化了。然后利用ObjectOutputStream进行序列化和用ObjectInputStream进行反序列化。 注意： 该方式下序列化机制会自动保存该对象的成员变量，static成员变量和transient关键字修饰的成员变量不会被序列化保存。 这是最简单的一种方式，因为这种方式让序列化机制看起来很方便（然后，我们在进行对象序列化时，只需要使用ObjectOutputStream和ObjectInputStream的writeObject(object)方法和readObject()方法，就可以把传入的对象参数序列化和反序列化了，其他不用管）。有时候想自己来控制序列化哪些成员，还有如何保存static和transient成员？ 再注意： 该方式下，反序列化时不会调用该对象的构造器，但是会调用父类的构造器，如果父类没有默认构造器则会报错。static字段是类共享的字段，当该类的一个对象被序列化后，这个static变量可能会被另一个对象改变，所以这就决定了静态变量是不能序列化的，但如果再加上final修饰，就可以被序列化了，因为这是一个常量，不会改变。 第二种实现Externalizable接口。 Externalizable 接口是继承自 Serializable 接口的，我们在实现 Externalizable 接口时，必须实现writeExternal(ObjectOutput)和readExternal(ObjectInput)方法，在这两个方法下我们可以手动的进行序列化和反序列化那些需要保存的成员变量。 反序列化时，首先会调用对象的默认构造器（没有则报错，如果默认构造器不是public的也会报错），然后再调用readExternal方法。 这种方式一定要显式的序列化成员变量，使得整个序列化过程是可控制的，可以自己选择将哪些部分序列化。 第三种 实现Serializable接口，在该实现类中再增加writeObject方法和readObject方法。该方式要严格遵循以下两个方法的方法签名： writeObject和readObject 在这两个方法里面需要使用stream.defaultWriteObject()序列化那些非static和非transient修饰的成员变量，static的和transient的变量则用stream.writeObject(object)显式序列化。 在序列化输出的时候，writeObject(object)会检查object参数，如果object拥有自己的writeObject()方法，那么就会使用它自己的writeObject()方法进行序列化。readObject()也采用了类似的步骤进行处理。 如果object参数没有writeObject()方法，在readObject方法中就不能调用stream.readObject()，否则会报错。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Class + Static 代码块]]></title>
    <url>%2Fblogs%2F90ab9288.html</url>
    <content type="text"><![CDATA[Class + Static 代码块Class.forName VS LoadClass区别：LoadClass 不初始化类。Class.forName 初始化类。 tips:只要出现了 xx.Class ， 这个 Class 就已经加入了 JVM 中。 静态代码块什么时候执行的。装载 – 链接 – 初始化 – 实例化。 初始化后 开始执行静态代码块。 对象初始化顺序对象初始化，顺序： 父类静态对象，静态代码块 子类静态对象，静态代码块 父类非静态对象，非静态代码块 父类构造函数 子类非静态对象，非静态代码块 子类构造函数]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异常处理]]></title>
    <url>%2Fblogs%2F28877bf.html</url>
    <content type="text"><![CDATA[异常是否要处理运行时异常是RuntimeException类及其子类的异常，是非受检异常，如NullPointerException、IndexOutOfBoundsException等。由于这类异常要么是系统异常，无法处理，如网络问题；要么是程序逻辑错误，如空指针异常；JVM必须停止运行以改正这种错误，所以运行时异常可以不进行处理（捕获或向上抛出，当然也可以处理），而由JVM自行处理。Java Runtime会自动catch到程序throw的RuntimeException，然后停止线程，打印异常。 非运行时异常是RuntimeException以外的异常，类型上都属于Exception类及其子类，是受检异常。非运行时异常必须进行处理（捕获或向上抛出），如果不处理，程序将出现编译错误。一般情况下，API中写了throws的Exception都不是RuntimeException。 总结即所有的异常都要捕获，受检异常默认捕获，不然不编译通过。非受检异常非逻辑问题外是不可控的。尽量捕获，如果不能捕获，则会出现问题，停止程序。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取本机的 UUID]]></title>
    <url>%2Fblogs%2Fae01c73b.html</url>
    <content type="text"><![CDATA[DMI - 获取本机的 uuid DMI 是英文单词 Desktop Management Interface 的缩写，也就是桌面管理界面，它含有关于系统硬件的配置信息。计算机每次启动时都对 DMI 数据进行校验，如果该数据出错或硬件有所变动，就会对机器进行检测，并把测试的数据写入 BIOS 芯片保存。所以如果我们在 BIOS 设置中禁止了 BIOS 芯片的刷新功能或者在主板使用跳线禁止了 BIOS 芯片的刷新功能，那这台机器的 DMI 数据将不能被更新。如果你更换了硬件配置，那么在进行 WINDOWS 系统时，机器仍旧按老系统的配置进行工作。这样就不能充分发挥新添加硬件的性能，有时还会出现这样或那样的故障。 1/sys/devices/virtual/dmi/id/product_uuid 备用方案 1cat /var/lib/dbus/machine-id]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ProtectionDomain 与 Url 的区别]]></title>
    <url>%2Fblogs%2F7c998ba2.html</url>
    <content type="text"><![CDATA[class.getProtectionDomain()ProtectionDomain 介绍 可以查看运行时某个类文件所在jar的位置和 -verbose 命令相似。 1234567891011121314151617181920212223242526272829private static String getEnvPath() &#123; if (underlying.getIdentity().equals(ProjectConstants.WAR)) &#123; return "/WEB-INF"; &#125; String envPath = WorkContext.getCurrent().getPath(); if (StringUtils.isEmpty(envPath)) &#123; try &#123; URL url = ResourceIOUtils.class.getProtectionDomain().getCodeSource().getLocation(); envPath = URLDecoder.decode(url.getPath(), EncodeConstants.ENCODING_UTF_8); &#125; catch (UnsupportedEncodingException ignored) &#123; &#125; int idx = envPath.indexOf(ProjectConstants.WEBINF_NAME); if (idx &lt; 0) &#123; idx = envPath.indexOf("classes"); &#125; if (idx &lt; 0) &#123; idx = envPath.indexOf("lib"); &#125; if (idx &gt; 0) &#123; envPath = envPath.substring(0, idx + ProjectConstants.WEBINF_NAME.length() + 1); &#125; else &#123; envPath = RepositoryUtils.getParent(envPath); &#125; &#125; return envPath;&#125; 上面这段代码的优点，就是无论什么情况，都能读取到 web-inf 的值。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killPython_字符串相关]]></title>
    <url>%2Fblogs%2F56bb9de.html</url>
    <content type="text"><![CDATA[字符串 API字符串格式化1print("I'm %s. I'm %d year old" % ('Vamei', 99)) &quot;I&#39;m %s. I&#39;m %d year old&quot; 为我们的模板。%s 为第一个格式符，表示一个字符串。%d为第二个格式符，表示一个整数。(&#39;Vamei&#39;, 99)的两个元素 &#39;Vamei&#39; 和 9 为替换 %s和%d 的真实值。 在模板和tuple之间，有一个 % 号分隔，它代表了格式化操作。 12345678910111213%s 字符串 (采用str()的显示)%r 字符串 (采用repr()的显示)%c 单个字符%b 二进制整数%d 十进制整数%i 十进制整数%o 八进制整数%x 十六进制整数%e 指数 (基底写为e)%E 指数 (基底写为E)%f 浮点数%F 浮点数，与上相同%% 字符"%" 判断是否含有中文字符12345678910import sysreload(sys)sys.setdefaultencoding('utf8') def check_contain_chinese(check_str): for ch in check_str.decode('utf-8'): if u'\u4e00' &lt;= ch &lt;= u'\u9fff': return True return False 正则表达式注意， ptn 加入了一个 r 作为正则表达式的标志12ptn = r"r[au]n" # start with "r" means raw stringprint(re.search(ptn, "dog runs to cat")) # &lt;_sre.SRE_Match object; span=(4, 7), match='run'&gt;]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killPython</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Thread Dump]]></title>
    <url>%2Fblogs%2Fe13c32e8.html</url>
    <content type="text"><![CDATA[名词解释 tid - Java-Level Thread Id nid - Native Thread Id 状态dump 文件里，值得关注的线程状态有： 死锁，Deadlock（重点关注） 执行中，Runnable 等待资源，Waiting on condition（重点关注） 等待获取监视器，Waiting on monitor entry（重点关注） 暂停，Suspended 对象等待中，Object.wait() 或 TIMED_WAITING 阻塞，Blocked（重点关注） 停止，Parked 案例综合示范一：Waiting to lock 和 Blocked实例如下： 12345678&quot;RMI TCP Connection(267865)-172.16.5.25&quot; daemon prio=10 tid=0x00007fd508371000 nid=0x55ae waiting for monitor entry [0x00007fd4f8684000] java.lang.Thread.State: BLOCKED (on object monitor)at org.apache.log4j.Category.callAppenders(Category.java:201)- waiting to lock &lt;0x00000000acf4d0c0&gt; (a org.apache.log4j.Logger)at org.apache.log4j.Category.forcedLog(Category.java:388)at org.apache.log4j.Category.log(Category.java:853)at org.apache.commons.logging.impl.Log4JLogger.warn(Log4JLogger.java:234)at com.tuan.core.common.lang.cache.remote.SpyMemcachedClient.get(SpyMemcachedClient.java:110) 1）线程状态是 Blocked，阻塞状态。说明线程等待资源超时！2）“ waiting to lock ”指，线程在等待给这个 0x00000000acf4d0c0 地址上锁（英文可描述为：trying to obtain 0x00000000acf4d0c0 lock）。3）在 dump 日志里查找字符串 0x00000000acf4d0c0，发现有大量线程都在等待给这个地址上锁。如果能在日志里找到谁获得了这个锁（如locked &lt; 0x00000000acf4d0c0 &gt;），就可以顺藤摸瓜了。4）“waiting for monitor entry”说明此线程通过 synchronized(obj) {……} 申请进入了临界区，从而进入了下图1中的“Entry Set”队列，但该 obj 对应的 monitor 被其他线程拥有，所以本线程在 Entry Set 队列中等待。5）第一行里，”RMI TCP Connection(267865)-172.16.5.25”是 Thread Name 。tid指Java Thread id。nid指native线程的id。prio是线程优先级。[0x00007fd4f8684000]是线程栈起始地址。 详解 Deadlock：死锁线程，一般指多个线程调用间，进入相互资源占用，导致一直等待无法释放的情况。 Runnable：一般指该线程正在执行状态中，该线程占用了资源，正在处理某个请求，有可能正在传递SQL到数据库执行，有可能在对某个文件操作，有可能进行数据类型等转换。 Waiting on condition：等待资源，或等待某个条件的发生。具体原因需结合 stacktrace来分析。 如果堆栈信息明确是应用代码，则证明该线程正在等待资源。一般是大量读取某资源，且该资源采用了资源锁的情况下，线程进入等待状态，等待资源的读取。 又或者，正在等待其他线程的执行等。 如果发现有大量的线程都在处在 Wait on condition，从线程 stack看，正等待网络读写，这可能是一个网络瓶颈的征兆。因为网络阻塞导致线程无法执行。 一种情况是网络非常忙，几乎消耗了所有的带宽，仍然有大量数据等待网络读写； 另一种情况也可能是网络空闲，但由于路由等问题，导致包无法正常的到达。 另外一种出现 Wait on condition的常见情况是该线程在 sleep，等待 sleep的时间到了时候，将被唤醒。 Blocked：线程阻塞，是指当前线程执行过程中，所需要的资源长时间等待却一直未能获取到，被容器的线程管理器标识为阻塞状态，可以理解为等待资源超时的线程。 Waiting for monitor entry 和 in Object.wait()： Monitor是 Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者 Class的锁。每一个对象都有，也仅有一个 monitor。从下图1中可以看出，每个 Monitor在某个时刻，只能被一个线程拥有，该线程就是 “Active Thread”，而其它线程都是 “Waiting Thread”，分别在两个队列 “ Entry Set”和 “Wait Set”里面等候。在 “Entry Set”中等待的线程状态是 “Waiting for monitor entry”，而在 “Wait Set”中等待的线程状态是 “in Object.wait()”。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[耦合与内聚。]]></title>
    <url>%2Fblogs%2Fe59253ce.html</url>
    <content type="text"><![CDATA[耦合 VS 内聚耦合耦合是对coupling的中文翻译。而coupling是couple的变形，指a connection (like a clamp or vise) between two things so they move together。 存在一种连接在两事物之间，以至于这两事物相互影响。 在本文中，耦合可以是一个名词——耦合度的同义词，也可以作为形容词——耦合性的同义词。 不少书籍都告诉我们要追求高内聚（High Cohesion）及低耦合（Low Coupling）的软件？高内聚和低耦合可以给我们软件开发人员带来可读性、复用性、可维护性和易变更性。 低耦合代表的是在软件不同级别的概念上只依赖它需要依赖的，从而达到它本身的修改不至于造成其它系统的非必要影响，反之亦然。 事实上，在软件开发过程中，耦合的本质是假设。 在设计软件过程，在业务级别上，对与其交互的业务的假设是什么？ 它需要使用哪些具体技术，可否将这些具体技术隔离出去，以至于我可以低成本的更换实现，也就是减少对具体技术的假设。 在写代码时，方法级别上它是不是对其它方法的处理结果进行假设了？类级别的设计有什么假设？等等。 总的来说，就是找到软件开发过程中每个环节可能的假设，并问：如果这个假设并打破了，系统会受到什么影响？ 以上，是传统意义上的低耦合。 我感觉上面这种概念很难理解。并且在写代码的时候，需要考虑很多的东西。 非常的复杂，可能，对于一个富有经验的老手来说，简单一点，但对于我来说，我很难在自己去编写代码的时候，考虑这么多的内容。 我在写代码的时候更多的是靠以下的概念。 我认为这是低耦合的一种变种。 下面有相关概念的变种。 －－&gt;&gt; 依赖。 依赖 ＋ 正交 ＋ 紧凑 依赖依赖和耦合的最大区别在于，当我们说“A和B耦合”时，在字面含义中，A和B二者平等。然而，正确的模块关系根本不应该平等，而应该是单向依赖才对。所以我们应该说“A依赖B”，这样含义要清楚得多。A依赖B意味着，A模块可以调用B模块暴露的API，但B模块绝不允许调用A模块的API。单向依赖是红线，好的设计一定不会违反这条红线。只要程序员编写模块A时，需要知道模块B的存在，需要知道模块B提供哪些功能，A对B依赖就存在。 正交正交性是指一个模块提供的API中，多个方法之间是否有重复的功能。如果有重复功能，正交性就差。通常，正交性高的模块更稳定，不会因为上层业务变化而被迫修改代码。好的API内部的多个方法之间不应该有任何重复功能，只实现正交的机制。如果感觉拆得太细使用不便，应该在底层API之外包装出一层Helper、Utility组成的胶水层。胶水层调用底层原语API来实现常用模式供上层使用。对于胶水层中的模块，对正交性的要求可以稍低一些。注意上层代码既可以直接调用正交的底层API，又可以调用胶水层的常用模式。 紧凑紧凑性是指一段程序提供的API中，公有方法总数必须很少，每个方法的参数也必须很少。《代码大全》上说一个类应该将参数的类型限制为 7 个。多了，就需要考虑这个类的作用，功能，然后拆分。 通过这三个指标，将一段程序给量化。 正交： 方便程序的复用，并减少对程序本身单一功能的污染 依赖：理解每一段代码的功能与另一端代码功能之间的关系。可以帮助这一段代码的整体逻辑更加的清楚。 紧凑：是为了方便理解这个类的功能。 依赖注入 DI + 控制反转 IOC 控制反转 ： a 依赖 b, 但 a 不控制 b 的创建和销毁。交由第三方控制。 依赖注入 ：a 依赖 b, 必然使用 b 的 instance。使用的方法有三种： 1. 通过 a 的接口传入2. 通过 a 的构造传入3. 通过设置 a 的属性将 b 传入 当时，在面试的时候，就问我这个问题， 这两个名词作用就是减少耦合。 一段生动形象的比喻是这样的。 正常的造一辆车，是先造轮子，然后底盘，然后外壳，发动机，最后建成一辆车。 但是如果轮子换了，上面的底盘，外壳，发动机可能都要改变，因为这整个车都是依赖于底层的轮子建造起来的。 而 DI + IOC 的逻辑是， 先有一辆车，然后传入发动机，发动机传入外壳，外壳传入底盘，底盘传入轮子。、 这样一来，即便轮子换了，只需要改变轮子的形状，样式，然后传入底盘就可以了，完全影响不到上层模块的构建。 这样上层模块（车）就和下层模块（轮子）解耦了。 结语以上就是我理解的耦合，很浅显，还有很多要学习的地方。 并且只有不断的实践才能帮助自己真正理解这个概念。 代码之路，才刚刚启程~~]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《见识》 读书笔记]]></title>
    <url>%2Fblogs%2F3adec6d9.html</url>
    <content type="text"><![CDATA[0. 序言注意你的想法，因为它能决定你的言辞和行动注意你的言辞和行动，因为它能主导你的行为注意你的行为，因为它能变成你的习惯注意你的习惯，因为它能塑造你的性格注意你的性格，因为它能决定你的命运– 撒切尔夫人 1. 商业的本质商业的本质是让人花钱，不是省钱。第一个趋势， 从线上到线下，从实体到虚拟。目的是为了省时间，省钱。 但是，2016年，互联网企业的销售额3800亿美元。 而传统意义上的电信行业有35000亿美元。第二个趋势 从线上回到线下，则是为了花时间，花钱。只有花钱才能拓宽道路。 没有选择的好处。苹果的定位是为了给大家争面子。通过苹果的优秀的品牌推广，苹果是将自己的品牌溢价出一个合理的区间。每次只推出两个产品。选择的余地少，但是往往这两个产品就代表着手机行业的最顶尖的水平。苹果的iphone5c，是为了拓宽商品线，而为了做出的改变。是当年的苹果最便宜的商品。但是，市场效果并不好。在中国更是将“多样”的c 戏称为 “廉价” 的c 。 产品的三个阶段。 革命性发明的出现。 方便使用但价格昂贵。 解决价格问题，普及大众。 未来商业的本质 共享经济： 什么叫共享经济。不是让大家减少消费，而是通过这个概念，让大家增加消费。 跟踪经济: 根据每一个人的生活习惯，量身定做相应的东西，贴合每个人的要求，这样才能成为一个日用品。 合作经济： 原先的互联网＋的概念很是狭隘，准确的来说，应该是＋互联网。现在是一个新的时代，从农业时代，蒸汽时代，电气时代，然后是Pc端的过渡，现在是互联网时代。 众筹经济： 让大家参与进来，不光是参与到这个设计的方面，还要直接问用户，买还是不买。小米的饥饿营销就是这个套路。 2. 创业的n+1对创始人来说， 你应该成为公司的刹车，而不是引擎。 你最主要的工作是招人。 你最大的作用是成为一个信仰，或者说为公司找到一个信仰。也就是确立公司的文化。 确立一个公司的期望最大化函数。以物理学层面上讲，各物质之间有四种基本力，强核力，形成原子核。弱核力保证原子核还要太大。电磁力保证原子核和电子能够形成原子。万有引力保证物质能够形成星球。宇宙通过这几条规则，不断的演化，最后孕育出生命。一个公司的基本规则就是期望最大化函数。谷歌的规则是 engineer &gt; product manager ，所以在公司里 产品经理的权力要小于 工程师。腾讯的则相反是注重用户的体验，所以 腾讯内部 product manager &gt; engineer . 对产品来说，一个好的产品需要注意以下几点。 好产品的目标必须明确 好产品没有绝对的正确答案，只能在当时的情况下寻找最好的解决方法。就像你在做测试的时候，有时候即使发现了bug，也会为了因为优先级原因而让步。对于一个工程师而言，他不能等待条件的成熟，而是要尽可能地利用现有技术解决实际问题。 随着一个问题的解决，还会随之出现新的问题，因此，工程师要和产品经理不断协商，作出取舍。 当目标改变时，要学会舍弃，改变原先的架构，或者直接舍弃这个产品。避免尾大不掉。 对方向来说，为了战胜大公司，除了上面商业的本质不能违反，还要注意以下几点： 大公司已经涉及的领域是很难被打败的，找不到相应的方向前，可以选择那些大公司不愿意干的脏货，累活。因为在人工智能领域时代创业，三类公司会得到大量的机会，一是谷歌，微软，BATJ等平台型公司，拥有大量的人力财力，拥有自己的得天独厚的优势，别人很难撼动，相当于处在很长一段时间的舒适发展期。二是传统电信产业，银行产业等，拥有大量的数据，但不知道如何使用或者商业规模老旧一时无法转型的公司三是掌握新技术的创业公司，拥有技术专长，但没有第一类公司的水平，业务水平也低于第一类公司人综合实力。但是在第一类公司和第二类公司存在利益冲突的情况下，完全可以凭借着这个优势，得到大量的发展机会。 找到那些具有颠覆性的技术。硅谷的企业往往不是技术的创世人，但是他们能够将原来的技术转化为自己的东西。并且他们往往具有的叛逆与执拗支撑着这个技术的不断突破。这样的技术是洋枪洋炮，拥有这样技术的企业将成为新时代的行业领袖。如此这般，你才能将整个时代的推动力化为自己的助推力。你与那些大企业的争斗，将是两个时代的争斗。拥有一个时代力量的新企业，将不断收益于不断发展的技术，只有这样，你才能将原先那些占据着行业魁首的企业打败。 进攻是最好的防守。二战时期德军领袖曼施泰因，发明了闪电战的打法。凭借这种打法，他在德国与苏联的战争中，在德国遭受斯大林格勒战役惨败后，力挽狂澜，带领7万德国军队，大胆奇袭，重创35万苏联军队，歼灭对方52个师。回到现在，谈到技术，专利是离不开的一个话题，经常会在网络上看到哪家公司告哪家公司侵权之类的话题。但是，当一个公司拥有着强劲的势头的时候，他往往不会注意这个东西。在硅谷最富创新的公司在最富创新的时期往往专利数量并不多，无论是facebook,google,apple都是这样。因为专利是用来防守的，一个极富创新力的公司会用极快的速度将技术转化为产品，然后引领行业。但是当一个公司的发展势头放缓的时候，就需要通过专利权减缓竞争对手的势头，保护她的侧翼和后方。 谷歌的创世人– 拉里佩奇的智慧 薪尽火传对公司来说，一个公司想要成为一个百年老店的可能性微乎其微，无论是欧洲的豪门还是日本的企业，他们即便真正让品牌存活下上百年的时间，其背后的掌权人往往也会变了几番。所以做一个公司的理念，应该放宽。要首先认识到公司是很可能死的。要努力寻找下一次机会，开创一个专而精的有活力的公司，生前站在时代浪巅，死后将资产经验传递给下一任，下一代的公司。就比如谷歌。谷歌是做搜索起家，后来拉里佩奇决定成立alphbet 公司，将原先谷歌的业务打包分出去，成立一个子公司交给 皮柴 掌管。 现在，alphbet 的领域涉及医疗（calico) , 风投（google ventures） , 资本（google capital) , 智能家庭（nest) etc.. 但是，拉里佩奇很精髓的一点是，他并没有安排其他人去开创新的业务，而是交给自己这个困难的问题。为什么？因为，基因决定论。只有一个公司的创始人才能深刻知道自己想创办的公司是一家什么样的公司，什么样的文化，什么样的基因。他通过这种一以贯之的文化传播，让这些子公司都鲜明的带着 google 的血液。 通过这种方式来传承一个公司的基因和文化。 “牙刷” 产品将产品做成牙刷，这是打了一个比喻，是因为每家每户每一个人都需要使用牙刷，这是一个习惯。而习惯是一个非常可怕的力量。想要让产品成为牙刷需要： 可靠性和稳定性。 爆款。由于牙刷式产品的功能简单，容易被同类型的产品取代。而人总是有好奇的心理，希望能够多多尝试新的东西。所以要每过一段时间给大家一个惊喜，提醒大家他的存在。这就是可口可乐公司和宝洁公司的产品这么有名，他们还要每年花上百亿美元做广告的原因。再举一个例子，就是英特尔公司。当年英特尔公司 x86 架构的处理器和摩托罗拉的 RISC 架构的处理器竞争。RISC 架构的处理器明明架构更合理确依然失败了。 英特尔的首席执行官 安迪格鲁夫是这么解释的。英特尔公司的处理器 产品线是 18 个月一更新。 而其他公司是 36个月一更新。 36个月 这个过程太长，用户已经慢慢把产品给遗忘了，而18 个月却能不断的刷新用户的记忆。 这就是致胜的原因。这个道理在如今的移动互联网社会也是共通的。app的不断更新，除了弥补之前的问题，推出新的功能，提高用户粘性，还有一部分原因是为了刷存在感。让用户意识到这个app 的存在。这个道理一样可以适用在职场上，每周做一次工作总结，不要多，固定数量的几句话就可以，然后周一早上汇报。每半年到一年，给出一个惊喜的成果。这样是刷存在感，最合适的方式。 寻求商业本质《智能时代》中讲，连接比拥有更重要。对于谷歌来说，就是将有用的信息送达到每一个用户。注意，这里的有用很重要，谷歌使用算法严格控制搜索结果的质量。保证用户看到的信息是客观公正的，权威的。虽然会采用广告，但会与自然搜索的结果严格的区分来，表示自然搜索的结果是不沾染任何商业利益的。这种模式在互联网时代很常见，比如阿里巴巴，所销售的商品都不是自己的，作用只是把商品信息送达用户。但是，当你不能突破原有的水平时，你所奉献的就不是有用的东西。比如必应搜索虽然也是在做相似的事情，但是，谷歌已经做了这件事，微软的必应就违背了“有用”这个原则。]]></content>
      <categories>
        <category>essay</category>
      </categories>
      <tags>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[final 变量的修改与问题]]></title>
    <url>%2Fblogs%2Fce574744.html</url>
    <content type="text"><![CDATA[Final 变量反射修改123456field = Comtest.class.getDeclaredField("value1");field.setAccessible(true);Field modifiersField = Field.class.getDeclaredField("modifiers");modifiersField.setAccessible(true);modifiersField.setInt(field,field.getModifiers()&amp;~Modifier.FINAL);field.set(null, new char[]&#123;'1', '2', '3'&#125;); field.getModifiers()&amp;~Modifier.FINAL 这句话就是去掉final。其实java的访问权限信息啥的都是以2的N次幂来作为表示的，具体都是在java.lang.reflect.Modifier这个类里。getModifiers()&amp;~Modifier.FINAL 具体看下问运算，如果有（111111&amp;000000=000000.）抹去了16这个final标识。 问题int/float/String 等不能使用变量反射修改。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[live_Win_IPv6Setting]]></title>
    <url>%2Fblogs%2Fd482faa4.html</url>
    <content type="text"><![CDATA[1. 开启 ipv4 到 ipv6 的转换将以下代码保存为 .bat 格式，并以管理员方式运行@echo offnetsh interface isatap set state defaultnetsh interface teredo set state defaultnetsh interface teredo set state server=teredo.remlab.netnetsh interface ipv6 set teredo enterpriseclient cmd2. 开启路由的 ipv6 功能netsh int ipv6 add route ::/0 “有效的Teredo接口名称”,成功会提示 “确定” 有效的接口名称查看方法：这里的有效接口就是你的网络适配器的名称。如下图：我是使用的 “ 无线网络连接 ” 。所以我应该在 命令行中输入 ：netsh int ipv6 add route ::/0 &quot;无线网络连接&quot;设置好后，可以通过如下命令查看netsh int ipv6 show route , 效果图如下： 然后就可以登入这个网站进行 ipv6测试 3. Teredo 驱动问题失败的情况我原先这个驱动 Microsoft Teredo Tunneling Adapter 是无法启动的。上面显示一个黄色的图标。 通过以下方式，可以解决。 1. 使用管理员账号打开的命令提示符； 2. 输入netsh并按回车键； 3. 输入int teredo并回车； 4. 输入 set state disabled 并回车； 5. 然后打开设备管理器并卸载&quot; Microsoft Teredo Tunneling Adapter&quot;； 6. 再重新用管理员身份进入命令提示符下； 7. 输入netsh并回车； 8. 输入int ipv6并回车； 9. 输入set teredo client并回车； 10. 打开设备管理器---操作---添加过时硬件。 11. 安装驱动 &quot;Microsoft Teredo Tunneling Adapter&quot; 然后重新使用上面的方式，就可以进行测试。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[面向对象葵花宝典]]></title>
    <url>%2Fblogs%2F325dab97.html</url>
    <content type="text"><![CDATA[概念结构化设计 结构化程序设计的主要特点是抛弃goto语句，采取“自顶向下、逐步细化、模块化”的指导思想 人脑存在人类短期记忆一般一次只能记住5-9个事物，这就是著名的 7+- 2原理 面向过程 面向过程是一种以“过程”作为中心的编程思想，其中过程的含义就是“完成一件事情的步骤 面向对象 更加侧重于对现实世界的模拟 面向过程中有“程序=算法+数据结构”的经典总结， 面向对象也有类似的总结：“程序=对象 + 交互”。其中对象就是具体存在的事物，而交互则是事物之间的相互作用、互动等。 中文“可扩展性”对应英文有两种解释：extensibility 和 scalability，extensibility指系统需求变化后，能够比较容易的扩展以支持新需求；scalability指系统访问压力增加后，能够通过简单的增加更多硬件设备以支撑访问压力，又翻译为“可伸缩性”。 本文的可扩展性是指extensibility。 类类是本，代码是末，只有清晰地掌握了类的概念，才能写出好的代码。 那究竟何为类呢？ 物以类聚人以群分。 类就是一组相似事物的统称。 首先：请看“一组”，思考一下为什么是“一组”，不是“一个”？ 其次：请看“相似”，思考一下为什么是“相似”，不是“相同”？ 最后：请看“统称”，思考一下为什么是“统称”，不是“名称”？ 第一个玄机——“一组”：一组的玄机在于“多个“，单个事物无法成为类。 一个很简单的例子：“人“可以是一类，但“我”就不是一个类（那又是什么呢，请看后文分解？） 第二个玄机——“相似”：相似的玄机在于“比较像，但不完全相同”。 还是“人”这个例子：奥巴马和克林顿都是美国总统，都是人，有很多相似的地方，但他们两个绝对不是完全相同的。 第三个玄机——“统称”：统称的玄机在于“统”，也可以叫做“通称”，统称要能够概括这多个事物。 还是上一个例子：奥巴马和克林顿的统称可以为“人”、“男人”、“总统”，但不会统称为“奥巴马”，因为奥巴马是一个具体的人了。 类的定义玄机我们已经基本解读，看起来已经比较清晰了，但不要高兴太早，还有一个更大的玄机：我们怎么划分类？ 只要有相似点的就是同一类 站在你的观察角度，具有相似点的事物就是同一类！ 对象定义对象为“一个具体的类”，但这是否意味着必须是先有类后有对象呢？ 现实对象：你能看到的物体都可以称为现实对象； 现实类：对现实对象的归纳总结； 软件对象：软件实际运行过程中存在的对象； 软件类：软件设计过程中归纳总结出来的类； 抽象第一个层次：对象 抽象成 类。 例如奥巴马和梅西抽象成“人”，这一层的抽象主要是将“属性类似”的对象抽取成类。 第二个层次（或更高层次）：将 类 抽象成超类 例如人和猪抽象成“动物”，这一层的抽象主要是将“行为类似”的类抽象成父类。 抽象最主要的作用是“划分类别”，而划分类别的主要目的其实还是“隔离关注点，降低复杂度” 封装第一个问题是：我们要封装什么？ 第二个问题是：我们为什么要封装？ 封装数据的主要原因是“保护隐私” 封装方法的主要原因是“隔离复杂度” 继承抽象：是分析和设计过程中的一个动作，一个技巧，通过抽象得出类 继承：是实现过程中的一个动作，基于抽象结果，通过编程语言的特性，完成抽象图的模拟。 多态多态屏蔽了子类对象的差异，使得调用者可以写出通用性的代码，而无需针对每个子类都需要写不同的代码。 完整流程1. 管理流程瀑布模型、螺旋模型、迭代开发、敏捷、RUP 2. 技术流程需求模型 -&gt; 领域模型 -&gt; 设计模型 -&gt; 实现模型 l 需求模型 通过和客户沟通，结合行业经验和知识，明确要求客户的需求。 l 领域模型 基于需求模型，提炼出领域相关的概念，为后面的面向对象设计打下基础。 l 设计模型 以领域模型为基础，综合面向对象的各种设计技巧，完成类的设计。 l 实现模型 以设计模型为基础，将设计模型翻译为具体的语言实现，完成编码。 需求模型需求：对客户来说有价值的事情； 功能：系统为了实现客户价值而提供的能力； 例子 POS机：“买单”是需求，“商品扫描”、“金额汇总”、“收银”等是功能，因为买完单后顾客就能将产品拿走； 汽车：“驾驶”是需求，“发动机”、“刹车”、“加速”等是功能； 打印机：“打印”是需求，“进纸”、“设定”、“与电脑连接”等是功能； 需求分析 518 方法 5：5W，即When、Where、Who、What、Why 1：1H，即How 8：8C，即8个Constraint，包括性能Performance、成本Cost、时间Time、可靠性Reliability、安全性Security、合规性Compliance、技术性Technology、兼容性Compatibility 提取功能点 是动词——提取出来，就成为了系统的功能。 用例 use case NEA 方法 1） 正常处理（Normal）：通过和客户沟通，分析需求的正常流程； 2） 异常处理（Exception）：在正常处理流程的步骤上，分析每一步的各种异常情况和对应的处理； 3） 替代处理（Alternative）：在正常处理流程的步骤上，分析每一步是否有其它替代方法，以及替代方法如何做； 领域模型1）发掘重要的业务领域概念 2）建立业务领域概念之间的关系 总结 ： 找名词、加属性、连关系。 名词 属性 备注 顾客 NA 对于POS机来说，并不需要识别顾客的相关信息，因此在领域模型中，顾客是没有属性的 收银员 国籍、编号 “国籍”由找名词步骤中的“中国人”提炼 商品 条形码、名称、价格 名称和价格并没有在用例中体现，但毫无疑问这是商品最基本的属性 扫描仪 NA 扫描仪是POS机的一个输入设备，POS机不需要识别扫描仪的相关信息，因此在领域模型中，扫描仪也是没有属性的 钱（现金） 数量，币别 从领域分析的角度来讲，“现金”更专业一些 信用卡 卡号 NA 会员卡 会员号、积分、有效期 NA 小票 交易信息、POS机信息、收银员信息 小票的属性在用例中并没有详细体现，但有经验的分析师能够很容易识别出来 买单（交易） 商品列表、日期时间、总额、支付信息 这里的属性看起来和“小票”一样，是因为“小票”本质上是给客户的一个交易记录。这里为了更加符合软件系统的属于习惯，可以将“买单“改为“交易”。 键盘 NA 和扫描仪类似，POS机不需要识别键盘信息 屏幕 NA 设计模型静态模型又可以称为“类模型”，主要关注系统的“静态”结构，描述了系统包含的类， 以及类的名称、职责、属性、方法，类与类之间的关系。 动态模型关注系统的“动态”行为，描述类本身的一些动作或者状态变化，以及类之间如何配合以完成最终的业务功能。只有结合静态模型和动态模型，我们才能够真正的将一个系统描述清楚。 静态模型和动态模型对于后续的编码也具有不同的指导意义。静态模型主要用于指导类的声明，包括类名称，属性名，方法名；而动态模型主要用于指导类的实现，主要就是每个方法内部的具体实现。 类模型问题对象从哪里来？ 什么时候用设计模式？ 如何判断设计是否正确？ 什么样的设计才是优秀的设计？ 第一步（照猫画虎）：领域类映射 — 告诉你类从哪里来 领域模型找名词，用例分析找动词。 第二步（精雕细琢）：应用设计原则和设计模式 —告诉你如何设计“好”类 首字母 英文简写 英文名称 中文名称 说明 S SRP Single Responsibility Principle 单一职责原则 对象应该只具备单一职责 O OCP Open/Close Principle 开放/封闭原则 认为“软件体应该是对于扩展开放的，但是对于修改封闭的”的概念。 L LSP Liskov Substitution Principle Liskov替换原则 认为“程序中的对象应该是可以在不改变程序正确性的前提下被它的子类所替换的”的概念 I ISP Interface Segregation Principle 接口隔离原则 多个特定客户端接口要好于一个宽泛用途的接口 D DIP Dependency Inversion Principle 依赖反转原则 依赖于抽象而不是一个实例 设计原则主要用于指导“类的定义”的设计，而设计模式主要用于指导“类的行为”的设计 第三步（照本宣科）：拆分辅助类 —告诉你如何和你的开发框架结合起来 内聚和耦合内聚关注模块内部的元素结合程度，耦合关注模块之间的依赖程度。 1. 内聚cohesion refers to the degree to which the elements of a module) belong together. （http://en.wikipedia.org/wiki/Cohesion_(computer_science)） cohension 也指 凝聚力。 l 判断团队凝聚力时，我们关注团队成员是否都专注于团队的目标；判断面向对象模块的凝聚力时，我们同样关注元素是否专注于模块的目标，即：模块本身的职责！ l 判断团队凝聚力时，我们还会关注团队成员之间是否互相吸引和帮助；判断面向对象模块凝聚力时，我们同样关注元素间的结合关系； 像 DAO 层，都是依赖于其他模块完成本模块的工作。 2. 耦合 coupling or dependency is the degree to which each program module) relies on each one of the other modules （http://en.wikipedia.org/wiki/Coupling_(computer_science)） 3. 高内聚低耦合低内聚: Person类改变后，虽然这个改动和Coach、Director都没有关系，但Coach和Director类都需要重新编译测试部署 高耦合： 对于高耦合的模块，可能本身并不需要修改(低内聚是每次自己都要修改)，但每次其它模块修改，当前模块都要编译、测试、部署，工作量同样不小。 4. 冲突我们详细来分析一下为什么高内聚和低耦合是冲突的。 对于内聚，在一个类的层面上，一个类只有一个方法，这个模块内部内聚性很高。但是在这个类同一层的抽象上，这个模块（以类为模块）的需要大量依赖其他的模块。这是一个高内聚高耦合的模块。 同理，对于耦合来说，最弱的耦合是一个类将所有的函数都包含了，这样类完全不依赖其它类，耦合性是最低的。但这样会带来一个明显的问题：内聚性很低，于是整个设计就变成了“低耦合低内聚”了。由于低内聚，整个类的变动同样非常频繁。 对于“低耦合低内聚”来说，还有另外一个明显的问题：几乎无法被其它类重用。原因很简单，类本身太庞大了，要么实现很复杂，要么数据很大，其它类无法明确该如何重用这个类。 SRP 原则 – 单一职责原则有很多翻译叫做： 一个类只做一件事。一个类只有一个变化的原因。 但是这个太难满足了。 我们从语义上说。什么叫职责？ “职责”是站在他人的角度来定义的，而不是自己定义的。 所以类的职责： 1） 类的职责是站在其它类的角度来定义的； 2） 类的职责包含多个相关功能； 一个类只负责一组相关的事情 SRP不能应用于聚合类，那么如何保证聚合类的设计质量呢？ OCP 原则 ？？？ – 还是不能理解。。open for provider extension，closed for consumer modification]]></content>
      <categories>
        <category>Code</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[book -- 学会提问]]></title>
    <url>%2Fblogs%2Fbbd7ce62.html</url>
    <content type="text"><![CDATA[淘金式思维与海绵式思维 弱者批判性思维与强者批判性思维 关键问题 论题和结论是什么 理由是什么 哪些词语的意思不明确 什么是价值观假设和描述性假设 推理过程中有没有谬误 证据的效力如何 有没有替代原因 数据有没有欺骗性 有什么重要信息被省略了 能得出哪些合理的结论 提问之前学会分析，关我什么事 下结论时，有理有据，然后信心百倍。但留有余地，三思后行。 两种论题： 1. 描述性论题：对过去、现在或将来的各种描述是否精确的命题 2. 规定性论题：我更想称之为是社科类命题 词语的解释方法： 举例-忧虑 1. 同义替换：忧虑就是感到紧张不安 2. 举例说明：忧虑就是候选人打开电视收看选举结果公布时的心情 3. 具体标准定义：忧虑是一种主观上的不适感，伴随有自主神经系统越来越强的感受。 如果判断价值观假设： 1. 从身份信息 2. 从其推论的结果。核电厂污染环境 vs 核电厂提高供电量 描述性假设：对过去，现在与未来是什么样的想法。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[killBase系列 -- 设计模式]]></title>
    <url>%2Fblogs%2F5b269d9f.html</url>
    <content type="text"><![CDATA[设计模式过去，曾经看过一本书， Head First 设计模式。那是第一次真正意义上的接触设计模式上面的东西。生动形象加上贴图作为例子。可以说是对设计模式有了一点初步的了解，但是，碍于时间原因，不过是浅尝辄止吧。不过，现在入职后，因为要阅读大量的源码，所以，需要对代码结构有更深层次的了解。因此，通过设计模式进行对照，一方面方便源码的阅读，一方面加深自己对设计模式的印象。 不过这一次的博客，不能像过去那样，只是作为一个知识的储存场所。应该是整理思维脉络的时候。所以，这一次的大概逻辑是 先把自己能想象到的设计模式列出来。 然后把作用列出来。 然后是 Uml 图。 最后做补充。 Factory Method生成实例的工厂。 有别于静态工厂。 Template Method将逻辑写到抽象类中，然后具体实现由子类实现 Iterator 模式帮助遍历整个集合 Adapter将两个不同的类，组合起来。并对外界表现为其中一个的模样 Bridge桥接，说明有两个岸。分别代表功能层次与实现层次 State取消 if 语句 Builder灵活的创建相应的对象。 CompositeFile 与 Directory ， 但是同属于 Item Abstract Factory上面的工厂是生成不同的实例，而这里的工厂是生成不同的工厂。 Visitor 模式交给 拜访者 做某些事情。 Chain of Responsibility一层层的向下推卸责任。 Command这里的主体，是 Command , 但往往每个命令存在单一的指令。。不是单一的策略。而是可以多个命令顺序执行。并且是由命令执行。 execute Strategy这里的策略内的方法是实现上一层逻辑的基础，内部可能存在多个方法，只要替换了这个类，整个逻辑就不一样了。 ObserverMediator 模式交给中立者仲裁 Decorator 模式添加装饰1234567new SideBorder( new FullBorder( new SideBoder( new SideBoder() ) )) 类似于这种，可以一致持续下去。 Facade 模式将处理的逻辑隐藏起来。· Memento 模式储存 snapshot Protype 模式基于原型的模式上，加入一些新功能。利用了 clone() 方法 – 默认浅拷贝 使用原型模式创建对象比直接new一个对象在性能上要好的多，因为Object类的clone方法是一个本地方法，它直接操作内存中的二进制流，特别是复制大对象时，性能的差别非常明显。 使用原型模式的另一个好处是简化对象的创建，使得创建对象就像我们在编辑文档时的复制粘贴一样简单。 因为以上优点，所以在需要重复地创建相似对象时可以考虑使用原型模式。比如需要在一个循环体内创建对象，假如对象创建过程比较复杂或者循环次数很多的话，使用原型模式不但可以简化创建过程，而且可以使系统的整体性能提高很多。 Flyweight 模式Proxy 模式]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[book -- 人月神话]]></title>
    <url>%2Fblogs%2Fb493d1fd.html</url>
    <content type="text"><![CDATA[不要相进度落后的队伍增添人手 注意沟通和交流。并且及时的沟通和交流 配备精良的外科团队。 一个优秀的大脑。 清晰明确的文档。规划目标，里程碑，交流，分歧。 好的自顶向下设计从几个方面避免了bug。首先，清晰的结构和表达方式更容易对需求和模块功能进行精确的描述。其次，模块分割和模块独立性避免了系统级的bug。另外，细节的隐藏使结构上的缺陷更加容易识别。最后，设计在每个精化步骤的层次上是可以测试的，所以测试可以尽早开始，并且每个步骤的重点可以放在合适的级别上。 进度的透明可见 减少角色冲突和鼓励状态共享 – 不对他人权限内的东西过多干涉 评审机制 总结：这是一本作为项目经理，如何去管理团队，保证项目的按时完成的管理书籍。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[killWork -- bug's party -- 180729]]></title>
    <url>%2Fblogs%2F84398cd3.html</url>
    <content type="text"><![CDATA[class 的热替换 class 的热替换包含 tomcathttp://www.importnew.com/22462.htmljar 包的读取https://blog.csdn.net/hy_timer/article/details/76268759netty selector 原理 NIO 中 selector 是通过 epoll 实现https://cloud.tencent.com/developer/article/1005481 [1]select、poll、epoll_wait 陷入内核，判断监控的socket是否有关心的事件发生了，如果没，则为当前 process 构建一个 wait_entry 节点，然后插入到监控 socket 的 sleep_list[2]进入循环的schedule 直到关心的事件发生了[3]关心的事件发生后，将当前 process 的 wait_entry 节点从 socket 的 sleep_list 中删除。 [1]socket 的事件发生了，然后 socket 顺序遍历其睡眠队列，依次调用每个 wait_entry 节点的 callback 函数[2]直到完成队列的遍历或遇到某个 wait_entry 节点是排他的才停止。[3]一般情况下callback 包含两个逻辑：1.wait_entry自定义的私有逻辑；2.唤醒的公共逻辑，主要用于将该 wait_entry 的 process 放入CPU的就绪队列，让CPU随后可以调度其执行。 select 逻辑 我们应该block在等待事件的发生上，这个事件简单点就是”关心的N个socket中一个或多个socket有数据可读了”，当block解除的时候，就意味着，我们一定可以找到一个或多个socket上有可读的数据。 另一方面，根据上面的socket wakeup callback机制，我们不知道什么时候，哪个socket会有读事件发生，于是，process需要同时插入到这N个socket的sleep_list上等待任意一个socket可读事件发生而被唤醒，当时process被唤醒的时候，其callback里面应该有个逻辑去检查具体那些socket可读了。 当用户process调用select的时候，select会将需要监控的readfds集合拷贝到 内核空间（假设监控的仅仅是socket可读），然后遍历自己监控的socket_sk，挨个调用sk的poll逻辑以便检查该sk是否有可读事件，遍历完所有的sk后, 如果没有任何一个sk可读，那么select会调用schedule_timeout进入schedule循环，使得process进入睡眠。如果在timeout时间内某个sk上有数据可读了，或者等待timeout了，则调用select的process会被唤醒，接下来select就是遍历监控的sk集合，挨个收集可读事件并返回给用户了 epoll 逻辑fds集合拷贝问题的解决epoll引入了epoll_ctl系统调用，将高频调用的epoll_wait和低频的epoll_ctl隔离开。epoll_ctl通过(EPOLL_CTL_ADD、EPOLL_CTL_MOD、EPOLL_CTL_DEL)三个操作来分散对需要监控的fds集合的修改，做到了有变化才变更，将select或poll高频、大块内存拷贝(集中处理)变成epoll_ctl的低频、小块内存的拷贝(分散处理)，避免了大量的内存拷贝。 同时，对于高频epoll_wait的可读就绪的fd集合返回的拷贝问题，epoll通过内核与用户空间mmap(内存映射)同一块内存来解决。mmap将用户空间的一块地址和内核空间的一块地址同时映射到相同的一块物理内存地址（不管是用户空间还是内核空间都是虚拟地址，最终要通过地址映射映射到物理地址），使得这块物理内存对内核和对用户均可见，减少用户态和内核态之间的数据交换。 epoll通过epoll_ctl来对监控的fds集合来进行增、删、改，那么必须涉及到fd的快速查找问题，于是，一个低时间复杂度的增、删、改、查的数据结构来组织被监控的fds集合是必不可少的了。fds 集合为红黑树。 按需遍历就绪的fds集合通过上面的socket的睡眠队列唤醒逻辑我们知道，socket唤醒睡眠在其睡眠队列的 wait_entry(process )的时候会调用wait_entry的回调函数callback，并且，我们可以在callback中做任何事情。为了做到只遍历就绪的fd，我们需要有个地方来组织那些已经就绪的fd。为此，epoll引入了一个中间层，一个双向链表(ready_list)作为一个单独的睡眠队列(single_epoll_wait_list)，并且，与select或poll不同的是，epoll的process不需要同时插入到多路复用的socket集合的所有睡眠队列中，相反process只是插入到中间层的epoll的单独睡眠队列中，process睡眠在epoll的单独队列上，等待事件的发生。 同时，引入一个中间的wait_entry_sk，它与某个socket_sk密切相关，wait_entry_sk睡眠在sk的睡眠队列上，其callback函数逻辑是将当前sk排入到epoll的ready_list中，并唤醒epoll的single_epoll_wait_list。而single_epoll_wait_list上睡眠的process的回调函数就明朗了：遍历 ready_list 上的所有sk，挨个调用sk的poll函数收集事件，然后唤醒 process 从 epoll_wait 返回。 ET(Edge Triggered 边沿触发) vs LT(Level Triggered 水平触发)Edge Triggered (ET) 边沿触发 socket的接收缓冲区状态变化时触发读事件，即空的接收缓冲区刚接收到数据时触发读事件 socket的发送缓冲区状态变化时触发写事件，即满的缓冲区刚空出空间时触发读事件仅在缓冲区状态变化时触发事件，比如数据缓冲去从无到有的时候(不可读-可读) Level Triggered (LT) 水平触发 socket接收缓冲区不为空，有数据可读，则读事件一直触发 socket发送缓冲区不满可以继续写入数据，则写事件一直触发 ifcfg-eth33 prefix 参数为了自己的虚拟机里的 Linux 可以连接上网，不知道在哪拷贝了一段代码，加入到了自己的文件里。但是还是连接不上，经过排错后，发现是 因为 prefix 参数的问题。如果 prefix 参数设置不对，那么 ip 地址和 网关 不管怎么修改，都不对。最简单的方法，删除 prefix 参数。 isAssignableFrom() 与 instanceof() 区别 isAssignableFrom()方法是从类继承的角度去判断，instanceof()方法是从实例继承的角度去判断。 isAssignableFrom()方法是判断是否为某个类的父类，instanceof()方法是判断是否某个类的子类。 JDK 自带的监控器模式在Java中通过Observable类和Observer接口实现了观察者模式。Observer对象是观察者，Observable对象是被观察者。实现观察者模式非常简单，[1]创建被观察者类，它继承自java.util.Observable类；[2]创建观察者类，它实现java.util.Observer接口；[3]对于被观察者类，添加它的观察者：void addObserver(Observer o) addObserver()方法把观察者对象添加到观察者对象列表中。 当被观察事件发生时，执行：12setChanged();notifyObservers(); setChange()方法用来设置一个内部标志位注明数据发生了变化；notifyObservers()方法会去调用观察者对象列表中所有的Observer的update()方法，通知它们数据发生了变化。只有在setChange()被调用后，notifyObservers()才会去调用update()。 [4]对于观察者类，实现Observer接口的唯一方法update1void update(Observable o, Object arg) 形参Object arg，对应一个由notifyObservers(Object arg);传递来的参数，当执行的是notifyObservers();时，arg为null。 获取 Annotation 相关的注解http://liuxi.name/blog/20161227/java-annotations-api.html 12345678getAnnotationgetAnnotationsgetAnnotationByType// 1. 忽略继承// 2. JDK 1.8 以下没用getDeclaredAnnotationgetDeclaredAnnotationsgetDeclaredAnnotationByType getResourceAsStream – getSystemResourceAsStreamClassLoader().getSystemResource()只能获取 jvm 的 ClassLoader, 获取不到 tomcat 的 ClassLoader this.getClass().getClassLoader().getResource()获取当前类的 ClassLoader – 随环境改变 this.getClass().getResource()相对路径，会判断文件路径 “/” 还是 “./” 必须加入 / Thread.currentThread().getContextClasLoader().getResource()加载当前线程的 ClassLoader 1234567891011System.out.println(ClassLoader.getSystemResource(&quot;&quot;).getPath());// 当前类目录System.out.println(getClass().getResource(&quot;&quot;).getPath());// 根目录System.out.println(getClass().getResource(&quot;/&quot;).getPath());// 相对目录System.out.println(getClass().getResource(&quot;./&quot;).getPath());System.out.println(getClass().getResource(&quot;../&quot;).getPath());System.out.println(getClass().getClassLoader().getResource(&quot;&quot;).getPath());System.out.println(getClass().getClassLoader().getResource(&quot;&quot;).getPath()); 输出 1234567/D:/Programme/Tomcat-8/webapps/FR/WEB-INF/classes//D:/Programme/Tomcat-8/webapps/FR/WEB-INF/classes/com/fr/env/util//D:/Programme/Tomcat-8/webapps/FR/WEB-INF/classes//D:/Programme/Tomcat-8/webapps/FR/WEB-INF/classes/com/fr/env/util//D:/Programme/Tomcat-8/webapps/FR/WEB-INF/classes/com/fr/env//D:/Programme/Tomcat-8/webapps/FR/WEB-INF/classes//D:/Programme/Tomcat-8/webapps/FR/WEB-INF/classes/ 双重校验锁的 volatie 变量申请内存空间，初始化默认值（区别于构造器方法的初始化），执行构造器方法连接引用和实例。 这4个步骤后两个有可能会重排序，1234 1243都有可能，造成未初始化完全的对象发布。volatile可以禁止指令重排序，从而避免这个问题。 Filenew File(String Path)path 不能为这种形式。Tomcat 8.]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killWork</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killWork -- bug's party -- 180723]]></title>
    <url>%2Fblogs%2F64ec65cd.html</url>
    <content type="text"><![CDATA[180722 问题总结文件服务器路径问题。目录不能写 /要写 /home/3dot141/pics因为 ../backup 是这种形式 cd /usr/local/nginx/../redis_test 进入 /usr/local/nginx/然后上一个文件夹 即 /usr/local/最后进入 redis_test tomcat 部署不了项目因为自己在 catalina.bat 上写了 jvm 的参数 localhost:8080 没反应localhost:8080 没反应的原因我们的项目的工件输出目录在下图红色矩形框出来的地方，而不是在安装的tomcat的Apache-tomcat的webapps的目录下。所以就相当于，IDEA在H:\IdeaProjects\DialogeEngine\out\artifacts虚拟了一个Tomcat，而在H:\IdeaProjects\DialogeEngine\out\artifacts下又没有Tomcat首页的工程。而此时并没有把Tomcat首页的工程部署到服务器，所以就访问不到Tomcat首页，而访问到的是我们项目里的其他页面信息。![](http://ovmspkp0s.bkt.clouddn.com/201807170952_57.png Xshell Socket error Event: 32 Error: 10053重新更改权限(系统配置文件请勿随意开放为所有权限，切记)chmod 400 /etc/ssh/*重启SSHservice sshd restart重启网关service network restart 原文链接 Tomcat 停机过程分析文件或字符串 MD5 校验获取文件的MD5码：System.out.println(DigestUtils.md5Hex(new FileInputStream(new File(“C:/ttt/new1328505655521”)))); 获取字符串MD5码：System.out.println(DigestUtils.md5Hex(string)); redis集群 报错[ERR] Node is not empty. Either the node already knows other nodes 解决方法： 将需要新增的节点下aof、rdb等本地备份文件删除； 同时将新Node的集群配置文件删除,即：删除你redis.conf里面cluster-config-file所在的文件； 再次添加新节点如果还是报错，则登录新Node,./redis-cli–h x –p对数据库进行清除： 172.168.63.201:7001&gt; flushdb #清空当前数据库注： 每一个集群中的节点都需要还原。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killWork</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mood -- 不能这样]]></title>
    <url>%2Fblogs%2F5ba33d35.html</url>
    <content type="text"><![CDATA[不自律没有一个规律的作息，让生活过得挺让人遗憾的。生命的长度就这么一点，但是自己还不能完美的使用他，多让人遗憾。 之前，在学校的时候，自己没有什么必须完成的任务，所以，每天该做什么事情的时候，可以不考虑这么多，直接去做就是了。但是入职后不一样了。首先要完成自己的任务，才能够放心的去做自己的事情。但是起冲突的一点是任务的时限往往不是一天。因此，自己如果想要完成后再做这件事情，就会误了之前几天的时间。所以想要解决这个问题的一个方法是，将任务细化，每天完成一点，而不是赶着完成。精神有一点点的紧绷，是有助于自身的学习的。这种紧绷的感觉会带动整个身体，大到头脑的控制中枢，小到细胞的活跃程度。都会有不同程度的提升。但是，这种紧绷的感觉是不能持续太久的。这是以消耗自身的能量储备为前提的一种兴奋刺激。因此，一晚上优质的睡眠 + 自己喜欢的事情 + 规律的锻炼 = 能量的恢复所以必须好好安排这一切。 另外现在的这种时间安排是没有安排自己的阅读时间的。这一点是非常不友好的，尤其是对一个阅读爱好者来说。所以自己的时间安排，和心态调整必须尽早提上日程。刻不容缓。 杂乱的知识现在自己的 pocket/evernote 中还存储着大量的未阅读知识。这些东西现在只是一个知识的储存工具。但是， pocket 知识过滤的作用没起到。并且， evernote 对知识的二次加工效果也不是很好。这些都需要进一步的去整合。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[serendipity -- 180714]]></title>
    <url>%2Fblogs%2Ff5134600.html</url>
    <content type="text"><![CDATA[冯小刚十问谬误这是一个逻辑题目。很有意思 。比较适合之后在商场中和别人交锋。 第1段：《手机》主角严守一没娘、离过婚···他干的所有事你崔永元没有干过、人物关系也和你不同，因此，严守一≠崔永元，所以构不成对你的影射伤害，因此你是碰瓷； 混淆概念： 这里说的是一个精确的概念和大众概念的理解问题。大众对一部电影的人物的理解是什么？是找角色和现实人物的共通点，而不是找不同点。第2段：既然你觉得受了伤害，为什么不起诉；因为你不起诉，所以你更是碰瓷； 循环论证： 预设一个前提 A ,然后得到一个结论 B ，根据这个结论 B , 反过来推论这个 前提 A.第3段：文艺作品切忌对号入座，意大利黑帮都没有找《教父》，你就更不应该找了； 个人怀疑，诉诸权威 1. 意大利的黑帮找过 教父。2. 即便没找过，我也可以找你。第4段：你反基因是为了卖你的产品；你不能光举报别人漏税，你也要晒你的税单； 诉诸动机，斥之虚伪 别人有没有错，和你有没有错，不是一回事。第5段：中国电影发展不易，你却恶意抹黑电影行业和明星，明星做的善事比你多多了；第8段：你用一个合同，引起股市下滑，让亿万股民蒙受损失； 诉诸情感 将股民和电影业拉到自己这一边。第6段：你不善良，因此你不是好丈夫和好父亲；第7段：刘震云教育女儿、你说刘震云给你道歉，实际是断章取义，说假话； 谬误谬误 你发现一个人的某一点不好，从而否定这整个人。说这个人就是不好的。第9段：你不体面、你不如流氓、你是小人；第10段：你没能力让《手机2》停拍，《手机2》已经杀青，永远存在。 我不是药神进口药为什么贵？ 研发成本 + 专利权 + 市场竞争 + 受众在中国为什么更贵？ 5% 关税 + 17% 增值税 中国不承认美国药监局的测试，需要自己测试，加大了成本。 中国政策漏洞，进口药自主定价，使得本土药利润低，对生产商，医院的收益不好。并且可以在 20 年产权后，继续自主定价。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[killWork -- 入职一周查缺补漏]]></title>
    <url>%2Fblogs%2F1181d157.html</url>
    <content type="text"><![CDATA[res-45 ViusalVM布置的任务是通过 VisualVM api 的源码，输出相应的 JVM 信息。 这里首先记录源码阅读的思路。 其次记录源码涉及到的一些 api 的使用 然后总结一下，下一次如果还要阅读源码，应该如何开始。 1. 源码阅读的思路这里编译出来的源码是一个图形界面。所以，根据图形界面，找后台对应的 Bean – {1. DataSource, 2. Model }以及之后细分的那些 Bean , xxImpl;找到 xxProvider , xxSupport , xxModelFactory 的逻辑。然后分析 xxImpl 如何生成的。 注意： 这里要注意一个问题就是 要将这个类里引用的外部的包给搞清楚。更改源码，从而可以通过外部调用。 2. Attach API &amp;&amp; JMX API &amp;&amp; Instrumentation API2.1 Attach API提供 JVM 的一些基本信息。并且提供动态加载 class 的方法。 loadAgent()这里使用的 agent 非常重要，之后会介绍相关的内容。 网址如下： https://docs.oracle.com/javase/8/docs/jdk/api/attach/spec/index.html 2.2 Instrumentation APIhttp://ayufox.iteye.com/blog/655619https://blog.csdn.net/conquer0715/article/details/5177474 2.3 loadAgent涉及到代理类的问题。可以从 找到相应的解释 2.4 JMX APIthe Java Management Extensions.提供 对 JVM 各种参数的解析功能。api :https://docs.oracle.com/javase/8/docs/api/javax/management/package-summary.htm 2.5 System.getProperties()—|—java.version | Java 运行时环境版本java.vendor | Java 运行时环境供应商java.vendor.url | Java 供应商的 URLjava.home | Java 安装目录java.vm.specification.version | Java 虚拟机规范版本java.vm.specification.vendor | Java 虚拟机规范供应商java.vm.specification.name | Java 虚拟机规范名称java.vm.version | Java 虚拟机实现版本java.vm.vendor | Java 虚拟机实现供应商java.vm.name | Java 虚拟机实现名称java.specification.version | Java 运行时环境规范版本java.specification.vendor | Java 运行时环境规范供应商java.specification.name | Java 运行时环境规范名称java.class.version | Java 类格式版本号java.class.path | Java 类路径java.library.path | 加载库时搜索的路径列表java.io.tmpdir | 默认的临时文件路径java.compiler | 要使用的 JIT 编译器的名称java.ext.dirs | 一个或多个扩展目录的路径os.name | 操作系统的名称os.arch | 操作系统的架构os.version | 操作系统的版本file.separator | 文件分隔符（在 UNIX 系统中是“/”）path.separator | 路径分隔符（在 UNIX 系统中是“:”）line.separator | 行分隔符（在 UNIX 系统中是“/n”）user.name | 用户的账户名称user.home | 用户的主目录user.dir | 用户的当前工作目 3 学会阅读源码 首先读 core / base 目录 分析设计模式 入职双选会查缺补漏今天进行了一波面试，发现了一些自己的问题。所以需要进行总结一波。加深一下印象。 1. 常见反问总结 想听听您对这个产品下一步发展的想法，以及未来几年内希望达到的高度 希望听一下您对这个岗位的理想人选的要求。 2. 问题总结1 spring ioc 有什么作用低耦合 https://www.zhihu.com/question/23277575https://blog.csdn.net/javazejian/article/details/54561302 2 spring aop 有什么作用减少核心代码的复杂度，降低对代码的入侵 https://blog.csdn.net/javazejian/article/details/56267036 3 jvm 标记整理算法gc roots 遍历对象，然后区分存活以及死去的。标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。 4 jvm 青年代的空间 100， 老年代的空间 10. minor gc 后，老年代空间不够，怎么办？这里缺少了 major gc 的知识。http://www.importnew.com/15820.html 5 你在工作中遇到的最大的问题是什么。是怎么解决的。 6 你在工作中常用的 jar 包有哪些？ 7 多线程volatie 如何保持原子性，可见性…内存屏障。 8 算法25匹马，一个赛道，一次只能跑 5 匹。得到速度，问跑几次可以得到最前面的 3 个答 这就不是一道算法题目，这是一道智力题目。很尴尬。我没往这方向想。同学说，可以多从慕课网上，看 Java 智力题]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killWork</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killJava -- JVM 基础知识]]></title>
    <url>%2Fblogs%2Ff9222ed6.html</url>
    <content type="text"><![CDATA[jvm 基础知识 如何自定义默认的 类加载器。 loadclass – 双亲委派模型loadclass 源码 https://www.ibm.com/developerworks/cn/java/j-lo-classloader/https://www.cnblogs.com/xrq730/p/4847337.html JVM 表示一个类是同一个类有两个条件， 类的完整类名 加载这个类的 classloader 是否是同一个实例。 如何实现 java 的热部署因为java 不能加载重复的类， 但是 只要classloader 不同，就不是重复，所以可以创建同一个 classloader 的不同实例，从而达到 java 热部署的目的。 jvm 类的加载预先加载以及按需加载1 预先加载Java 运行环境为了优化系统，提高程序的执行速度，在 JRE 运行的开始会将 Java 运行所需要的基本类采用预先加载（ pre-loading ）的方法全部加载要内存当中，因为这些单元在 Java 程序运行的过程当中经常要使用的，主要包括 JRE 的 rt.jar 文件里面所有的 .class 文件当 java.exe 虚拟机开始运行以后，它会找到安装在机器上的 JRE 环境，然后把控制权交给 JRE ， JRE 的类加载器会将 lib 目录下的 rt.jar 基础类别文件库加载进内存，这些文件是 Java 程序执行所必须的，所以系统在开始就将这些文件加载，避免以后的多次 IO 操作，从而提高程序执行效率。注： 这里应该是使用 启动类加载器(BootStrap) 2 按需加载我们在定义一个类实例的时候，比如 TestClassA testClassA ，这个时候 testClassA 的值为 null ，也就是说还没有初始化，没有调用 TestClassA 的构造函数，只有当执行 testClassA = new TestClassA() 以后， JRE 才正真把 TestClassA 加载进来。 隐式加载和显示加载 隐式加载new 一个对象 显示加载class.forName() 加载流程当执行 java .class **的时候， java.exe 会帮助我们找到 JRE ，接着找到位于 JRE 内部的 jvm.dll ，这才是真正的 Java 虚拟机器 , 最后加载动态库，激活 Java 虚拟机器。虚拟机器激活以后，会先做一些初始化的动作，比如说读取系统参数等。一旦初始化动作完成之后，就会产生第一个类加载器―― Bootstrap Loader ， Bootstrap Loader 是由 C++ 所撰写而成，这个 Bootstrap Loader 所做的初始工作中，除了一些基本的初始化动作之外，最重要的就是加载 Launcher.java 之中的 ExtClassLoader ，并设定其 Parent 为 null ，代表其父加载器为 BootstrapLoader 。然后 Bootstrap Loader 再要求加载 Launcher.java 之中的 AppClassLoader ，并设定其 Parent 为之前产生的 ExtClassLoader 实体。这两个加载器都是以静态类的形式存在的。这里要请大家注意的是， Launcher$ExtClassLoader.class 与 Launcher$AppClassLoader.class 都是由 Bootstrap Loader 所加载，所以 Parent 和由哪个类加载器加载没有关系。 动态编译java中早就提供了用java方式去动态编译java源文件的接口，有关java动态编译的API都在javax.tools包中。本文主要使用jdk1.6以上版本提供的JavaCompiler工具来动态编译java源文件。我们可以通过ToolProvider类的静态方法getSystemJavaCompiler得到JavaCompiler对象实例。 12// 获取编译器实例 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); 得到JavaCompiler对象实例后，我们可以调用该工具的getTask(Writer out, JavaFileManager fileManager, DiagnosticListener&lt;? super JavaFileObject&gt; diagnosticListener, Iterable options, Iterable classes, Iterable&lt;? extends JavaFileObject&gt; compilationUnits)方法获取一个编译任务对象。 1CompilationTask compilationTask = compiler.getTask(null, fileManager, diagnostics, options, null, compilationUnits); 该方法第一个参数为文件输出，这里我们可以不指定，第二个参数为文件管理器实例 12// 获取标准文件管理器实例 StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null); 该文件管理器实例的作用就是将我们需要动态编译的java源文件转换为getTask需要的编译单元。 第三个参数DiagnosticCollector diagnostics是在编译出错时，存放编译错误信息。 第四个参数为编译命令选项，就是javac命令的可选项，这里我们主要使用了-d和-sourcepath这两个选项。 1234/** * 编译选项，在编译java文件时，编译程序会自动的去寻找java文件引用的其他的java源文件或者class。 -sourcepath选项就是定义java源文件的查找目录， -classpath选项就是定义class文件的查找目录，-d就是编译文件的输出目录。 */ Iterable&lt;String&gt; options = Arrays.asList(&quot;-d&quot;, targetDir, &quot;-sourcepath&quot;, sourceDir); 第五个参数为类名称，具体作用没研究清楚。第六个参数为上面提到的编译单元，就是我们需要编译的java源文件 12// 获取要编译的编译单元 Iterable&lt;? extends JavaFileObject&gt; compilationUnits = fileManager.getJavaFileObjectsFromFiles(sourceFileList); 当我们得到CompilationTask compilationTask编译任务后，我们就可以调用compilationTask.call()方法进行编译工作 12// 运行编译任务 compilationTask.call() 动态加载VirtualMachine + Attach + Agent + Instrumentation + ClassFileTransformer 这里的主要重点是 Instrumentation InstrumentationJava Instrutment只提供了JVM TI中非常小的一个功能子集，一个是允许在类加载之前，修改类字节(ClassFileTransformer)(JDK5中开始提供，即使随JVM启动的Agent)，另外一个是在类加载之后，触发JVM重新进行类加载(JDK6中开始提供，用于JVM启动之后通过Attach去加载Agent)。第二种方法 主要是用于 loadAgent 生成 Agent 类 下面是通过 ViusalMachine.attach() 方法后得到 VisualMachine 类。然后加载 JMX Agent 得到本地的 JMX 链接地址。然后创建 相应的 JMXConnetor 。从而得到相应的信息。1234567891011121314151617181920212223// 被监控jvm的pid(windows上可以通过任务管理器查看) String targetVmPid = &quot;5936&quot;; // Attach到被监控的JVM进程上 VirtualMachine virtualmachine = VirtualMachine.attach(targetVmPid); // 让JVM加载jmx Agent String javaHome = virtualmachine.getSystemProperties().getProperty(&quot;java.home&quot;); String jmxAgent = javaHome + File.separator + &quot;lib&quot; + File.separator + &quot;management-agent.jar&quot;; virtualmachine.loadAgent(jmxAgent, &quot;com.sun.management.jmxremote&quot;); // 获得连接地址 Properties properties = virtualmachine.getAgentProperties(); String address = (String) properties.get(&quot;com.sun.management.jmxremote.localConnectorAddress&quot;); // Detach virtualmachine.detach(); // 通过jxm address来获取RuntimeMXBean对象，从而得到虚拟机运行时相关信息 JMXServiceURL url = new JMXServiceURL(address); JMXConnector connector = JMXConnectorFactory.connect(url); RuntimeMXBean rmxb = ManagementFactory.newPlatformMXBeanProxy(connector.getMBeanServerConnection(), &quot;java.lang:type=Runtime&quot;, RuntimeMXBean.class); // 得到目标虚拟机占用cpu时间 System.out.println(rmxb.getUptime()); Agent目前Agent类的启动有两种方式，一种是在JDK5版本中提供随JVM启动的Agent，我们称之为premain方式。另一种是在JDK6中在JDK5的基础之上又提供了JVM启动之后通过Attach去加载的Agent类，我们称之为agentmain方式。Agent类的两种实现方式：在这两种启动方式下，Agent JAR文件中的代理类中都必须实现特定的方法，如下所示： 1、随JVM启动的Agent方式必须实现下面两个方法中的其中一个： 12public static void premain(String agentArgs, Instrumentation inst);[1] public static void premain(String agentArgs);[2] JVM 首先尝试在代理类上调用以下方法：1public static void premain(String agentArgs, Instrumentation inst); 如果代理类没有实现此方法，那么 JVM 将尝试调用： 1public static void premain(String agentArgs); 2、通过Attach去启动Agent类方式必须实现下面两个方法中的其中一个： 12public static void agentmain (String agentArgs, Instrumentation inst);[1] public static void agentmain (String agentArgs);[2] 代理类必须实现公共静态agentmain方法。系统类加载器（ClassLoader.getSystemClassLoader）必须支持将代理 JAR 文件添加到系统类路径的机制。代理 JAR 将被添加到系统类路径。系统类路径是通常加载包含应用程序 main 方法的类的类路径。代理类将被加载，JVM 尝试调用agentmain 方法。JVM 首先尝试对代理类调用以下方法： 1public static void agentmain(String agentArgs, Instrumentation inst); 如果代理类没有实现此方法，那么 JVM 将尝试调用： 1public static void agentmain(String agentArgs); 如果是使用命令行选项启动代理，那么agentmain方法将不会被调用。 代理类agent的加载：代理类将被系统类加载器加载（参见 ClassLoader.getSystemClassLoader），系统类加载器是通常加载包含应用程序main方法的类的类加载器。 MANIFEST.MF文件配置：Agent类(又称为代理类）必须被部署为JAR 文件。Agent代理类jar包中的MANIFEST.MF文件中，必须指定Premain-Class或者Agent-Class参数。MANIFEST.MF文件内容如下： 1234Manifest-Version: 1.0 Created-By: 1.6.0 (Sun Microsystems Inc.) Agent-Class: sun.management.Agent Premain-Class: sun.management.Agent ClassFileTransformer该类主要和 Instrumentation 类有关系，主要是为其添加一个更换字节码的转换器，从而在每次类加载之前，替换字节码，改变其作用。 主要方法： 1byte[] transform(ClassLoader loader,String className, Class&lt;?&gt; classBeingRedefined,ProtectionDomain protectionDomain, byte[] classfileBuffer)throws IllegalClassFormatException 该接口只定义个一个方法transform，该方法会在加载新class类或者重新加载class类时，调用。例如，inst.addTransformer(new SdlTransformer(), true)当代码中增加了一个可重转换转换器后，每次类加载之前，就会调用transform方法。若该方法返回null，则不改变加载的class字节码，若返回一个byte[]数组，则jvm将会用返回的byte[]数组替换掉原先应该加载的字节码。 byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) throws IllegalClassFormatException此方法的实现可以转换提供的类文件，并返回一个新的替换类文件。有两种装换器，由 Instrumentation.addTransformer(ClassFileTransformer,boolean) 的 canRetransform 参数确定： 可重转换 转换器，将 canRetransform 设为 true 可添加这种转换器不可重转换 转换器，将 canRetransform 设为 false 或者使用 Instrumentation.addTransformer(ClassFileTransformer) 可添加这种转换器在转换器使用 addTransformer 注册之后，每次定义新类和重定义类时都将调用该转换器。每次重转换类时还将调用可重转换转换器。对新类定义的请求通过 ClassLoader.defineClass 或其本机等价方法进行。对类重定义的请求通过 Instrumentation.redefineClasses 或其本机等价方法进行。对类重转换的请求将通过 Instrumentation.retransformClasses 或其本机等价方法进行。转换器是在验证或应用类文件字节之前的请求处理过程中调用的。 当存在多个转换器时，转换将由 transform 调用链组成。也就是说，一个 transform 调用返回的 byte 数组将成为下一个调用的输入（通过 classfileBuffer 参数）。 转换将按以下顺序应用： 不可重转换转换器不可重转换本机转换器可重转换转换器可重转换本机转换器对于重转换，不会调用不可重转换转换器，而是重用前一个转换的结果。对于所有其他情况，调用此方法。在每个这种调用组中，转换器将按照注册的顺序调用。本机转换器由 Java 虚拟机 Tool 接口中的 ClassFileLoadHook 事件提供。 第一个转换器的输入（通过 classfileBuffer 参数）如下： 对于新的类定义，是传递给 ClassLoader.defineClass 的 byte对于类重定义，是 definitions.getDefinitionClassFile()，其中 definitions 是 Instrumentation.redefineClasses 的参数对于类重转换，是传递给新类定义的 byte，或者是最后一个重定义（如果有重定义），所有不可转换转换器进行的转换都将自动重新应用并保持不变；有关细节，请参阅 Instrumentation.retransformClasses如果实现方法确定不需要进行转换，则应返回 null。否则，它将创建一个新的 byte[] 数组，将输入 classfileBuffer 连同所有需要的转换复制到其中，并返回这个新数组。不得修改输入 classfileBuffer。 在重转换和重定义中，转换器必须支持重定义语义：如果转换器在初始定义期间更改的类在以后要重转换或重定义，那么转换器必须确保第二个输出类文件是第一个输出类文件的合法重定义文件。 如果转换器抛出异常（未捕获的异常），后续转换器仍然将被调用并加载，仍然将尝试重定义或重转换。因此，抛出异常与返回 null 的效果相同。若要使用转换器代码在生成未检验异常时防止不希望发生的行为，可以让转换器捕获 Throwable。如果转换器认为 classFileBuffer 不表示一个有效格式的类文件，则将抛出 IllegalClassFormatException；尽管这与返回 null 的效果相同，但它便于对格式毁坏进行记录或调试。 jvm_内存管理 堆 线程 类和类加载器 – permgen NIO – direct memorysystem.gc() – –XX:DisableExplictGC JNI – native memory可以采用 openfiler 热点分析工具分析 当前系统执行的热点代码。 GC 日志分析1、 GC 输出参数： -verboes:gc-XX:+PrintGCDetails-XX:+PrintGCApplicationStoppedTime-XX:+PrintGCDateStamps-XX:+PrintHeapAtGC-Xloggc:[file} 2、 GC 日志格式 [GC [: -&gt; (total size1), secs] -&gt; (total size2), secs] GC 收集器名称 Young 区在GC 前占用的内存 Young 区在 GC 后 占用的内存 表示 Young 区局部收集时 jvm 暂停处理的时间 jvm heap 在 gc 前占用的内存 jvm heap 在gc 后占用的内存 gc过程中 jvm 暂停处理的总时间 - = - jstat -gcutil[pid][intervel][count]] 参数 解析 S0 Heap 上 Survirvor space 0 已经使用的空间比 S1 Heap 上 Survirvor space 1 已经使用的空间比 E Eden space 已经使用的空间比 O Old space 已经使用的空间比 P Perm space 已经使用的空间比 YGC Young GC 次数 YGCT Young GC 时间 FGC FGCT GCT 3、 堆快照分析 jamp -dump::format=b,file=[filename][pid]-XX:+HeapDumpOnOutOfMemoryError 配置当内存耗尽时记录下的内存快照-XX:+HeapDumpPath 指定文件路径 4、 Jvm Crash 日志分析 -XX:ErrorFile= 配置JVM 退出时在工作目录下产生日志文件退出原因分类，退出的 Thread 信息，退出的 Process 状态信息， 退出时与操作系统相关的信息 EXCEPTION_ACCESS_VIOLATION SIGSEGV EXCEPTION_STACK_OVERFLOW 涉及参数 -Xss , -XX:StackShadowPages=n thread 部分 instructions: 当前系统执行的机器指令 – udis86 stack: gbd + core文件]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mood -- 入职一周回顾_生活]]></title>
    <url>%2Fblogs%2F87784a66.html</url>
    <content type="text"><![CDATA[过去从 6.28 号来到无锡，这一转眼已经一个多星期的时间了。但是还没有适应这种身份的转变。从原来可以犯错的学生，到现在必须每一步都必须追求完美的职场人士。这种带来的压力，是我之前那种顺风顺水的生活没有体验过的。刚开始那几天尤其的厉害。每天晚上 12 点睡觉。但是 5 点半左右就会醒过来。然后内心就会惶恐。开始焦虑。从 7.6 号周五之后，整个人就放松了许多。应该是积压很久的压力来源终于过去了。因此无论结果如何，都感觉可以接受的这种样子。但是。这种心情是不对的。或者说这种想法是不对的。怎么能这么想呢。并不是一件事情过去之后，就与之后的生活没有多少联系了。而是会影响的。只不过这个影响的轨迹可能大可能小而已。自己究其惶恐的原因，还是自己不够强大。与这个行业接触的比较少，因此对自己的水平没有一个清楚的认识。但是根本上，还是自己之前的惰性，让自己感觉配不上这份工作。一段时间的逃避后，突然需要开始面对之前的逃避所带来的结果了。自己不知所措。慌张，慌乱。害怕原先因为距离带来的不熟悉到如今抽丝剥茧的拨开自己的一切之后，发现，自己只是一个空壳子。害怕别人的评价。害怕即将到来的结果。想再次的逃避，却无路可退。挂在悬崖边上，不敢上去面对现实，也不敢松开手纵身一跃坠入深渊。因此，就在这徘徊着，迷茫着。如果说今天的自己，最想说给自己听的一句话的吧。我想大概是，你活该。 现在7.8。周末。终于得了一天空闲。为了放松一下自己，我骑行去了南禅寺。以及鼋头渚。风景挺好，除了路途有些艰辛以外，都挺放松的。最大的感受就是身体真的不是很好。刚开始精力很是充沛。但是之后到了大约 12 点左右，就开始疲惫。高高的太阳悬着，虽然还不到那种，路上的柏油马路都冒出阵阵热气的时候。但依旧让我汗流不止。几十米的登山 再加上 10 公里左右的步行路程。就已经让我筋疲力竭。中途还不得不找个地方歇息一下。恢复恢复体力。身体是革命的本钱。整天坐在办公室里，一坐一天实在是让人的身体日渐松垮。将锻炼身体提到日程上迫在眉睫了呢。 未来不要追求平凡这是这两天看的一篇文章。我回顾之前自己的生活，确实在得到 offer 后，对自己放松了要求。没在多研究几本书，没再多去读别人的技术文章。也没有继续加强自己技术栈的深度和广度。自己好像对现状非常的满意。连一点对未来的希冀都没有了。就这样，安于现状，混吃等死。这让我惊愕。我还能够依稀的记得，自己当时为什么要转行。自己的雄心壮志，自己的满腔抱负。但是好像现在都抛掷脑后了。平凡正一点点的吞噬自己 不行，我还没有跨过山和大海，也没有看过人山人海，怎么能就这样，坐着一艘小船，顺着河流而下，离着那些山峰，那些人群，越来越远呢。古之圣人常立宏愿，以督促自己的一生。我也要仔细思考一下，我的人生抱负是什么。到了什么样的地步，我才觉得此生无憾呢？这个抱负一定要大，大到要花半辈子的时间去完成。这样无论中途有什么样的阻碍，或是停顿。我都可以在安排好一切后，重新整装出发。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[serendipity -- 180506]]></title>
    <url>%2Fblogs%2F28ef678f.html</url>
    <content type="text"><![CDATA[0502徐焰少将 - 《解放军为什么能赢》 共产党为什么赢了。依靠的是间谍战，而共产党的间谍战之所以比国民党优秀，是因为，我党的特务组织是由周恩来管理的，并且信条是绝对不搞对高层的暗杀，不腐败享受，不为情报搞色诱等等。 国民党为什么打不了游击战 。因为对待军政的策略不一样。虽然国民党的高层军官大多是学历较高，但是相比较起来，共产党的整体军队素质是高于国民党的。因为国民党的军队策略是 “兵贵愚，将贵智”，蒋介石由一句 名言” 打仗就是打将 “ 。 这是中国自古以来的名将领兵之道。明朝的戚家军只招收农民，凡是脸色白皙，眼神轻灵，动作轻快的一律不招。清朝曾国藩的湘军也是如此。但是共产党不一样 共产党讲究“兵民是胜利之本”，需要发挥基层士兵的革命觉悟和积极性。为此，需要士兵认字。所以对于共产党来说，分出的小股部队由很高的文化素养和政治素养，因此可以脱离大部队进行行动，骚扰敌军，团结群众，并且隐蔽自己。sum: 创新的过程总结两点： 可能需要离经叛道 并且足够的离经叛道。 选择困难症 上一次快速做出一个正确选择是什么时候。 之前哪些快速决策没有成功，但是早点发现比晚点发现要强 上一件你没有把握但是结果不错的事情是什么 如果不在这件事情上过度思考，省下来的时间精力可以做什么？ 摄影人像摄影 4 个方法 巧用玻璃，进行反光的多层遮罩效果，或者破碎效果 利用霓虹灯的多种光线 图书馆，如果模特的脸部有瑕疵，可以通过透过书中间的方式径向的隐藏瑕疵. 0505抑郁症暴走大事件第五季 – 54 如何鉴别抑郁症： 反应过重 持续时间长 ， 两周以上 抑郁症的危害：除了产后抑郁症，其他的只是自己心情不好。 如何帮助： 首先要知道单纯口头上的安慰是没有用处的。 将他们当作正常人一样，交流沟通。 帮助他们制定一个以任务量而统筹的时间表，将整个的一天贯穿起来。早上几点几点干什么，下午几点几点干什么。 在陪伴的时候，要告诉他们，我们去做什么，去做什么。 心理学什么影响了我们对一件物品的评价禀赋效应：当一个人一旦拥有某件物品，他对这件物品价值的评价，就会比之前未曾拥有时显著增加。 贫穷的危害只是物质的匮乏吗贫穷不止危害物质，更会影响大脑的结构，高自尊可以帮助摆脱这种影响。结论：一个人只有不卑不亢，才能于人于己做到泰然处事。 人的大脑与心理的发展是匀速的吗？不是，每个阶段有不同的敏感能力，可能5岁的时候，大脑是敏感能力，开发大脑的功能，会事半功倍，而6岁的时候，心理的发展是敏感能力，在这一阶段，有意的加快心理的成熟，会事半功倍。 自由意志决定人的动作吗？不，自由意志是一个旁观者，帮助我们理解我们为什么做这件事。当你试图摆动手指的时候， 会先产生一个电信号，决定我要动一下手指 过了大约 300 毫秒， 我们会意识到 “ 我们想动一下手指 ”。 最后做出动作。年龄变大导致人们能力的衰退？并不完全是，老人能力的衰退，更多的是心理的衰退哈佛大学的教授做一个实验，通过搭建“时空胶囊”，将房间布置得和16年前一模一样，然后邀请16位老人，在其中生活一个星期。后来，这16位老人，生活一周后，身体都有不同程度的改善。视力，听力，记忆力和反应速度都有明显提高。 0506亲密关系公式 公式一： 结果 = 奖赏 - 代价社会交换理论 (Social Exchange Theory) 结果是 奖赏(相处中正面积极的经历) 与 代价 (关系中具有惩罚性，不愉快的经历) 所衡量的。 公式二： 满意度 = 结果 - 比较水平比较水平 (Comparison Level): 亲密关系中，人们多多少少会对这段关系有一定的期待，或是觉得自己应当得到某种结果。 公式三： 依赖度 = 结果 - 替代的比较水平替代比较水平 (Comparison Level for Alternative)： 如果我们离开现有的亲密关系，选择我们所认为更好的伴侣或者情境所获得的结果。四种亲密关系 结果&gt;比较水平&gt;替代比较水平 = 稳定又幸福的亲密关系对现有关系满意，并且用心维持。 比较水平&gt;结果&gt;替代比较水平 = 稳定但不幸福的亲密关系对现有关系不满意，但是勉强维持。 替代比较水平&gt;结果&gt;比较水平 = 不稳定但幸福的亲密关系对现有关系满意，但倾向于离去 余下所有对现有关系不满意，将会离去。满意度的改变原因有二： 人们在感情的初期为了取悦伴侣会尽力展现出自己美好的一面，从而拉高了伴侣对亲密关系的期待成都。 当人们与自己的伴侣相处时间久后，会对伴侣越来越没有耐心，更容易向伴侣情绪化的发泄自己的不满。 一旦我们对亲密关系的满意程度降低，我们会对身边的替代比较水平开始敏感，仔细观察身边是否有能够替代现有关系的可能。 心理武器 - 解决方案 第一人称陈述 (I-Statement)以“我”开头的句子来表达个人对情境的反感。比如用 “我现在很生气” 代替 “你惹我生气了” 行为描述 (Behavior Description)面对不满时，通过详细的指出惹怒我们的特定行为，从而避免牵扯到伴侣的人格与品质 XYZ 陈述 (XYZ Statement)1 + 2 = 3 复述 (Paraphasing)这样做的优点： 伴侣知道我们在认真倾听 在伴侣讲完之前，不会打断 通过复述，减少误解的可能性，给对方以解释的机会。 为什么粉笔划过黑板会让人难受人耳的频率接受范围是 20 - 20000 hz而根据分析 处于 2000 - 5000 hz 的声音会让人不舒服。 从长远角度看利息 首先我们要理解，什么是利息。100 万房贷， 年利率 6%， 贷款 30 年，利息会有 115 万。 为什么存在利息。因为资源在整个时间维度上是稀缺的。利息就是提前享用资源的代价 早消费的人，需要给晚消费的人补偿，这个补偿就是利息。 长远角度的折现率考虑到通货膨胀，物品在时间维度上的价格的起伏。总结来说，早消费比晚消费花费的更多。 因为同样的产品，未来的更加便宜，所以不能将两个时间维度进行直接比较，需要将未来的价格折现后与现在的价格进行比较。因此回到 1 的例子，房贷分期付款 + 利息 的总价值折现到现在，恰好等同于全款买房的价格。 折现值概念大量运用于商业和金融中，大致使用的方式就是将 现在所做的事情 与 未来所得到的回报进行折现后的价值 进行比较。 放在个人身上，就是一个人越是对自己有更高的要求和目标，则对自己的自律越强。因为现在做的事情在整个时间维度上是最优的。 天人之际罗辑思维里讲了一个词 天人之际这个词出自 司马迁 的 史记 - “究天人之际，通古今之变，成一家之言”什么是天人之际呢，罗辑思维里提出一个观点是 “不详”。但是这个词语还是太过于宽泛。在我的理解中，天人之际，代表的更多是人心所向。古代帝王登基，往往有一句顺应天意。以天意为统治工具，对民众，百姓进行思想上的洗脑。告诉他们，我是天选之子，你们需要顺从我。这种师出有名的大义，之所以重要，就是民意决定了你是否能够成功。载舟覆舟，旨在民意一念之间。人心所向，方可披荆斩棘，战无不胜。 0509消费观的改变第一阶段： 渴望凭借名贵物品衬托我的气质。然而真正有气质的人往往具有使廉价物品增值的能力。缺乏底气的人才会过度依赖奢侈品第二阶段： 追求单一奢华主义寺山修司(电影导演，前卫戏剧的代表人物)评价单一奢华主义： 有的人可以裹着毛毯蜗居在桥底下，却省下钱买来梦寐以求的运动跑车；有的人可以连续三天只靠面包和一罐牛奶度日，第四天却踏进了马克西姆西餐厅。(巴黎上流社会年轻人聚会的 “俱乐部”)对平衡生活的突破以及制造更多的不可能。第三阶段： 彻底跟自己的消费能力和解 如果只是有钱就可以做到的事情，那么门槛还是太低了，不高级。 不要跳出心理舒适区心理舒适区： 呆在这个圈子里很舒服。一般来说，很多激励你不断学习的文章，会鼓励你跳出心理舒适区。 心理舒适区 + 自我追求 + 社会期待 的关系 心理舒适区 = 自我追求 = 社会期待。 不需要跳出心里舒适区。 此时需要 扩大 心理舒适区。 追求 不等于 期待 。此时会产生迷茫的心情，不知道是否需要跳出心里舒适区，因此，会极大的影响跳出的动力。 如何与领导相处 努力完成自己的工作，并且正确评价。 建立直系领导的 “ 资料库 ” 和 “ 情报网 ”。做到不越雷池 汇报之前事先彩排，不打无准备之战。 汇报的着重点，是部门现状以及项目的推进情况。 面对大领导，不要急着表现。要做好自己的本职工作，因为你能够见到大领导，往往是直系领导带你一起汇报。 大领导不会直接决定你的升职 直系领导往往希望你做好补充，这才是最重要的工作。 保证自己的建设性。也就是全面性。要多角度考虑。想出两种解决方法，分别应对不同的情况。 面对极端的领导，要知道一件事，就是 “ 你自己已经做好了一切属于你的工作，你已经足够优秀 ”。 私下场合，可以和领导 务虚 ， 谈谈人生谈谈理想。听听教诲可能会更好。 在和同事们一起面对领导时，注意后发优势。这就像无领导讨论，最后总结发言的人，也是一个很重要的展示自己的位置。 摄影 – 极简风格 做减法，观察环境，在脑海中复现，然后精简画面元素，让元素数量最小。 做加法，背景如果非常的干净整洁，可以加入一些高对比度的物体作为前面的主体元素。 色彩与对比度，极简风格一般色彩的改变很少，但是会很突兀，色彩对比度的差距较大。 纹理与重复图案。可以作为背景，因为这种大量的有序的图案或者纹理会让人觉得整洁，干净。而容易突出主体部分。 合理运用线条。除了可以作为背景，纵向延伸的线条，可以加剧纵深。而交错的线条，垂直的线条又会有不一样的感觉。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[serendipity -- 雷军-小米是谁]]></title>
    <url>%2Fblogs%2F7be8403e.html</url>
    <content type="text"><![CDATA[小米内容摘录“铁人三项”商业模式：硬件+新零售+互联网服务 小米前进的路上，我们一直在思考：从古至今，商业世界变化纷繁，跳出形形色色的商业模式话题之外，始终不变的是什么？ 用户对“感动人心、价格厚道”的产品的期待，这就是小米的答案。 “德不孤，必有邻”，通过独特的“生态链模式”，小米投资、带动了更多志同道合的创业者，围绕手机业务构建起手机配件、智能硬件、生活消费产品三层产品矩阵。 许商业以敦厚，许科技以温暖，许大众以幸福，我们的征途是星辰大海 评价蓝港 ：(蓝港互娱，娱乐方面的创业公司，设计游戏，动画等多个领域，杰出代表是 《十万个冷笑话》)雷军是中国人的骄傲，他的成就，是这个时代无数个人奋斗者的榜样。 bilibili : (前不久刚刚上市，是一家以 UGC 驱动的内容网站，动漫为主，从炮姐起家，然后涉及鬼畜、直播等多个领域，多为年轻人喜爱。)我2001年毕业就加入金山，在我成长的过程中，雷总一直是我的老师。他给我的不仅是事业上的指导，更重要的是教我如何为人。“做正直的人，做值得用户尊敬的公司”，这是雷总对我说的话，我一直铭记。 真格基金 ：(由新东方联合创始人 徐小平，王强，红杉资本中国创办)他创办小米，物质层面是要为中国消费者创造世界级物美价廉的产品。但在本质上，他是要扭转中国制造连中国人都不屑使用的现状。雷军要改变中国制造“潮水的方向” 拉卡拉 ： (联想控股成员企业，为综合性互联网金融服务公司，具备征信资格，服务多为：便民支付，移动支付，pos 收单， 跨境支付 – 这个不是和支付宝冲突吗？ 还有征信是什么意思) 猎豹 ： (原名金山网络)对小米而言，这是八年长跑梦想终于成真的时刻，对整个互联网而言，更是新生独角兽创造历史，改变行业格局的重要时刻。 感想毫无疑问，小米是一家离经叛道的公司。在2010年，智能手机市场才刚刚起步的时候。中华酷联正当红。一步国产的旗舰机型至少是3000+。让大多数人望而却步。是小米，通过开创独有的互联网模式，将整个手机产业吊打。本来一片和谐的手机市场，因为小米的入局，开始大量的清洗。魅族， 努比亚， 锤子， 一加， 还有乐视大量模仿小米模式的手机开始了自己的道路。中兴没落，酷派被收购，联想取消手机业务。若不是华为依靠内部的荣耀在刚开始抵挡住小米的寝室，后面的市场鹿死谁手还未可知。随着 oppo,vivo 的线下大量扩张，铺天盖地的广告吸引了大量中国人的眼球，小米的增长态势开始放缓。甚至一度被看衰。当这种需要一个一锤定音的决策，决定接下来的道路应该怎么走的时候。小米没有让我们失望。进军印度市场，开设小米之家，全面屏的开创。这一个又一个的决定，让小米从艰难的 15，16 年走了过来。也让我们感受到来自于小米内部决策者的高瞻远瞩。印度市场手机占有率第一，小米之家通过手机+配件+智能生活将这一切联系成一个整体，解决了线下门店的部分弊端。全面屏的首次亮相，让多少人惊呼，这是一次划时代的变革。小米正是通过这种与大众选择看似违背的角度，走出了一条创新的道路，并且通过一系列优秀的决策，在每一个分岔路口走的很平稳，很顺畅。上面说小米是一家工程师文化的公司。创始人 8 人， 6 个工程师，2 个设计师。我曾经用过几个小米手机，小米手机的 miui 系统是国产最优秀的 os ， 没有之一。我还记得我大二的时候，买了一个小米4c ， 刚开始触屏有一点问题， 上网查验后，发现是普遍问题， 就提意见，等修复。只用了一个星期的时间，在下一个小版本的更迭中，就成功改善了这个 bug ，提高了我的体验。最近，小米还联合其他6家公司，推出了 快程序 这个对标 小程序的产品，试图改变 小程序 一家独大，从而侵蚀公司利益的行为。虽然我还不知道 快程序 体验如何，但是敢于领头做这件事情，足以说明这家以技术为推动的公司有着自己的底气与傲气。 然而，在我看来，小米现在的问题有哪些？？ 供应链的问题。猴王的称号不是一天两天的。每次发布新机的时候，尽管许诺的很好，但是你抢不到就成了最大的问题。往往只有线下黄牛高价才能购入。这是小米与黄牛的联手的套路吗？我相信不是，以雷总的眼光，不会贪图这一点蝇头小利，这与公司的文化不符。但是，没有自己的工厂，没有自己的芯片，总是会受制于人。现在小米的销量是很不错，但是多是红米这种低端机型。在消费升级的背景下，这种机型的寿命势必是短暂的。以我周边的人为例，曾经用小米并坚持用下去的只有一人。从没用过小米，想用小米的，但是没抢到的，一人。其余都是放弃小米，或者从来不选择小米的人。是什么导致小米的依赖度这么低？我想他的供应链是其中重要的一个因素。相比较于隔壁友商， 发布华为 p20 后，抢购当天，现货充足，抢购 5 分钟内，都可以轻松入手。而小米 Mix 2s 从第一次发售，到 4 个星期后，我和我寝室的四个室友仍旧抢购失败，别无他法，只好入手了 iphone 8. 硬件的创新问题。小米近些年最杰出的创新就是小米 Mix 的全面屏，此后多是新瓶装旧酒，依次的更新迭代内部零件而已，澎湃处理器的出现，也只不过是一朵小浪花，距离那种大的震撼，还差的远。而华为凭借自己在硬件方面的雄厚基础，从一开始的 cpu ,gpu 全面被吊打，到现在 cpu 的迎头赶上， npu 的率先发布。积极与世界知名相机厂商徕卡合作，得到画质的相应调教。最近 华为 P20 pro 更是通过与索尼的深度合作，从而制成的 imx 600 ,4000 万像素真正意义上第一次超越了外国厂商。这些都是小米所不具备的。 小米的根本仍旧是手机，其智能配件只是井上添花，根据统计，手机、lot、互联网服务及其他营收分别占比 70.3%， 20.5%， 8.6%， 0.6%。如果不能抓住用户的痛点，将手机业务进一步铺展开来，小米之后的道路转型将异常艰难。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[book -- 谁动了我的奶酪]]></title>
    <url>%2Fblogs%2Fb9a77aa4.html</url>
    <content type="text"><![CDATA[前言这个故事中有4个虚构的角色： 嗅嗅： 及早嗅出变化的端倪 匆匆： 立刻采取行动 哼哼： 担心事态变得更加糟糕而否认、抵制变化。 唧唧： 发现变化可以带来更好的生活后及时调整。 摘录 唧唧呀唧唧，看看你自己吧！你居然等到每天重复同样的错误，还总是奇怪、怀疑为什么情况还没有得到改善，还有什么比你 这种做法更可笑呢？这如果不是荒谬，就是滑稽。 有时候，恐惧是一件好事，因为当你担心自己的无所作为会导致事态严重时，恐惧会促使你立即采取行动。但是，如果恐惧已经束缚你的手脚，以至于你什么也做不好，就不好了。 改变自己最快捷的方式就是嘲笑自己的愚蠢，这样才能对自己的过去使然，并迅速朝着新的方向前进，从而发现新的奶酪 不管自己怎么样，变化总是会不断的出现。你可能认为变化会伤害到你，所以抵制它们，拒绝接受变化。或者你认为找到新的奶酪对你有益，所以热烈的欢迎。只要相信自己能够找到并且享用新的奶酪，你就会改变自己的行为，预测变化，密切关注变化，迅速适应变化，并享受变化。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[serendipity -- 180430]]></title>
    <url>%2Fblogs%2Ffd6475c4.html</url>
    <content type="text"><![CDATA[投资观念玩币倾家荡产四大捷径： 追涨杀跌 期货杠杆由于期货是保证金交易，就是说，你只需要出一定比例的钱就可以做全部的买卖了。例如：假设铜每吨20000元，一手=5吨，那么一手单子的总价值就是520000=100000，如果保证金比例是10%，那么你只需要有1万做保证金就可以买入或卖出1手铜了。但是亏，盈都还是按一手单子货物的全价算，如果铜价跌到19000，那么519000=95000，如果这个时候平仓的话就是输5000元，相对1万的本金来说就是输50%了。所以说期货的杠杆是指1/保证金比例，保证金比例越高那么杠杆越低，反之，保证金比例越低杠杆越高。正规的期货品种杠杆倍数应该是大概8~12倍左右。一句话，杠杆效应就是有放大输赢倍数的作用。 融资融币 短线神操作 人生巅峰四条大道： 他是工作 闲钱投资 底部买进长线持有 按时吃饭睡觉 张哥：看不懂的钱，不赚也能保持心安理得是正确心态。有人炒房赚钱了，有人买比特币赚钱了，有人买腾讯股票赚钱了，有人创业成功赚钱了。这世界看不懂的赚钱方式太正常了。如果也想分一杯羹，就花精力了解，实践。如果自己没能力了解，也没时间了解。就随它去。 eosEOS ：EOS并不是官方的缩写，你可以理解为 Enterprise Operation System ，即为商用分布式应用设计的一款区块链操作系统。EOS是一种新的区块链架构，旨在实现分布式应用的性能扩展。 优势：1、EOS通过创建一个对开发者友好的区块链底层平台，类似区块链的操作系统，性能强大，可以支持多个应用程序同时运，可以同时支持多种编程语言，为开发dApp的开发者提供底层模块，降低开发门槛，就像是微软的windows，你说微软值不值钱。2、EOS通过并行链和DPOS的方式解决了延迟和数据吞吐量的难题。EOS能够实现每秒百万级的处理量，而目前比特币是每秒7笔，以太坊是30-40笔，EOS的这一超强能力吊打比特币和以太。如最近的CryptoKitties| Collect and breed digital cats! 这个特别火的ETH游戏，仅仅一个游戏就占了ETH 15%左右的吞吐量，要是同时上个七八个类似的游戏，ETH估计就要挂掉了，想想就很吓人。无法拓展带宽的ETH在吞吐量上会有很大的挑战，而EOS能解决上面的问题。3、EOS没有手续费，会吸引更多普通用户。而且如果在EOS上开发dApp，需要用到的网络和计算资源是按照开发者拥有的EOS的比例分配的。简单来说，就是你拥有了EOS，就相当于拥有了一套房租给别人收房租，或者说拥有了一块地租给别人建房。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[movie -- 后来的我们]]></title>
    <url>%2Fblogs%2F3738a5a.html</url>
    <content type="text"><![CDATA[起始的时候，这部电影并不吸引我，老套的剧情。并不能触及我内心柔软的台词。周冬雨没有太多突破的演技。失望。可能是我最大的感受。 因为感觉这样的电影，担负不起刘若英的后来，也担负不起我们。之后随着剧情的跌进，这种感觉还是缭绕着。知道剧情来到男女主角跨年后，第一次发生关系，然后女主的离开。才第一次让我觉得，这个剧情好像有点不一般。后面男女主顺理成章的在一起，然后又合乎情理的分手。让我第一次有了代入感，我认为这是这部电影的精髓。因为在情侣之间，很有可能会发生类似的事情。因此，当再一次进入到类似的语境时，会不由自主的想到当时的自己。这部电影，就像生活中的很平凡的小事情。你可能不关注，但是当需要记起的时候，你绝对不会遗忘。挺羡慕那些说，看完之后找不到一个情节有共鸣的人的。因为这样代表着他们少了一段遗憾。年少时的我们，总是不会在一起。这才是这个世界的常态。 总体而言，就人物的刻画上，这两个主角挺渣的。一个在开始的时候不断的换男友，一个在已经已婚后，还带着初恋来宾馆开房。如果不是恰好被同事撞见。可能又是一场激情。 知乎上有个女生的高票答案是这么回答的，反正我不能忍受老公跟前女友共度一夜谈人生谈理想回忆过去喝个半死还差点啪啪啪，最后还送对方回家这种事情。这个应该是女生的感情总结的比较完善的了。但是，她逃避了一个问题，如果是她相遇了她的前任，她能够那么洒脱的放下一切嘛。看过一个视频。一个小伙子失恋后，一直单身。有一天，他意外得知前女友的婚期，于是自己一个人开着车跟在婚礼车队后面，默默送了一路。。。他一边开车，一边嚎啕大哭，像个无助的孩子，看着自己喜爱的东西，却没有办法得到。理智一点点的剥离，而回忆以及回忆带来的伤痛铺天盖地。直到收到前女友发来的短信： 对不起，别追了，就送到这里吧。他才慢慢把车停下，目送着婚礼车队渐行渐远。而昔日里爱过的那个人啊，终于穿着婚纱，带着一脸的娇羞，嫁给了他人的妻子。 所有的欲言又止、一言难尽，都被岁月这壶酒好好的沉淀着，直到”后来”将它启封，然后相忘。 曾经看“你的名字”的时候，有一个影评很打动我，所爱隔山海，山海亦可平。但是，生活里更多的，是 所爱隔山海，山海不可平。想起电影里，见清的父亲给小晓信里的那句话：缘分这个东西，不负对方就好，想不负此生，真的难。我爱过的人啊，不知道，对你来说，我是否做到了不负如来不负卿。但我想对你说，我想你过的比我好，也不想你比我过的坏，只要过的，比我坏一点点就好。 电影里最打动我的场面是见清从出租屋里追到地铁站，和小晓隔着一扇地铁门相互对视。随着地铁的灯亮起，滴滴滴滴的提示音带走了小晓，也带走了十年。十年之后，他们再相遇的时候。见情问：“如果当时你没走，后来的我们会不会不一样？”方小晓回答：“如果当时你有勇气上了地铁，我会跟你一辈子。”很多人说，见清懦弱，没有责任感。我也这么觉得，因为我也是这么懦弱。 和前任分手的时候，我们在山木楼的桥上坐着，安静着不说话。我一直平静的看着她的侧脸，到最后也没敢说出一句挽留的话语。懦弱吗？当然是的。可笑的是，自己当时还真的以为是为了她好。因为未来的不确定，而放弃自己喜欢的人。是不值得爱的。这是最近的一次聊天里，一个可爱的女孩子教会我的道理。 曾经，“有一个男孩爱着一个女孩” 是很好的开始，后来，“有些人一旦错过就不再” 是很好的结局。谢谢年少时相爱的人，教会了现在如何去爱。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mood -- 180430]]></title>
    <url>%2Fblogs%2Fb775701c.html</url>
    <content type="text"><![CDATA[今天一天的天气都灰蒙蒙的，阴沉着一天的小脸终于在临近夜晚的时候，绷不住自己的情绪，泪珠哗啦啦的滚下。 趁着闲暇和父上大人打了一通电话，虽然都是些家长里短，但也不无尽兴。 过去和老爸都是会对一些问题产生分歧，然后进行辩证的讨论，从中得到营养，感悟。 但是，现在，可能是随着时间的流逝，老爸没有了之前的锐气，开始听从我的意见。 我们的话题从辩论赛转移到了生活上。 聊一聊谁家的姑娘该出嫁了，谁家又买了辆车，谁家的孩子又考上了学。 过去的我，从来没想过，能轻松，愉快的和父亲谈论这样的话题。也没有想过，原来家长里短，也都不无趣味。 很喜欢今天的风，今天的云，今天阴沉的阳光与滚落的雨。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[book -- 高效能人士的七个习惯]]></title>
    <url>%2Fblogs%2F1a0b30b6.html</url>
    <content type="text"><![CDATA[上个周末，去书店看书，挑来挑去选了这一本书。算是缘分使然吧。从中得到了许多关于人生的建议。与诸君分享。 0. 总纲习惯 知识： 做什么，为何做 技巧： 如何做 意愿： 想要做 七个习惯模型 依赖期 – 独立期 积极主动 以终为始 要事第一 独立期 – 互赖期 双赢思维 知彼解己 综合统效 不断更新 1. 积极主动人类独有的四种天赋： 自我意识人类具有选择的自由 想象力超越现实而在头脑中进行创造的能力 良知明辨是非，坚持行为原则，判断思想，言行正确与否的能力 独立意志基于自我意识，不受外力影响而自行其是的能力 积极主动的案例： 消极被动的语言 积极主动的语言 我已无能为力 试试看有没有其他的可能性 我就是这样 我可以选择不同的作风 他把我气疯了 我可以控制自己的情绪 他们不会答应的 我可以想出有效的表达方式 我只能这样做 我能选择恰当的回应 我不能… 我选择… 我不得不… 我更愿意… 要是…就好了 我打算… 影响圈与关注圈积极主动的人专注于“影响圈”，专心做自己利索能力的事，使影响圈不断扩大。 影响圈的核心：做出承诺，与信守承诺的能力 这里要说一句，最好承诺的事情，是举手之劳，并且把握与影响较大的事情，不然，请果断拒绝。 2. 以终为始以终为始的原则 两次创造的过程 Mental/First Creation: 头脑构思 Physical/Second Creation: 付诸实践 自我领导 领导是第一次的创造，先于管理 管理是正确的做事情，领导是做正确的事情。 人格的组成： 安全感 ： 代表价值观、认同、情感的归属，自尊自重与是否拥有个人的基本能力 人生方向 ： 地图和内心的准绳，人类以此为解释外界事物的理据以及决策与行为的原则和内在标准 智慧 : 人类对生命的认知，对平衡的感知，对事物间联系的理解，包括判断力，洞察力，理解力，是这些能力的统一。 力量 ： 采取行动，达成目标的能力。 自我领导的方式：心灵演练：以 个人、积极、果断、可视、情感 五个方面，进行模拟。例： 发现子女行为不当时，我（个人）能以智慧，爱心、坚定的立场以自制力(积极) 及时应对 (果断)， 结果让我深感欣慰。 使命宣言：使命，目标，角色。详细的使命宣言在附录 3. 要事第一四代时间理论 第一代 ， 着重利用便条与备忘录, 在忙碌中调配时间与精力 第二代 ， 强调日程， 反映时间管理已经注意到未来的重要。 第三代 ， 一句轻重缓急设定 短、中、长期目标，再逐日制定目标的计划，将有限的时间、精力加以分配，争取最高的效率。 第四代 ， 主张个人管理，将重心维持到产出于产能的平衡上。 时间管理矩阵 紧迫 不紧迫 重要 危机迫切问题再限定时间内完成 预防性措施建立关系明确新的发展机会制定计划和休闲 不重要 接待访客某些信件、报告，会议公共活动 令人愉快的活动琐碎的工作 不紧迫 + 重要 是高效能人士，最应该注重的东西 4. 双赢思维不能双赢，就好聚好散。 5. 知彼解己自传式回应(Autobiographical response) 价值判断 – 对旁人的意见只有接受或不接受 追根究底 – 依自己的价值观探查别人的隐私 好为人师 – 以自己的经验提供忠告。 自以为是 – 根据自己的行为于动机衡量别人的行为于动机 真正的交流方式：复述+解释+感情 例：子： 上学真是无聊透了 复述父： 你已经受不了了，觉得上学太无聊 复述 + 解释父： 你不想上学了 感情父： 你感觉很有挫败感 复述 + 解释 + 感情父： 你对上学有很深的挫败感。 总结： 在日常交流中，应该养成的习惯： 倾听 – 上学无聊 找出想法 – 不想上学 加以感情 ， 解释原因 – 因为有挫败感 最后陈述 附录使命宣言：我的使命：不恋过去，不畏将来，脚踏实地，有规划，有激情的走好每一步，并在生活中力所能及的给予他人关怀与爱。需求： - 自律：登峰造极的成就来源于自律。无论是智力，身体，精神，社会/情感，都需要自律的支持。 - 坚持：这里的坚持，是说在面对他人的不解与质疑的时候，能够走好自己的道路。不要太过于在意他人的眼光，从而打乱自己的节奏。 - 友善：在生活中，无论对待什么人，还是什么事，第一时间，应该是微笑，然后再考虑如何处理。第一印象的笑容，无论是平和自己的心情，还是抚平对方的焦躁，都是最有力的武器。 - 阳光：人生不如意之事，十之八九，然不幸各不相同。永远开心，阳光的去感染身边的人，做一颗发光发热的小太阳，也是极好的。角色： - 儿子： - 丈夫 - 朋友 - 学生 - Coder]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[记一次讯飞平台的 api 使用问题。]]></title>
    <url>%2Fblogs%2F2bb530bc.html</url>
    <content type="text"><![CDATA[之前的便签，一直是 google keep ， 但是在 ios 系统上，同步不方便。每次打开都需要挂着 vpn 。最近接触到了 workflow 与 讯飞听写 。有了一些新的想法。 本来是想通过 url sceme 直接调用 讯飞听写，从而快捷记录。但是这样记录还是将自己的想法分散的放到了不同的 app 里。不便于管理。因此，开始将所有的 idea 通过 evernote 进行管理。通过 workflow 进行便捷记录。但是在使用的过程中，遇到了一个问题，就是想要模拟出讯飞听写 的效果，同时保存录音与文字。在网上查了讯飞听写的文档，恰好最近开通了 web api , 所以就想要使用 web api 进行网络上的语音处理。 Question具体的使用过程，讯飞有着完整的文档。详情点击这里下面我就说一下，我使用的时候，出现的问题。 1. 讯飞白名单。讯飞听写，需要为每个 ip 地址设置白名单，大约 5 分钟左右生效，所以，你刚开始提交请求是没有任何作用的。 2. 提交格式提交的 url 中，需要在 url 里 附加音频文件的 base64 转码后的文字。 3. 文件格式这里涉及到 录音文件的转码格式。录音文件要求是 wav, 或者 pcmios 系统的录音在高质量的情况下，默认是 wav 格式的。但是还有一个需要满足的条件是 采样率为 16000 hz但是 ios 的录音文件默认是 48000 hz ， 并且只能是通过开发 app 的时候修改，所以无法满足相应的条件。 Answer上面的第三点问题，我有想过抓取 讯飞听见 的包，看看他调用的 api 是什么，进行一些相应的改动。但是考虑到 一些问题，先留下思路，之后可以尝试改变一下。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killDev</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killBase系列 -- UML 图入门]]></title>
    <url>%2Fblogs%2Fa3184c4f.html</url>
    <content type="text"><![CDATA[UML 类 UML 的多重性修饰123450..* 0 个到多个* 0 个到多个1..* 1 个到多个6 刚好 6 个3，6 3 个或 6 个 UML 类间关系 继承 实现 依赖可以简单的理解，就是一个类A使用到了另一个类B，而这种使用关系是具有偶然性的、、临时性的、非常弱的，但是B类的变化会影响到A；比如某人要过河，需要借用一条船，此时人与船之间的关系就是依赖；表现在代码层面，为类B作为参数被类A在某个method方法中使用； 关联他体现的是两个类、或者类与接口之间语义级别的一种强依赖关系，比如我和我的朋友；这种关系比依赖更强、不存在依赖关系的偶然性、关系也不是临时性的，一般是长期性的，而且双方的关系一般是平等的、关联可以是单向、双向的；表现在代码层面，为被关联类B以类属性的形式出现在关联类A中，也可能是关联类A引用了一个类型为被关联类B的全局变量； 聚合聚合是关联关系的一种特例，他体现的是整体与部分、拥有的关系，即has-a的关系，此时整体与部分之间是可分离的，他们可以具有各自的生命周期，部分可以属于多个整体对象，也可以为多个整体对象共享；比如计算机与CPU、公司与员工的关系等；表现在代码层面，和关联关系是一致的，只能从语义级别来区分； 组合组合也是关联关系的一种特例，他体现的是一种contains-a的关系，这种关系比聚合更强，也称为强聚合；他同样体现整体与部分间的关系，但此时整体与部分是不可分的，整体的生命周期结束也就意味着部分的生命周期结束；比如你和你的大脑；表现在代码层面，和关联关系是一致的，只能从语义级别来区分； 强弱程度 ： 组合&gt;聚合&gt;关联&gt;依赖 UML 时序图 UML 状态图状态是用圆角矩形表示。这个矩形可以有两个分隔栏。顶部分隔栏是对状态进行命名。底部分隔栏是状态的内部迁移。 使用 事件名/动作 表示可以有两个特殊的事件，进入 – entry , 退出 – exit]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tool -- ios 中 url scheme 的使用]]></title>
    <url>%2Fblogs%2F1d89bf34.html</url>
    <content type="text"><![CDATA[由于自己最近从 android 叛变到了 ios 的阵营，所以，用了一天的时间来琢磨相关的效率工具，提高自己的工作效率。作为一个程序员，那必须好好的折腾下，才合适。终于在我的不懈努力（折腾下），找到了一个 名词 url scheme。url scheme 是 ios 系统下，快捷启动应用与功能的一种方式。有关于 url scheme 的介绍可以从这类找 不越狱寻找基本 url scheme 的方法在网上找了很多，但是都不符合自己的要求，不是要越狱，就是因为 ios11 的发布，所以不再合适这个版本。大致有以下几种： 通过 Retriever —— 快速查 URL Scheme这是由 pin 的作者开发的，但是不适用于 ios 11. 通过 lcp – launch center pro 进行自动查找，因为不是认为控制的，所以不能保证可以得到自己想要的工具。 使用 Itunes 安装应用，查找应用的安装包，然后进行解压，查找相应的 info.plist. Itunes 已经不再支持安装应用。 通过自己对查找 url scheme 的了解，找到了一种方式，就是下载 越狱应用， 然后解压。过程如下。第一步、 安装电脑板 pp 助手第二步、 点击 找应用 -》 越狱应用 -》 搜索应用名 -》 直接安装tips: 这一步好像会提示让你连接手机，不要连接，再说一次，不要连接，直接安装即可。第三步、 正常解压缩 .ipa 文件第四步、 打开 .\paload\*.app\info.plist 文件，搜索 urlschemes 如下图，可以找到 weixin , weixinapp 等，这些就是 基本 url scheme 寻找复杂 url scheme 是从官网找，一般为了方便用户的使用，官网上会有相应的介绍。 是联系客服，尝试获取，我使用的 app 比较小众，所以正在尝试和客服沟通 ， 😰。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[book -- growth hacker]]></title>
    <url>%2Fblogs%2F55cdb191.html</url>
    <content type="text"><![CDATA[通过阅读一本书，拓宽自己的知识面，是一件非常有趣的事情呢。 增长黑客的介绍增长黑客 ：以数据驱动营销，以市场指导产品，通过技术化手段观察增长目标的人。 这里的技术化手段包括但不限于 A/B测试， 搜索引擎优化， 电子邮件召回， 病毒应i笑傲。 目标指 页面加载速度， 注册转化率， 电子邮件到达水品。 增长目标 – AARRR Acquisition – 获取用户 Activation – 激发活跃 Retention – 提高留存 Revenue – 增加收入 Referral – 传播推荐。 合格的特质： 数据为王 专注目标 专注细节 富于创意 信息通透总结：以大量的数据为基础，通过数据分析， – 数据为王来找到提高用户黏性，优化用户体验的方法，并且在这个复杂且单调的过程中，不断的挖掘新鲜且高效的方法， – 专注目标，富于创意。时刻关注那些可能存在的细节问题，并随时准备优化解决， – 专注细节还要具备一个宏观的市场角度来看待产品的发展， – 信息通透从而达到产品的提升。 数据分析一切用数据说话 分析的目的。 数据来源的正确。 分析的方法： 定性分析 定量分析 分析工具 Google Analytics Mixpanel KissMetrics UserCycle 统计分析（Trends）和用户分组（Cohorts） 生命周期维护(Lifecycle Messaging) 分组实验测试(Split-Test Experiments) Customer.io – 邮件互动 Optimize.ly – A/B Basecamp – 项目管理软件 友盟统计分析平台 – 国内的移动应用统计分析平台sum: 1-4 是获取分析指标， 5-9 是分析数据， 10 是统一管理项目的平台， 11 是主攻移动应用方面。 分析需求： 需求需要雪中送炭 刚需竞争激烈，但是可以减少前期的风险以及后期推广阻力。 需求量的研究问题 估计目标用户的基数，消费能力，预算然后将这些数字相乘并与行业的公开报告进行比对验证。 评估市场的产值，然后通过更低的价格，更长的使用周期，从而提升效率，节省成本，最后折算出相对于原产值的全新规模 相关的概念介绍产品设计阶段PMF (Product/Market Fit) 产品与市场契合：这是一个目标，为了达成这个目标需要的是从早期用户那里获得反馈，并且持续的以低成本改进产品。 MVP (Minimum Viable Product) 最小化可行产品 最小化可行产品： 将产品原型用最简洁的方式开发出来，过滤掉冗余的杂音和高级特性。推荐使用微信小程序 用户反馈： 从早期客户的上手使用中，得到相关的优化反馈。 快速迭代：结合反馈，迅速优化产品sum： 这样的优势在于前期的投入小，可以快速获得可沉淀的用户数据，劣势在于后期的转型比较麻烦，因为通过这种方式获得的用户，大都是因为前期参与了产品的迭代过程，每一次的更进都会让他们觉得自己在这个产品的生命周期中起到了至关重要的作用，然而当量大的时候，这种方式必然不在可取，因此如何进行这个方向的迭代是下一个要考虑的问题。 A/B 测试：简单来说 非 A 即 B 。 因为一个产品设计的时候，备选方案可能模棱两可，所以如何选择成为一个问题。通过 A/B 测试， 让用户选择自己喜欢的方案，从而让一切简单化。 提供两个方案并行测试 不同方案之间只存在一个变量。 有损服务刻意输出在品质上存在某些损失的服务。这是一种产品能力与用户需求之间的平衡与博弈。note: 这里最优秀的例子是 ov 大厂。oppo,vivo 的研究院都几千人，研究的一样是这个世界最先进最前沿的技术，然而他们并不会将之运用到自己的产品上，或者说完全运用到自己的产品上。这就是他们对自己的产品以及用户的定位有一个清晰的规划。这种对技术的妥协，也是一种意义上的有损服务。 产品传播阶段病毒式传播 K 因子 – K factor = 感染率*转化率 ， 换句话说 1 个 K银子等于平均 1 个用户能带来的 1 个新用户 病毒循环周期 – Virial Cycle Time 用户从发出病毒邀请，到新用户完成转化所需时间。利用的心理： 喜欢 逐利，互惠：天下熙熙皆为利来，天下攘攘皆为利往 害怕错过：同样是利用利益的心理，将两种方式差异化，一个需要付费，一个免费但需要传播信息。 求助： 游戏中的体力槽机制，往往可以通过朋友的赠送补满 炫耀： 爱炫耀是人内心渴求被关注的一种外在现象，并且在某种深层的程度上来讲，可以产生权力的幻觉，让身处竞争的个体感觉更好。 稀缺： 懒惰： 这应该是优化产品体验的一种方法，借助于社交工具，一键分享或者一键登陆等。提高用户体验。 留存与流失流失的原因： 程序漏洞，性能瓶颈 用户在产品变现的过程中感到的反感 话题产品热度的衰减 更好的替代品 留存率的常用指标： 次日留存率 – 产品新版本的品质变动与渠道的优势 7日留存 – 完整体验周期的去留状况 30日留存 – 版本迭代后的稳定性。判断产品的演进方式是否合理。 唤醒机制为找回流失的用户而设计的产品机制。 邮件唤醒： EDM(Email DirectMarketing , 电子邮件直接营销) 消息推送通知 移动网页唤醒应用 流量变现重定向广告针对已经浏览过网站的人群进行再次营销的广告方式，让用户曾经看过的广告再次展示在其面前，通过这种不断的提醒来强化品牌印象，最终促成消费行为code: 在网站上插入一段追踪代码，当用户进入该页面后，代码将会在他们的电脑里植入一个 cookie , 它会标记出用户身份和感兴趣的商品信息，当这个用户访问其他网站时，只要该网站加入了重定向广告联盟，就有资格读取出 cookie 中记录的用户身份和商品信息，从而将动态的广告位替换成用户感兴趣的商品广告。 经济学名词边际成本 (marginal cost) ：厂商每增加一单位产量所增加的成本 ($\frac{\Delta TC}{\Delta Q}$) 在经济学和金融学中，边际成本（marginal cost）指的是每一单位新增生产的产品（或者购买的产品）带来到总成本的增量。 这个概念表明每一单位的产品的成本与总产品量有关。比如，仅生产一辆汽车的成本是极其巨大的，而生产第101辆汽车的成本就低得多，而生产第10000汽车的成本就更低了（这是因为规模经济）。 但是，考虑到机会成本，随着生产量的增加，边际成本可能会增加。还是这个例子，生产新的一辆汽车时，所用的材料可能有更好的用处，所以要尽量用最少的材料生产出最多的车，这样才能提高边际收益。]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[tool -- hexo 博客搭建教程进阶]]></title>
    <url>%2Fblogs%2F804c9fef.html</url>
    <content type="text"><![CDATA[1. 前言因为要使用 hexo 搭建个人博客，而自己作为一个 code 路上的初学者，必然要对这么有趣的项目进行一些分析。掌握一些进阶的手段，才算是一个合格的 coder 。 2. 独立域名作为一名程序员，必须有自己的域名，才算帅。下面就让我从最简单的方式一步步教大家注册域名。包括 SSL ， CDN 等等 一站式配齐。注： 以下所有的方式都是以 github pages 为准。 2.0 基本概念 名词介绍： 域名提供商 ： 在哪里购买，即哪里是域名提供商。 域名解析商 ： 提供 nameserver 服务器的厂家。 dns解析 : 请参看我的 killWeb – dns 介绍 流程简介： 首先是购买域名 – namesilo 然后是域名解析 – cloudflare 最后是上传 cname 2.1 域名购买可以看 这里的推荐这里选择最便宜的 namesilo 。1、首先点我打开namesilo网站， 注册一个账户。然后继续填写相关信息，因为大家都是在国内使用，所以尽量如实填写2、登陆刚创建的账户，在domain search框中输入你想买的域名，点击search。3、选中你要买的域名后缀，点击REGISTER CHECKED DOMAINS进行注册。4、进入购买页面，设置隐私保护和购买几年，在promotion code输入优惠码 vpsss，点submit即可优惠1USD。com域名默认8.99USD，使用优惠码之后变成7.99USD，设置完了以后点击continue。。5、进入到付款页面，有多种付款方式可以选择，我们使用最方便的是支付宝，选择支付宝输入支付宝账号，点击GO就跳转到支付宝付款页面，付款后会自动跳转到namesilo注册成功提示页面，稍后你的注册邮箱会收到namesilo的邮件。 2.2 域名解析这里选择免费的 cloudflare 。自带 ssl, cdn , 并且可以抵御 ddos 攻击。1、 打开 cloudflare 官方网站 进行注册2、 注册成功，可以登陆打开控制台3、 选择 DNS, 然后等待导入 dns 记录，这里正常情况下，你是只有几个 namesilo 自带的 dns 记录的，可以直接将所有的 dns 记录删去。然后添加两个 cname 记录。 一个是 3dot141.com , 指向 3dot141.github.io 一个是 www , 指向 3dot141.github.iocname 记录与其他记录的区别，可以看我博客里的 killWeb – dns 介绍4、 回到 namesilo ， 更改域名解析商 nameserver这里的域名服务器 与 cloudflare 提供的一致。5、 回到 本地的 blog 文件夹， 在 blog/source 下，新建一个 cname 文件。如下图写入 3dot141.com, 然后保存，上传。 2.3 开启 ssl1、 点击进入 Crypto2、 等待状态的转化刚注册的域名不是这样的状态， 大约要等待 1 小时左右，才会成为激活状态。至于选择什么样的 方式， 这里有 full, flexible, full(strict) 三种可选，推荐 full ，一劳永逸。 2.4 优化速度1、 开启 cdn在 dns 下，可以看到 橘红色的 云标志，代表 cdn 开启。 灰色云标志，代表 cdn 关闭。2、 开启 js,css,html 文件压缩在 speed 下，可以看到第一个 Auto Minify. 点选全部3、 开启 Enable Accelerated Mobile Links同样是 speed 下，可以看到 如下图， 开启后，可以加快 手机端的访问速度。 3. 搜索优化其他的我就不多讲了， next 主题的网站上基本都有，我说一些，网站没有的东西。 3.1 seo优化SEO是由英文Search Engine Optimization缩写而来， 中文意译为“搜索引擎优化”。SEO是指通过站内优化比如网站结构调整、网站内容建设、网站代码优化等以及站外优化。 3.2 谷歌优化3.2.1 收录网页登陆 google 站点平台1、 先添加网站2、 然后按照步骤操作即可。首先下载文件，然后将文件放入 \blog\source\ 中。然后 部署 hexo ,将文件上传至 github page 中，等待几分钟，访问相关的网站进行确认。这里有个问题是，需要在文件中，加入以下代码1234---layout: false---google-site-verification: google82820b77d14c3755.htm google-site-verification….是原先文件中的内容，要加入 layout:false 才能够不被再次编译成 hexo 静态网页。3、 验证成功。等待收录即可，一般在一天左右。 3.2.2 提交站点安装sitemap 插件1npm install hexo-generator-sitemap --save 然后重新部署，会生成相应的 sitemap.xml 文件。 将生成的 sitemap.xml 文件加入 google 站点工具中。 3.3 百度优化github 不允许百度的爬虫，所以如果使用 github 上是不会被百度收录，所以百度优化这一部分，我就放弃了，因为本身，我这个博客的属性，只是对我知识的一个总结。太多的东西，只会增加我的负担。 注： 其实，这个也是有解决办法的，不过需要使用多线路解析，然后同时部署 coding 与 github。 然后对 coding 进行优化，这一部分的内容，之后我会进行说明。 3.4 url优化seo搜索引擎优化认为，网站的最佳结构是用户从首页点击三次就可以到达任何一个页面，但是我们使用hexo编译的站点打开文章的url是：sitename/year/mounth/day/title四层的结构，这样的url结构很不利于seo，爬虫就会经常爬不到我们的文章，所以我们可以修改我们的 url 连接。 安装 插件 1npm install hexo-abbrlink --save 在站点配置文件中查找 permalink, 更改为 1permalink: blogs/:abbrlink.html 在站点配置文件中添加如下代码： 1234# abbrlink configabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 可选择模式： 1234crc16 &amp; hexcrc16 &amp; deccrc32 &amp; hexcrc32 &amp; dec 4. 个性优化关于一些简单的东西，比如访问次数，字数统计等等简单的插件使用，next 官网上都有详细的教程，我就不献丑了。 4.1 点击桃心效果在网址输入如下1http://7u2ss1.com1.z0.glb.clouddn.com/love.js 然后将里面的代码copy一下，新建love.js文件并且将代码复制进去，然后保存。将love.js文件放到路径/themes/next/source/js/src里面，然后打开\themes\next\layout_layout.swig文件,在末尾（在前面引用会出现找不到的bug）添加以下代码：12&lt;!-- 页面点击小红心 --&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/love.js&quot;&gt;&lt;/script&gt; 4.2 文章加密访问打开themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,在以下位置插入这样一段代码：12345678910&lt;script&gt; (function()&#123; if(&apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; if (prompt(&apos;请输入文章密码&apos;) !== &apos;&#123;&#123; page.password &#125;&#125;&apos;)&#123; alert(&apos;密码错误！&apos;); history.back(); &#125; &#125; &#125;)();&lt;/script&gt; 然后在文章上写成类似这样： 4.3 Daovoice 匿名沟通首先在 daovoice 注册账号,邀请码是0f81ff2f,注册完成后会得到一个 app_id :记下这个 app_id的值，然后打开/themes/next/layout/_partials/head.swig,写下如下代码：123456789&#123;% if theme.daovoice %&#125; &lt;script&gt; (function(i,s,o,g,r,a,m)&#123;i[&quot;DaoVoiceObject&quot;]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=&quot;utf-8&quot;;m.parentNode.insertBefore(a,m)&#125;)(window,document,&quot;script&quot;,(&apos;https:&apos; == document.location.protocol ? &apos;https:&apos; : &apos;http:&apos;) + &quot;//widget.daovoice.io/widget/0f81ff2f.js&quot;,&quot;daovoice&quot;) daovoice(&apos;init&apos;, &#123; app_id: &quot;&#123;&#123;theme.daovoice_app_id&#125;&#125;&quot; &#125;); daovoice(&apos;update&apos;); &lt;/script&gt;&#123;% endif %&#125; 接着打开主题配置文件，在最后写下如下代码：123# Online contact daovoice: truedaovoice_app_id: 这里填你的刚才获得的 app_id 重新 hexo g ，hexo s 就能看到效果了。安装成功后可以在DaoVoice 控制台上的聊天设置里设置聊天窗口样式，附上我的设置 4.4 妙传图片至七牛云秒传图片到七牛云并展现在博客中在markdown中写blog的朋友，想必这点是最烦恼的吧，一般来说都要手动上传图片到七牛云，再把链接写到markdown中。逛了逛社区，有人用phthon实现一个自动上传的脚本，但是我觉得还不是特别方便，这时在github上找到一个一键贴图工具qiniu-image-tool，它支持本地文件、截图、网络图片一键上传七牛云并返回图片引用。Mac 是基于 Alfred 的，其 windows 也有相应版本windows版本。 按照其要求配置好以后，用截图软件截图后，或者本地图片后 copy，然后直接按设置好的 command+option+v，然后在图片成功上传到七牛云图床上，剪贴板上也有相应的连接。 4.5 多终端编辑 上传 删除主题下的 .git 文件, 以我为例，就是 themes/next/.git 创建分支 hexo 并切换为默认 编辑目录下的 .gitignore 文件。 回到 blog 的源文件目录下， git init git add -A git commit -m &quot;hexo source code&quot; git branch hexo git remote add origin git@github.com:3dot141/3Dot141.github.io.git 注意，这里把相应自己的 远程仓库 地址输入即可。 git push origin hexo -f 下载 先下载 node.js , 然后安装 hexo git hexo 源码。 编辑，之后再次上传即可。 不要忘了将修改后的源码再次上传。 5. 总结 修改外观样式themes/next/layout/*/*.swig 添加 js在 themes/next/source/js/src/*/*.js 添加 js 文件，然后在 themes/next/layout/_layout.swig 中加入 标签。 添加 css在 thems/next/sorce/css/_custom/custom.styl 中加入相关 css 语法。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[tool -- hexo 博客搭建教程入门]]></title>
    <url>%2Fblogs%2F32551.html</url>
    <content type="text"><![CDATA[1. 前言作为一个很喜欢整理知识的人，我特别希望能将自己写的一些东西，发布出去，通过云端保存，并且方便我随时随地查看。所以，当各大博客并不能完全满足我的需求时，我选择自己搭建一个博客，去整理自己所学。 在通过对各种建站方式的比较后，终于决定选择使用 hexo 作为我的个人博客。 2. 分析优点： 不需要投资，地址免费 流程简单 使用方便 使用 npm , git , hexo (node.js) ,markdown 操作。对我这个码农来说，很适用。缺点： 同步比较慢 不容易被搜索引擎收录 自己掌握备份 3. 流程1. 配置 Github注册，登录 github 记住自己的账号名 我的账号名 是 3dot141 创建一个新的仓库 注意： 这里因为我的名字 是 3dot141 ,所以我建了一个 3dot141.github.io 的仓库。 完成这一步后， Github 的部分暂时完成了 2. 环境配置这里要配置两个环境： node.js git 1. node.js直接下载安装即可。下面是地址https://nodejs.org/zh-cn/ 推荐使用 LTS 版 2. git因为国内获取 git ，需要科学上网。所以这里有一个国内的下载站，方便大家下载。 感谢大佬。 Git for Windows 国内下载站 然后使用cmder ， 一个windows 上的神器，进行 git 配置 12git config --global user.name &quot;这里是你自己的用户名 -- 以我为例 -- 3dot141&quot;git config --global user.email &quot;这里是你自己的注册邮箱 -- ..@gmail.com&quot; 如果觉得这样不好操作，可以到自己的c/users/你自己使用的用户下/.gitconfig打开后操作如下图 这里的 core 与 http \ https 留着下面再讲。。。 打开cmder,输入：1ssh-keygen -t rsa -C &quot;Github的注册邮箱地址 -- ..@gmail.com&quot; 然后直接一路确定，最后得到信息1Your public key has been saved in c/Users/你的用户/.ssh/id_rsa.pub. 打开该文件，Ctrl+a,Ctrl+c,v, 复制所有内容。 进入 github然后一路往下操作 使用 cmder , 安装 hexo 。 1npm install -g hexo-cli 可能会有警告，无视即可。 初始化进入自己想 存储的地址， 比如 f:/myblog然后右键打开 cmder 输入1hexo init blog 直至出现 ，1INFO Start blogging with Hexo! 然后就继续输入1234567# 因为你初始化hexo 之后source目录下自带一篇hello world文章, 所以直接执行下方命令$ hexo generate# 启动本地服务器$ hexo server# 在浏览器输入 http://localhost:4000/就可以看见网页和模板了INFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 在浏览器中输入localhost:4000 下面就是见证奇迹的时刻]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mood -- 180331]]></title>
    <url>%2Fblogs%2Ffcb82e9d.html</url>
    <content type="text"><![CDATA[不知不觉就已经到了三月的最后一天。从我外出实习，到现在也已经有了不短的时间。想讲的很多，就将这第一次的体验，写成文字，为自己记录这一段回不去的时光。 第一次真正的入职。经过自己一年多的努力，在去年10月中旬，得到了公司的 offer ，因为学校的课程比较满，所以一直没有时间进行入职考核，而现在终于能够进入公司，感受文化，氛围，成为一颗小齿轮⚙️，参与到一家优秀的公司的日常运转中。考核，必然是辛苦的，这一点当初的 hr 已经打过预防针， 说每天都要工作到 10 点钟之类的。 事实也是如此，每天 7点半 醒来， 8点半到公司， 开电脑， 开始汲取与考核相关的各个方面的知识。 10 点半回去， 然后再处理一下毕设的事情，12点左右才能躺在宾馆的床上， 真正的放松一下。这种精神的高度紧张，即便是在高考的时候，也是没有过的，更何况持续了十多天之久。累，辛苦，抱怨，怀疑，这些都是有的，但是，相比较这些，我更庆幸的是自己坚持下来了。在一个极度压缩的时间里，将考核完成，并且较之一般还稍好一点。这让我一个半路出家的初级 coder 建立了稍许自信，我，不比别人差。他们虽然多是名校毕业，但是，无论是学习能力，还是已经掌握的知识广度深度，我都比他们更胜一筹。这已经是对我的最大肯定。毕竟，当时我知道他们是南京大学之类的名校时，心里是有些许自卑的。自己的出身和他们相比，却是稍差。一个是985顶尖高校的科班毕业生，一个只不过211垫底学校的一名非科班学生。能得到这样的结果，我想，算是对自己的大学生活交出一份差强人意的答卷。除了工作上的收获，我还拥有了几份友谊，也是因缘际会吧。一见如故，相谈甚欢。这也对我在异乡的生活增添了一些不一样的韵味。幸福并感激着。 第一次带着同学游览家乡。付同学是我的室友，一年考研，成绩不尽人意，在调剂的过程中，机缘巧合来到了徐州。也是巧合，我当时刚完成考核回到家。当他告诉我，自己这是最后一次的尝试时，我明白，他现在的内心是非常疲惫的。一个人独自面对这个世界的压力，孤独和无力会是一根针，时时刺痛稚嫩的内心。这种感觉，我懂，也知道这个时候，他最需要的就是陪伴，不需要说多少话，不需要做多少事，只要身边有一个人，自己熟悉的人，然后心里就有了依靠，就不会在前进路上倒下，就不会被四面八方的陌生戳伤，毕竟，身后有着一个人，陪伴着你。因此，虽然从家里到市区需要大巴 2 个小时， 不过我还是当下背着包出发了。一天半的陪伴，可能不算什么，但是对于我来说，已经是强打着精神，撑下来的。结果也是满意的，昨天他说，自己被徐州某不知名高校录取了。我想，这对他来说，意义重大吧。毕竟，在荒漠里能够开出一朵娇艳的花🌹，总归是令人惊艳的。希望，这段宝贵的回忆，能够沉成一段经年不散的酒香，这样，对我来说，也会感受到温暖吖，哈哈。你以为这样就完了？不，从这件事中，我最开心的是身边的朋友，人或事，都在不断的前行，不管道途多崎岖，都一往无前。与优秀的人共事，才能让自己成为更好的自己。 第一次北上北京。应朋友的邀请，陪他一起去北京游玩。现在的自己正在前往北京的高铁上，记录下这三月的行程，路途未完，静待佳缘。]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ArithMagic -- 00]]></title>
    <url>%2Fblogs%2F29483.html</url>
    <content type="text"><![CDATA[前言在知乎上看到一道很有趣的题目，看有各种版本，但是没有 java 版，所以就自己写了一份。 代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316public class Main &#123; private boolean q1(int[] is)&#123; return true; &#125; private boolean q2(int[] is) &#123; switch (is[2]) &#123; case 65: is[5] = 67; break; case 66: is[5] = 68; break; case 67: is[5]=65; break; case 68: is[5]=66; break; &#125; return true; &#125; private boolean q3( int[] is) &#123; if (is[3] == 65) &#123; return (is[3]!=is[6])&amp;&amp;(is[3]!=is[2])&amp;&amp;(is[3]!=is[4]); &#125; if (is[3] == 66) &#123; return (is[6]!=is[3])&amp;&amp;(is[6]!=is[2])&amp;&amp;(is[6]!=is[4]); &#125; if (is[3] == 67) &#123; return (is[2]!=is[3])&amp;&amp;(is[2]!=is[6])&amp;&amp;(is[2]!=is[4]); &#125; if (is[3] == 68) &#123; return (is[4]!=is[3])&amp;&amp;(is[4]!=is[6])&amp;&amp;(is[4]!=is[2]); &#125; return false; &#125; private boolean q4( int[] is) &#123; if (is[4] == 65) &#123; if (is[1] == is[5]) &#123; return true; &#125; &#125; if (is[4]== 66) &#123; if (is[2] == is[7]) &#123; return true; &#125; &#125; if (is[4] == 67) &#123; if (is[1] == is[9]) &#123; return true; &#125; &#125; if (is[4] == 67) &#123; if (is[6] == is[10]) &#123; return true; &#125; &#125; return false; &#125; private boolean q5( int[] is) &#123; if (is[5] == 65) &#123; if (is[8] == is[5]) &#123; return true; &#125; &#125; if (is[5] == 66) &#123; if (is[4] == is[5]) &#123; return true; &#125; &#125; if (is[5] == 67) &#123; if (is[9] == is[5]) &#123; return true; &#125; &#125; if (is[5] == 67) &#123; if (is[7] == is[5]) &#123; return true; &#125; &#125; return false; &#125; //i=is[i] private boolean q6( int[] is) &#123; if (is[6] == 65) &#123; if (is[8] == is[2]&amp;&amp;is[8]==is[4]) &#123; return true; &#125; &#125; if (is[6] == 66) &#123; if (is[8] == is[1]&amp;&amp;is[8]==is[6]) &#123; return true; &#125; &#125; if (is[6] == 67) &#123; if (is[8] == is[3]&amp;&amp;is[10]==is[8]) &#123; return true; &#125; &#125; if (is[6] == 67) &#123; if (is[8] == is[5]||is[8]==is[9]) &#123; return true; &#125; &#125; return false; &#125; private boolean q7( int[] is) &#123; int na=0;int nb=0;int nc=0;int nd=0; for (int i1 : is) &#123; if(i1==65)&#123; na++; &#125; if (i1 == 66) &#123; nb++; &#125; if (i1 == 67) &#123; nc++; &#125; if (i1 == 68) &#123; nd++; &#125; &#125; int min = Math.min(Math.min(Math.min(na, nb), nc), nd); if (min == na) &#123; if (is[7] == 67) &#123; return true; &#125; return false; &#125; if(min==nb)&#123; if (is[7] == 66) &#123; return true; &#125; return false; &#125; if (min == nc) &#123; if (is[7] == 65) &#123; return true; &#125; return false; &#125; if (min == nd) &#123; if (is[7] == 68) &#123; return true; &#125; return false; &#125; return false; &#125; private boolean q8( int[] is) &#123; if(Math.abs(is[1]-is[7])&gt;0)&#123; if (is[8] == 65) &#123; return true; &#125; &#125; if(Math.abs(is[1]-is[5])&gt;0) &#123; if (is[8] == 66) &#123; return true; &#125; &#125; if(Math.abs(is[1]-is[2])&gt;0) &#123; if (is[8] == 67) &#123; return true; &#125; &#125; if(Math.abs(is[1]-is[10])&gt;0) &#123; if (is[8] == 68) &#123; return true; &#125; &#125; return false; &#125; private boolean q9( int[] is) &#123; if (is[1] == is[6]) &#123; if (is[9] == 65) &#123; if (is[5] != is[6]) &#123; return true; &#125; &#125; if (is[9] == 66) &#123; if (is[5] != is[10]) &#123; return true; &#125; &#125; if (is[9] == 67) &#123; if (is[5] != is[2]) &#123; return true; &#125; &#125; if (is[9] == 68) &#123; if (is[5] != is[9]) &#123; return true; &#125; &#125; &#125;else&#123; if (is[9] == 65) &#123; if (is[5] == is[6]) &#123; return true; &#125; &#125; if (is[9] == 66) &#123; if (is[5] == is[10]) &#123; return true; &#125; &#125; if (is[9] == 67) &#123; if (is[5] == is[2]) &#123; return true; &#125; &#125; if (is[9] == 68) &#123; if (is[5] == is[9]) &#123; return true; &#125; &#125; &#125; return false; &#125; private boolean q10( int[] is) &#123; int na=0;int nb=0;int nc=0;int nd=0; for (int i1 : is) &#123; if(i1==65)&#123; na++; &#125; if (i1 == 66) &#123; nb++; &#125; if (i1 == 67) &#123; nc++; &#125; if (i1 == 68) &#123; nd++; &#125; &#125; int min = Math.min(Math.min(Math.min(na, nb), nc), nd); int max = Math.max(Math.max(Math.max(na, nb), nc), nd); int delta = max-min; if (delta == 4) &#123; if (is[10] == 67) &#123; return true; &#125; return false; &#125; if(delta==2)&#123; if (is[10] == 66) &#123; return true; &#125; return false; &#125; if (delta==3) &#123; if (is[10] == 65) &#123; return true; &#125; return false; &#125; if (delta==1) &#123; if (is[10] == 68) &#123; return true; &#125; return false; &#125; return false; &#125; public boolean test(int[] is) &#123; if (q1(is) &amp;&amp; q2(is) &amp;&amp; q3(is) &amp;&amp; q4(is) &amp;&amp; q5(is) &amp;&amp; q6(is) &amp;&amp; q7(is) &amp;&amp; q8(is) &amp;&amp; q9(is) &amp;&amp; q10(is)) &#123; return true; &#125; return false; &#125; public static void main(String[] args) &#123; Main main = new Main(); for (int i = 0; i &lt; 4; i++) &#123; for (int j = 0; j &lt; 4; j++) &#123; for (int k = 0; k &lt; 4; k++) &#123; for (int l = 0; l &lt; 4; l++) &#123; for (int m = 0; m &lt; 4; m++) &#123; for (int n = 0; n &lt; 4; n++) &#123; for (int o = 0; o &lt; 4; o++) &#123; for (int p = 0; p &lt; 4; p++) &#123; for (int q = 0; q &lt; 4; q++) &#123; for (int r = 0; r &lt;4; r++) &#123; int[] is = &#123;0,i+65,j+65,k+65,l+65,m+65,n+65,o+65,p+65,q+65,r+65&#125;; if (main.test(is)) &#123; for (int i1 : is) &#123; System.out.print((char) i1); &#125; return ; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>arithmatic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 整合 RedisCache]]></title>
    <url>%2Fblogs%2F20329.html</url>
    <content type="text"><![CDATA[前言springboot 2.0 后，在与 RedisCache 的整合部分有一些改变，网上的文章很少，所以自己查阅官方的 api 以及 源码，花费两天的时间，做好了总结 依赖1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; CachingConfigSupport继承 CachingConfigSupport 类，然后重写 cacheManager 与 keyGenerator . 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@Configuration@EnableCachingpublic class MyConfig extends CachingConfigurerSupport &#123; @Value("$&#123;spring.redis.host&#125;") private String host; @Value("$&#123;spring.redis.port&#125;") private String port; @Bean public RedisStandaloneConfiguration getRedisClient() &#123; RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(host, Integer.parseInt(port)); return redisStandaloneConfiguration; &#125; @Bean public JedisConnectionFactory redisConnectionFactory(RedisStandaloneConfiguration RedisStandaloneConfiguration) &#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(RedisStandaloneConfiguration); return jedisConnectionFactory; &#125; @Bean public RedisTemplate&lt;String, String&gt; redisTemplate(RedisConnectionFactory cf) &#123; RedisTemplate&lt;String, String&gt; redisTemplate = new RedisTemplate&lt;String, String&gt;(); redisTemplate.setConnectionFactory(cf); return redisTemplate; &#125; @Bean public CacheManager cacheManager(RedisConnectionFactory cf) &#123; //RedisCacheWriter redisCacheWriter = RedisCacheWriter.nonLockingRedisCacheWriter(cf); //RedisCacheManager cacheManager = new RedisCacheManager(redisCacheWriter, RedisCacheConfiguration.defaultCacheConfig()); RedisCacheManager cm = RedisCacheManager.builder(cf) .cacheDefaults(RedisCacheConfiguration.defaultCacheConfig() .serializeValuesWith( RedisSerializationContext.SerializationPair .fromSerializer(new StringRedisSerializer()))).build(); return cm; &#125; @Bean public KeyGenerator keyGenerator() &#123; return new KeyGenerator() &#123; @Override public Object generate(Object o, Method method, Object... objects) &#123; StringBuilder sb = new StringBuilder(); sb.append(o.getClass().getName()); sb.append(method.getName()); for (Object obj : objects) &#123; sb.append(obj.toString()); &#125; System.out.println(sb.toString()); return sb.toString(); &#125; &#125;; &#125;&#125; CacheManger初始化 CacheManager 类有三种方法 12345678910111213141516// 最简单RedisCacheManager.create(connectionFactory);// 构造器![](http://ovmspkp0s.bkt.clouddn.com/201803071038_489.png)/* 推荐方法 */RedisCacheManager.builder(RedisCacheWriter.lockingRedisCacheWriter()) .cacheDefaults(defaultCacheConfig()) .build();RedisCacheManager cm = RedisCacheManager.builder(connectionFactory) .cacheDefaults(defaultCacheConfig()) .initialCacheConfigurations(singletonMap("predefined", defaultCacheConfig().disableCachingNullValues())) .transactionAware() .build(); ConnectionFactory上面每一种方法 ， 都需要用到 ConnectionFactory 类。所以，这里先介绍 ConnectionFactory 类。 如图所示 ， 上面涉及到了 5 个相关类分别为123456789JedisClientConfigurationJedisPoolConfigRedisStadaloneConfigurationRedisClusterConfigurationRedisSentinelConfiguration JedisClientConfiguration相关 方法 如下 可以看出这个类可以设置 poolConfig , ssl , hostnameVerifier 等与客户端连接的基本属性。因为设置了 poolConfig ，所以可以在做参数时，代替 JedisPoolConfig JedisPoolConfig一些 关于 连接池的 相关信息。 三种基本配置RedisStadaloneConfiguration用于 单个 redisStadaloneConfiguration 连接 RedisClusterConfiguration用于 redis 集群连接 RedisSentinelConfiguration用于 哨兵 模式的连接 进阶配置 之后再写。 默认设置通过 RedisCacheManager.create(connectionFactory) 得出的最简单的设置为RedisCacheManager defaults Setting Value Cache Writer non locking Cache Configuration RedisCacheConfiguration#defaultConfiguration Initial Caches none Trasaction Aware no Key Expiration none Cache null yes Prefix Keys yes Default Prefix the actual cache name Key Serializer StringRedisSerializer Value Serializer JdkSerializationRedisSerializer Conversion Service DefaultFormattingConversionService with default cache key converters 更改设置1、 第一部分1RedisCacheManager.builder(connectionFactory) --&gt; RedisCacheManagerBuilder 下面是 更改属性 与 相关方法 的映射关系 Setting Value Cache Writer fromCacheWriter Cache Configuration cacheDefaults Initial Caches initialCacheNames withInitialCacheConfigurations Trasaction Aware transactionAware 2、 第二部分这里介绍一下 withInitialCacheConfigurations 方法 1234567891011 public RedisCacheManagerBuilder withInitialCacheConfigurations( Map&lt;String, RedisCacheConfiguration&gt; cacheConfigurations) &#123; Assert.notNull(cacheConfigurations, "CacheConfigurations must not be null!"); cacheConfigurations.forEach((cacheName, configuration) -&gt; Assert.notNull(configuration, String.format("RedisCacheConfiguration for cache %s must not be null!", cacheName))); this.initialCaches.putAll(cacheConfigurations); return this;&#125; 这个方法可以将 cacheName 与 configuration 对应起来，比如 cacheName = “test” defaultConfiguration之后 当遇到 cacheName 为 test 的缓存时，就会默认使用 defaultConfiguration 配置的缓存配置。 3、 第三部分1RedisCacheManagerBuiler.cacheDefaults(RedisCacheConfiguration RedisCacheConfiguration) 这里的 RedisCacheConfiguration 还可以通过 设置 改变下面这些 相关属性 Setting value Key Expiration entryTtl Cache null disableCachingNullValues() Prefix Keys usePrefixe() disableKeyPrefix() Default Prefix prefixKeysWith(String) Key Serializer serializeKeysWith(SerialiazationPair) Value Serializer serializeValuesWith(SerializationPair&lt;?&gt;) Conversion Service withConversionService(ConversionService) 其中 SerializationPair 是一个静态内部类，可以通过 1234RedisSerializationContext .SerializationPair .fromSerializer(RedisSerializer&lt;T&gt;)--&gt; SerialiaztionPair 进行转换 keyGenerator12345678910111213141516@Beanpublic KeyGenerator keyGenerator() &#123; return new KeyGenerator() &#123; @Override public Object generate(Object o, Method method, Object... objects) &#123; StringBuilder sb = new StringBuilder(); sb.append(o.getClass().getName()); sb.append(method.getName()); for (Object obj : objects) &#123; sb.append(obj.toString()); &#125; System.out.println(sb.toString()); return sb.toString(); &#125; &#125;;&#125; 以上这种方式是覆盖默认的 keyGenerator还可以在注解中指定 keyGenerator 进行 key 的生成。 注解 注 解 描 述 @Cacheable 表明Spring在调用方法之前，首先应该在缓存中查找方法的返回值。如果这个值能够找到，就会返回缓存的值。否则的话，这个方法就会被调用，返回值会放到缓存之中 @CachePut 表明Spring应该将方法的返回值放到缓存中。在方法的调用前并不会检查缓存，方法始终都会被调用 @CacheEvict 表明Spring应该在缓存中清除一个或多个条目 @Caching 这是一个分组的注解，能够同时应用多个其他的缓存注解 @CacheConfig 可以在类层级配置一些共用的缓存配置 基础1、 @Cacheable 2、 @CachePut 3、 @CacheEvict 4、 @Caching 5、 @CacheConfig 6、 SPEL 表达式 名字 位置 描述 示例 methodName root对象 当前被调用的方法名 #root.methodName method root对象 当前被调用的方法 #root.method.name target root对象 当前被调用的目标对象 #root.target targetClass root对象 当前被调用的目标对象类 #root.targetClass args root对象 当前被调用的方法的参数列表 #root.args[0] caches root对象 当前方法调用使用的缓存列表（如@Cacheable(value={“cache1”, “cache2”})），则有两个cache #root.caches[0].name argument name 执行上下文 当前被调用的方法的参数，如findById(Long id)，我们可以通过#id拿到参数 #user.id result 执行上下文 方法执行后的返回值（仅当方法执行之后的判断有效，如‘unless’，’cache evict’的beforeInvocation=false） #result SPEL 的相关使用 7、 流程 首先执行@CacheEvict（如果beforeInvocation=true且condition 通过），如果allEntries=true，则清空所有 接着收集@Cacheable（如果condition 通过，且key对应的数据不在缓存），放入cachePutRequests（也就是说如果cachePutRequests为空，则数据在缓存中） 如果cachePutRequests为空且没有@CachePut操作，那么将查找@Cacheable的缓存，否则result=缓存数据（也就是说只要当没有cache put请求时才会查找缓存） 如果没有找到缓存，那么调用实际的API，把结果放入result 如果有@CachePut操作(如果condition 通过)，那么放入cachePutRequests 执行cachePutRequests，将数据写入缓存（unless为空或者unless解析结果为false）； 执行@CacheEvict（如果beforeInvocation=false 且 condition 通过），如果allEntries=true，则清空所有 进阶condition 条件缓存1、根据运行流程，如下 @Cacheable 将在执行方法之前( #result还拿不到返回值)判断condition，如果返回true，则查缓存； 12345678910111213141516@Cacheable(value = "user", key = "#id", condition = "#id lt 10") public User conditionFindById(final Long id) ``` 2、根据运行流程，如下 `@CachePut`将在执行完方法后（#result就能拿到返回值了）判断condition，如果返回true，则放入缓存； ```java@CachePut(value = "user", key = "#id", condition = "#result.username ne 'zhang'") public User conditionSave(final User user) ``` 根据运行流程，如下 `@CachePut`将在执行完方法后（#result就能拿到返回值了）判断unless，如果返回false，则放入缓存；（即跟condition相反）```java@CachePut(value = "user", key = "#user.id", unless = "#result.username eq 'zhang'") public User conditionSave2(final User user) 根据运行流程，如下 @CacheEvict， beforeInvocation=false表示在方法执行之后调用（#result能拿到返回值了）；且判断condition，如果返回true，则移除缓存； 12@CacheEvict(value = "user", key = "#user.id", beforeInvocation = false, condition = "#result.username ne 'zhang'") public User conditionDelete(final User user) 组合注解1、 自定义缓存注解 12345678910111213141516@Caching( put = &#123; @CachePut(value = &quot;user&quot;, key = &quot;#user.id&quot;), @CachePut(value = &quot;user&quot;, key = &quot;#user.username&quot;), @CachePut(value = &quot;user&quot;, key = &quot;#user.email&quot;) &#125; ) @Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;) @Retention(RetentionPolicy.RUNTIME) @Inherited public @interface UserSaveCache &#123; &#125; @UserSaveCache public User save(User user) 2、 SPEL 表达式12345678910111213141516171819202122// Simple Edition@CacheEvict(value = "user", key = "#user.id", condition = "#root.target.canCache() and #root.caches[0].get(#user.id).get().username ne #user.username", beforeInvocation = true) public void conditionUpdate(User user) // + Method @Caching( evict = &#123; @CacheEvict(value = "user", key = "#user.id", condition = "#root.target.canEvict(#root.caches[0], #user.id, #user.username)", beforeInvocation = true) &#125; ) public void conditionUpdate(User user) public boolean canEvict(Cache userCache, Long id, String username) &#123; User cacheUser = userCache.get(id, User.class); if (cacheUser == null) &#123; return false; &#125; return !cacheUser.getUsername().equals(username); &#125; // + Static Method@CacheEvict(value = "user", key = "#user.id", condition = "T(com.sishuok.spring.service.UserCacheHelper).canEvict(#root.caches[0], #user.id, #user.username)", beforeInvocation = true) public void conditionUpdate(User user) 重点 当一个支持缓存的方法在对象内部被调用时是不会触发缓存功能的。 cache:annotation-driven/还可以指定一个mode属性，可选值有proxy和aspectj。默认是使用proxy。当mode为proxy时，只有缓存方法在外部被调用的时候Spring Cache才会发生作用，这也就意味着如果一个缓存方法在其声明对象内部被调用时Spring Cache是不会发生作用的。而mode为aspectj时就不会有这种问题。另外使用proxy时，只有public方法上的@Cacheable等标注才会起作用，如果需要非public方法上的方法也可以使用Spring Cache时把mode设置为aspectj。此外，cache:annotation-driven/还可以指定一个proxy-target-class属性，表示是否要代理class，默认为false。我们前面提到的@Cacheable、@cacheEvict等也可以标注在接口上，这对于基于接口的代理来说是没有什么问题的，但是需要注意的是当我们设置proxy-target-class为true或者mode为aspectj时，是直接基于class进行操作的，定义在接口上的@Cacheable等Cache注解不会被识别到，那对应的Spring Cache也不会起作用了。这里的 cache:annotation-driven/ 等同于 @EnableCaching可以从上图中看到 ， 存在 order , mode , proxytagetclass 属性。 问题1、 注解进行注入时，其 key 为 “ cachenames ( value ) :: key “ , 不知道如何改变。2、 改造 CacheAspectSupport原博客中有关于 CacheAspectSupport 的改造。如下目的：findByUsername时，不应该只放username–&gt;user，应该连同id—&gt;user和email—&gt;user一起放入；这样下次如果按照id查找直接从缓存中就命中。原代码12345678// We only attempt to get a cached result if there are no put requests if (cachePutRequests.isEmpty() &amp;&amp; contexts.get(CachePutOperation.class).isEmpty()) &#123; result = findCachedResult(contexts.get(CacheableOperation.class)); &#125; Collection&lt;CacheOperationContext&gt; cacheOperationContexts = contexts.get(CacheableOperation.class); if (!cacheOperationContexts.isEmpty()) &#123; result = findCachedResult(cacheOperationContexts); &#125; 修改代码123456789101112131415161718@Caching( cacheable = &#123; @Cacheable(value = "user", key = "#username") &#125;, put = &#123; @CachePut(value = "user", key = "#result.id", condition = "#result != null"), @CachePut(value = "user", key = "#result.email", condition = "#result != null") &#125; ) public User findByUsername(final String username) &#123; System.out.println("cache miss, invoke find by username, username:" + username); for (User user : users) &#123; if (user.getUsername().equals(username)) &#123; return user; &#125; &#125; return null; &#125; 但是我并没有查找到如何去修改。有两个想法。 将源码修改，然后直接编译。使用自己编译过的 jar 文件。 继承该接口，然后进行复写，最后被 spring 扫描使用。 第一种应该不是，第二种需要查看源码，然后区分 spring 是如何调用的 CacheAspectSupport ， 是否存在默认的配置文件可以修改。 参考博客http://jinnianshilongnian.iteye.com/blog/2001040http://blog.csdn.net/wjacketcn/article/details/50945887]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killWeb -- 转发重定向以及Session&Cookie]]></title>
    <url>%2Fblogs%2F31584.html</url>
    <content type="text"><![CDATA[转发与重定向的区别转发与重定向的区别如下：转发是服务器行为,重定向是客户端行为 转发在服务器端完成的;重定向是在客户端完成的 转发的速度快;重定向速度慢 转发的是同一次请求;重定向是两次不同请求 转发不会执行转发后的代码;重定向会执行重定向之后的代码 转发地址栏没有变化;重定向地址栏有变化 转发必须是在同一台服务器下完成;重定向可以在不同的服务器下完成 在servlet中调用转发、重定向的语句如下：request.getRequestDispatcher(“new.jsp”).forward(request,response);//转发到new.jspresponse.sendRedirect(“new.jsp”);//重定向到new.jsp 转发过程：客户浏览器发送http请求,web服务器接受此请求,调用内部的一个方法在容器内部完成请求处理和转发动作,将目标资源发送给客户;在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。在客户浏览器路径栏显示的仍然是其第一次访问的路径，也就是说客户是感觉不到服务器做了转发的。转发行为是浏览器只做了一次访问请求。 重定向过程：客户浏览器发送http请求,web服务器接受后发送302状态码响应及对应新的location给客户浏览器,客户浏览器发现是302响应，则自动再发送一个新的http请求，请求url是新的location地址,服务器根据此请求寻找资源并发送给客户。在这里location可以重定向到任意URL，既然是浏览器重新发出了请求，则就没有什么request传递的概念了。在客户浏览器路径栏显示的是其重定向的路径，客户可以观察到地址的变化的。重定向行为是浏览器做了至少两次的访问请求的。第一次，客户端requestA,服务器响应，并response回来，告诉浏览器，你应该去B。这个时候IE可以看到地址变了，而且历史的回退按钮也亮了。重定向可以访问自己web应用以外的资源。在重定向的过程中，传输的信息会被丢失。 如何选择：通常情况下转发更快,而且能保持request内的对象,所以它是第一选择.但是由于在转发之后,浏览器中URL仍然指向开始页面,此时如果重载当前页面,开始页面将会被重新调用.如果你不想看到这样的情况,则选择转发. sessionSession存储在服务器端，一般为了防止在服务器的内存中（为了高速存取），Sessinon在用户访问第一次访问服务器时创建，需要注意只有访问JSP、Servlet等程序时才会创建Session，只访问HTML、IMAGE等静态资源并不会创建Session，可调用request.getSession(true)强制生成Session。 Session什么时候失效？ 1. 服务器会把长时间没有活动的Session从服务器内存中清除，此时Session便失效。Tomcat中Session的默认失效时间为20分钟。 2. 调用Session的invalidate方法。 Session对浏览器的要求：虽然Session保存在服务器，对客户端是透明的，它的正常运行仍然需要客户端浏览器的支持。这是因为Session需要使用Cookie作为识别标志。HTTP协议是无状态的，Session不能依据HTTP连接来判断是否为同一客户，因此服务器向客户端浏览器发送一个名为JSESSIONID的Cookie，它的值为该Session的id（也就是HttpSession.getId()的返回值）。Session依据该Cookie来识别是否为同一用户。该Cookie为服务器自动生成的，它的maxAge属性一般为-1，表示仅当前浏览器内有效，并且各浏览器窗口间不共享，关闭浏览器就会失效。因此同一机器的两个浏览器窗口访问服务器时，会生成两个不同的Session。但是由浏览器窗口内的链接、脚本等打开的新窗口（也就是说不是双击桌面浏览器图标等打开的窗口）除外。这类子窗口会共享父窗口的Cookie，因此会共享一个Session。 注意：新开的浏览器窗口会生成新的Session，但子窗口除外。子窗口会共用父窗口的Session。例如，在链接上右击，在弹出的快捷菜单中选择”在新窗口中打开”时，子窗口便可以访问父窗口的Session。 如果客户端浏览器将Cookie功能禁用，或者不支持Cookie怎么办？例如，绝大多数的手机浏览器都不支持Cookie。Java Web提供了另一种解决方案：URL地址重写。URL地址重写是对客户端不支持Cookie的解决方案。URL地址重写的原理是将该用户Session的id信息重写到URL地址中。服务器能够解析重写后的URL获取Session的id。这样即使客户端不支持Cookie，也可以使用Session来记录用户状态。HttpServletResponse类提供了encodeURL(String url)实现URL地址重写，该方法会自动判断客户端是否支持Cookie。如果客户端支持Cookie，会将URL原封不动地输出来。如果客户端不支持Cookie，则会将用户Session的id重写到URL中。 注意：tomcat判断客户端浏览器是否支持Cookie的依据是请求中是否含有Cookie。尽管客户端可能会支持Cookie，但是由于第一次请求时不会携带任何Cookie（因为并无任何Cookie可以携带），URL地址重写后的地址中仍然会带有jsessionid。当第二次访问时服务器已经在浏览器中写入Cookie了，因此URL地址重写后的地址中就不会带有jsessionid了。 cookie domain表示的是cookie所在的域，默认为请求的地址，如网址为www.test.com/test/test.aspx，那么domain默认为www.test.com。而跨域访问，如域A为t1.test.com，域B为t2.test.com，那么在域A生产一个令域A和域B都能访问的cookie就要将该cookie的domain设置为.test.com；如果要在域A生产一个令域A不能访问而域B能访问的cookie就要将该cookie的domain设置为t2.test.com。 path表示cookie所在的目录，asp.net默认为/，就是根目录。在同一个服务器上有目录如下：/test/,/test/cd/,/test/dd/，现设一个cookie1的path为/test/，cookie2的path为/test/cd/，那么test下的所有页面都可以访问到cookie1，而/test/和/test/dd/的子页面不能访问cookie2。这是因为cookie能让其path路径下的页面访问。 浏览器会将domain和path都相同的cookie保存在一个文件里，cookie间用*隔开。 总结一下顶级域名和子级域名之间的cookie共享和相互修改、删除聊一聊 cookie]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killWeb -- Nginx 详解]]></title>
    <url>%2Fblogs%2F60231.html</url>
    <content type="text"><![CDATA[前言内容比较多， 等到 结合 《Nginx 高性能 Web 服务器详解》 在将这些东西汇总。 参考文章http://wiki.nginx.org/Mainhttps://mp.weixin.qq.com/s?__biz=MzAxNzMwOTQ0NA==&amp;mid=2653355303&amp;idx=1&amp;sn=ce05d2a59c01f0e55b6d828805180aa2&amp;chksm=8035d74cb7425e5a95b52ebf7deebe99426886f6428a871dba3a98655deae79ebe383df3fb01#rdhttp://www.ha97.com/5194.htmlhttps://www.cnblogs.com/zhouxinfei/p/7862285.html]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killWeb -- 跨域问题总结]]></title>
    <url>%2Fblogs%2F57083.html</url>
    <content type="text"><![CDATA[跨域什么是跨域跨域是指a页面想获取b页面资源，如果a、b页面的协议、域名、端口、子域名不同，或是a页面为ip地址，b页面为域名地址，所进行的访问行动都是跨域的，而浏览器为了安全问题一般都限制了跨域访问，也就是不允许跨域请求资源。这就是 同源策略问题。举例： url 说明 是否跨域 http://www.cnblogs.com/a.jshttp://www.a.com/b.js 不同域名 是 http://www.a.com/lab/a.jshttp://www.a.com/script/b.js 同一域名下不同文件夹 否 http://www.a.com:8000/a.jshttp://www.a.com/b.js 同一域名，不同端口 是 http://www.a.com/a.jshttps://www.a.com/b.js 同一域名，不同协议 是 http://www.a.com/a.jshttp://70.32.92.74/b.js 域名和域名对应ip 是 http://www.a.com/a.jshttp://script.a.com/b.js 主域相同，子域不同 是（cookie不可访问） http://www.a.com/a.jshttp://a.com/b.js 同一域名，不同二级域名（同上） 是 跨域的解决方法1. jsonp1. 简介1、一个众所周知的问题，Ajax直接请求普通文件存在跨域无权限访问的问题，甭管你是静态页面、动态网页、web服务、WCF，只要是跨域请求，一律不准；2、不过我们又发现，Web页面上调用js文件时则不受是否跨域的影响（不仅如此，我们还发现凡是拥有“src”这个属性的标签都拥有跨域的能力，比如&lt;script&gt;、&lt;img&gt;、&lt;iframe&gt;）；3、于是可以判断，当前阶段如果想通过纯web端（ActiveX控件、服务端代理、属于未来的HTML5之Websocket等方式不算）跨域访问数据就只有一种可能，那就是在远程服务器上设法把数据装进js格式的文件里，供客户端调用和进一步处理；4、恰巧我们已经知道有一种叫做JSON的纯字符数据格式可以简洁的描述复杂数据，更妙的是JSON还被js原生支持，所以在客户端几乎可以随心所欲的处理这种格式的数据；5、这样子解决方案就呼之欲出了，web客户端通过与调用脚本一模一样的方式，来调用跨域服务器上动态生成的js格式文件（一般以JSON为后缀），显而易见，服务器之所以要动态生成JSON文件，目的就在于把客户端需要的数据装入进去。6、客户端在对JSON文件调用成功之后，也就获得了自己所需的数据，剩下的就是按照自己需求进行处理和展现了，这种获取远程数据的方式看起来非常像AJAX，但其实并不一样。7、为了便于客户端使用数据，逐渐形成了一种非正式传输协议，人们把它称作JSONP，该协议的一个要点就是允许用户传递一个callback参数给服务端，然后服务端返回数据时会将这个callback参数作为函数名来包裹住JSON数据，这样客户端就可以随意定制自己的函数来自动处理返回数据了。 2. 案例2.1 案例一通过 src 链接 跨域调用 remote server 中存在一个文件 remote.js1alert(" remote server 中的文件") local server12345678910&lt;!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type="text/javascript" src="http://remoteserver.com/remote.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 将会弹出 一个框体， remote server 中的文件调用成功 2.2 案例二通过 动态生成 &lt;script&gt; 标签 跨域调用12345678910111213141516171819202122&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD XHTML 1.0 Transitional//EN&quot; &quot;http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd&quot;&gt;&lt;html xmlns=&quot;http://www.w3.org/1999/xhtml&quot;&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; // 得到航班信息查询结果后的回调函数 var flightHandler = function(data)&#123; alert(&apos;你查询的航班结果是：票价 &apos; + data.price + &apos; 元，&apos; + &apos;余票 &apos; + data.tickets + &apos; 张。&apos;); &#125;; // 提供jsonp服务的url地址（不管是什么类型的地址，最终生成的返回值都是一段javascript代码） var url = &quot;http://flightQuery.com/jsonp/flightResult.aspx?code=CA1998&amp;callback=flightHandler&quot;; // 创建script标签，设置其属性 var script = document.createElement(&apos;script&apos;); script.setAttribute(&apos;src&apos;, url); // 把script标签加入head，此时调用开始 document.getElementsByTagName(&apos;head&apos;)[0].appendChild(script); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 2.3 案例三 通过 jquery 跨域调用 前端代码123456789101112131415161718192021222324252627282930313233343536373839&lt;%@ page pageEncoding=&quot;utf-8&quot; contentType=&quot;text/html;charset=UTF-8&quot; language=&quot;java&quot; %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;跨域测试&lt;/title&gt; &lt;script src=&quot;js/jquery-1.7.2.js&quot;&gt;&lt;/script&gt; &lt;script&gt; function showData (data) &#123; console.info(&quot;调用showData&quot;); var result = JSON.stringify(data); $(&quot;#text&quot;).val(result); &#125; $(document).ready(function () &#123; $(&quot;#btn&quot;).click(function () &#123; $.ajax(&#123; url: &quot;http://localhost:9090/student&quot;, type: &quot;GET&quot;, dataType: &quot;jsonp&quot;, //指定服务器返回的数据类型 jsonp: &quot;theFunction&quot;, //指定参数名称 jsonpCallback: &quot;showData&quot;, //指定回调函数名称 success: function (data) &#123; console.info(&quot;调用success&quot;); &#125; &#125;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;input id=&quot;btn&quot; type=&quot;button&quot; value=&quot;跨域获取数据&quot; /&gt; &lt;textarea id=&quot;text&quot; style=&quot;width: 400px; height: 100px;&quot;&gt;&lt;/textarea&gt;&lt;/body&gt;&lt;/html&gt; java 代码123456789101112131415161718protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; response.setCharacterEncoding("UTF-8"); response.setContentType("text/html;charset=UTF-8"); //数据 List&lt;Student&gt; studentList = getStudentList(); JSONArray jsonArray = JSONArray.fromObject(studentList); String result = jsonArray.toString(); //前端传过来的回调函数名称 String callback = request.getParameter("theFunction"); //用回调函数名称包裹返回数据，这样，返回数据就作为回调函数的参数传回去了 result = callback + "(" + result + ")"; response.getWriter().write(result);&#125; 返回的 urllocalhost:9090/student?theFunction = showData({result}) 2.3. 总结优点：适用于全部 浏览器，不用考虑不兼容的情况。缺点：但是，JSONP方案的局限性在于，JSONP只能实现GET请求。随着现在RESTful的兴起，JSONP显得力不从心了。因为，RESTful不仅有GET，还存在POST、PUT、PATCH、DELETE。 1、ajax和jsonp这两种技术在调用方式上“看起来”很像，目的也一样，都是请求一个url，然后把服务器返回的数据进行处理，因此jquery和ext等框架都把jsonp作为ajax的一种形式进行了封装；2、但ajax和jsonp其实本质上是不同的东西。ajax的核心是通过XmlHttpRequest获取非本页内容，而jsonp的核心则是动态添加&lt;script&gt;标签来调用服务器提供的js脚本。3、所以说，其实ajax与jsonp的区别不在于是否跨域，ajax通过服务端代理一样可以实现跨域，jsonp本身也不排斥同域的数据的获取。4、还有就是，jsonp是一种方式或者说非强制性协议，如同ajax一样，它也不一定非要用json格式来传递数据，如果你愿意，字符串都行，只不过这样不利于用jsonp提供公开服务。 2. corf跨域资源共享 CORS 详解 3. nginx 反向代理nginx反向代理机制详解用nginx的反向代理机制解决前端跨域问题 4. node.js 搭建中间服务器不知道 Node.js 相关的知识。以后可能会 涉及。 参考博客http://www.cnblogs.com/dowinning/archive/2012/04/19/json-jsonp-jquery.html 动脑环节cookie 跨域中的传递。https://segmentfault.com/a/1190000006932934https://segmentfault.com/a/1190000004556040]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killWeb -- dns介绍]]></title>
    <url>%2Fblogs%2F33506.html</url>
    <content type="text"><![CDATA[DNS 域名解析过程 用户在浏览器中输入域名并按下回车键后，浏览器检查缓存中有没有这个域名对应的解析过的 IP 地址。有，这个解析过程结束；没有，进行下一项。 查找操作系统缓存中有没有相应的 IP 地址。 （etc. C:/windows/system32/drivers/etc/hosts).没有，进行下一项 请求 域名服务器解析 域名。 网络配置中存在 “DNS 服务器地址” 。 操作系统会将域名发送给 LDNS (本地域名服务器，例如SPA)，缓存域名解析结果，主要承担工作。同理，没有，进行下一项 LDNS 没有命中， 到 ROOT SERVER 域名服务器请求解析。 ROOT SERVER 返回本地域名服务器 一个 查询域的主域名服务器(gTLD Server – 国际顶级域名服务器， 如 com,cn,org) LDNS 向返回的 gTLD 发送请求 gTLD 接受请求，并返回此域名对应的 Name Server 域名服务器地址(通常为 你注册的域名服务器)。 NS 查询存储的域名与IP地址的对应关系，连同一个 TTL 值一同返回给 LDNS LDNS 缓存域名与IP地址的对应关系，由 TTL 值控制缓存时间。 将解析的结果返回给用户。 DNS 域名解析记录 A 记录， Adress ,用来指定域名对应的 IP 地址， 可以将多个域名解析到一个 IP 地址 MX 记录， Mail Exchange ， 将某个域名下的邮件服务器指向自己的 Mail Server ， 如 taotao.com – A 记录 – 115.238.25.xxx , 如果将 MX 记录设置为 115.238.25.xxx，则 xx@taotao.com 的邮件将被解析到 115.238.25.xxx CNAME 记录， Canonical Name (别名解析)。 为一个域名设置一个或者多个别名。 比如我自己的博客 3dot141.cn – 3dot141.github.io. NS 记录， 为某个域名指定 DNS 解析服务器 TXT 记录， 为某个主机名或域名设置说明。 CDN 原理上文中 第8步，NS 查询存储的域名 的别名 – CNAME ， 并通过别名 指向 CDN 全局中的 DNS 负载均衡服务器(GTM Global Traffic Manager) 。GTM 返回给 距离这个用户最近的CDN节点。 用户直接去 这个几点访问 静态文件， 如果这个文件不存在，才会回到源站去获取。 清除缓存 windowsipconfig /flushdns linux/etc/init.d/nscd restart javaInetAddress 类的两种缓存策略 正确解析 错误解析由 %JAVA_HOME%\lib\security\java.security 文件中networkaddress.cache.ttl ( 默认值 -1 永不失效)networkaddress.cache.negative.ttl (默认值 10 缓存10s ) 注： 如果使用 InetAddress 类解析域名，必须是 单例模式]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killWeb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 工程结构]]></title>
    <url>%2Fblogs%2F19977.html</url>
    <content type="text"><![CDATA[springboot 包结构初级篇 root package结构：com.example.myproject 应用主类Application.java置于root package下，通常我们会在应用主类中做一些框架配置扫描等配置，我们放在root package下可以帮助程序减少手工配置来加载到我们希望被Spring加载的内容 实体（Entity）与数据访问层（Repository）置于com.example.myproject.domain包下 逻辑层（Service）置于com.example.myproject.service包下 Web层（web）置于com.example.myproject.web包下 123456789101112131415com +- example +- myproject +- Application.java | +- domain | +- Customer.java | +- CustomerRepository.java | +- service | +- CustomerService.java | +- web | +- CustomerController.java | 原因Application 是入口类， 其上有一个注解为 @SpringBootApplicaton12345678910111213141516@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125;), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125;)&#125;)public @interface SpringBootApplication &#123; @EnableAutoConfiguration其中 @EnableAutoConfiguration 的注解如下12345678910111213@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(&#123;AutoConfigurationImportSelector.class&#125;)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; @AutoConfigurationPackage 是引入 Registar.class AutoConfigurationImportSelector 则通过 SpringFactoriesLoader.loadFactoryNames 扫描 META/INF/spring.factories 文件。spring-boot-autoconfigure 包下就存在 spring.factories 文件。其中声明了有哪些自动配置。 总结因此 @EnableAutoConfiguration 会帮助 spring boot 根据类路径中的 jar 包依赖为当前项目进行自动配置 @ComponentScan帮助扫描 @SpringBootApplication 所在类的同级包，以及下级包。 进阶篇其他的RPC协议，多个微服务之间整个项目可以拆分成多个微服务，每个微服务工程又可以分为core和service两个工程，如：12user-coreuser-service 为什么要分为core、service呢？从两者的作用上来看，core主要是model、接口、常量，被service依赖，被使用方依赖，同时考虑到了使用方的感受；service主要是对接口的实现，以及对外提供多种RPC协议的服务。 core推荐的工程结构(user-core)代码层的结构 根目录+模块名：com.example.user 实体类(domain)置于com.example.user.domain，主要是与数据库的对应关系 实体类(domain)置于com.example.user.domain(或model)包下，每一张表对应一个Entity 数据访问层(Dao)置于com.example.user.repository 数据服务层(Service)置于com.example.user.service 常量接口类(consist)置于com.example.user.constant，包下是常量或枚举类型 service推荐的工程结构(user-service)代码层的结构 根目录+模块名：com.example.user 工程启动类(ApplicationServer.java)置于com.example.user包下 数据服务的实现接口(serviceImpl)至于com.example.user.service.impl 前端控制器(Controller)置于com.example.user.controller 工具类(utils)置于com.example.user.utils 配置信息类(config)置于com.example.user.config 数据传输类(vo)置于com.example.user.vo，为前端准备数据的json对象 公共项目commons-core可以把多个项目公共的代码抽取utils包下1234567891011com +- example +- common +- util | +- ftp | +- FtpUtil.java | +- fastdfs | +- FastdfsUtil.java |]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 与 mybatis 框架整合。]]></title>
    <url>%2Fblogs%2F62983.html</url>
    <content type="text"><![CDATA[springboot 整合 mybatis 框架pom 文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns = "http://maven.apache.org/POM/4.0.0" xmlns:xsi = "http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation = "http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.killCode&lt;/groupId&gt; &lt;artifactId&gt;mybatis_test&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;mybatis_test&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--mybatis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--mapper--&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--pagehelper--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- mybatis-generator 插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;!-- 解决 找不到相应的 mysql-connector-java 类 --&gt; &lt;!-- 使用内置 依赖的方式 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;!-- 文件的导入 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;basedir&#125;/src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;basedir&#125;/src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 使用 mybatis-generator 插件我曾经写过相关的文章Mybatis逆向工程 另外， Mybatis-generator 需要的 generatorConfig文件，默认在 src/main/resources 目录下。 创建一个测试表1234567CREATE DATABASE TEST;USE test;CREATE TABLE one( id INT AUTO_INCREMENT PRIMARY KEY , age INT, name VARCHAR(64)) properties 文件的修改修改 application.properties 文件123456789101112131415161718192021#mysqlspring.datasource.url=jdbc:mysql://localhost:3306/testspring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driver#mybatismybatis.type-aliases-package=com.killcode.pojomybatis.mapper-locations=classpath:com/killcode/mapper/*.xml#mapper#mappers 多个接口时逗号隔开#mapper.mappers=mapper.not-empty=falsemapper.identity=MYSQL#pagehelperpagehelper.helperDialect=mysqlpagehelper.reasonable=truepagehelper.supportMethodsArguments=truepagehelper.params=count=countSql 添加 spring-devtools.properties 文件12restart.include.mapper=/mapper-[\\w-\\.]+jarrestart.include.pagehelper=/pagehelper-[\\w-\\.]+jar 兼容生成的 mapper为了使 生成 的 mapper 被扫描到。可以使用两种方法 在类上添加 @Mapper 注解重点：这里要求 springboot 的工程结构如下：123456789101112131415com +- example +- myproject +- Application.java | +- domain | +- Customer.java | +- CustomerRepository.java | +- service | +- CustomerService.java | +- web | +- CustomerController.java | 即 domain , service , web 的包要放到 Application启动类的 同级或 下级中。详情请见这一份博客。 在启动类上 添加 @MapperScanner 注解。12345678@SpringBootApplication@MapperScan("com.killcode.mybatis_test.mapper")public class MybatisTestApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MybatisTestApplication.class, args); &#125;&#125; 这里要注意，根据作者所说， 要使用 tk.mybatis.spring.annotation.MapperScan . 测试test 文件12345678910111213141516@RunWith(SpringRunner.class)@SpringBootTest(classes = MybatisTestApplication.class)public class MybatisTestApplicationTests &#123; @Autowired private OneMapper oneMapper; @Test @Rollback public void contextLoads() &#123; One one = new One(); one.setAge(12); one.setName(&quot;test&quot;); oneMapper.insert(one); System.out.println(one); &#125;&#125; 解惑1、 关于 spring DevTools 配置在使用 DevTools 时，通用Mapper经常会出现 class x.x.A cannot be cast to x.x.A。同一个类如果使用了不同的类加载器，就会产生这样的错误，所以解决方案就是让通用Mapper和实体类使用相同的类加载器即可。DevTools 默认会对 IDE 中引入的所有项目使用 restart 类加载器，对于引入的 jar 包使用 base 类加载器，因此只要保证通用Mapper的jar包使用 restart 类加载器即可。 疑问1、当配置 mybatis.mapper-loccations 这个类时会有两个类同时满足条件，如图 并且这两个类的版本不同，所以springboot 是如何选择的呢？]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL -- notes01]]></title>
    <url>%2Fblogs%2F41528.html</url>
    <content type="text"><![CDATA[前言这是关于 《高性能mysql》 的读书笔记，其中的一些难点，参照网上的博客，给予解答。因为比较多，所以一点点的整理，现在只是将博客的链接发上去，方便自己理解。 5. 索引analyze table – 更新索引统计信息 OPTIMIZE TABLE – 减少碎片 6. 查询show fullprocesslist – 查询mysql 链接状态 查询优化器的提示 – 232optimizer_search_depth – 贪婪搜索模式 max_length_for_sort_data – mysql 排序算法的选择 优化 group by 和 distinctSQL_BIG_RESULT – SQL_SMALL_RESULT(临时表条件) group by with rollup 延迟关联 12345select film.film_id, film.description from sakila.film inner join ( select film_id from sakila.film order by title limit 50, 5 ) as lim using(film_id); 用户自定义变量 – 244SET @one := 1 ;避免重复查询刚刚更新的数据 – 247UPDATE t1 SET lastUpdated = NOW() WHERE ID=1 AND @now := NOW();SELECT @now; 7. 高级特性1、 分区表CREATE TABLE sales() ENGINE=InnoDB PARTITION BY RANGE( PARTITION 1 values LESS THAN (), …)MySQL 分区总结 2、视图 1. 合并算法 2. 临时表算法 EXPLAIN SELECT * FROM &lt;view_name&gt; CHECK OPTION -- 任何通过视图更新的行，都必须符合视图本身的where条件定义。 查找视图创建的语句 123456789SELECT REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE( REPLACE(REPLACE(REPLACE(REPLACE(REPLACE( SUBSTRING_INDEX(LOAD_FILE(&apos;/X.frm&apos;), &apos;\nsource=&apos;, -1), &apos;\\_&apos;,&apos;\_&apos;),&apos;\\%&apos;,&apos;\%&apos;),&apos;\\\\&apos;,&apos;\\&apos;),&apos;\\z&apos;,&apos;\z&apos;),&apos;\\t&apos;,&apos;\t&apos;), &apos;\\r&apos;,&apos;\r&apos;),&apos;\\n&apos;,&apos;\n&apos;),&apos;\\b&apos;,&apos;\b&apos;),&apos;\\\&quot;&apos;,&apos;\&quot;&apos;),&apos;\\\&apos;&apos;,&apos;\&apos;&apos;), &apos;\\o&apos;,&apos;\o&apos;)AS source; 3、 外键约束 1. 触发器 2. 显示限制取值 4、 全文索引innodb 的全文索引MATCH .. AGAINST ..修饰符a , ~a , +a , -a , a* , “a” 5、 分布式事务(XA)XA 协议- wikipedia 相关介绍http://www.importnew.com/15812.htmlhttps://segmentfault.com/a/1190000005718940http://blog.csdn.net/bluishglc/article/details/7612811 4、 查询缓存 如果查询语句中包含任何不确定的函数，那么在查询缓存中是不可能找到缓存结果的 占用内存 mysql 自己管理一大块内存， 在初始化创建查询缓存时执行，之后采用非贪婪策略，不断分配小的内存块。 配置与维护缓存12345678910111213141516query_cache_typequery_cache_sizequery_cache_min_res_unit -- 可能会造成 缓存碎片query_cache_limitquery_cache_wlock_invalidateqcache_free_memoryqcache_queries_in_cacheqcache_free_blocksqcache_total_blocksqcache_lowmem_prunessql_cachesql_no_cacheFLUSH QUERY CACHE 8. 优化服务器配置1、 常用变量1234567key_buffer_sizetable_cache_sizethread_cache_sizequery_cache_sizeread_buffer_sizeread_rnd_buffer_sizesort_buffer_size 注意： 将配置文件置于版本控制之下 2、 https://tools.percona.com/ 在线配置网站 3、 MyISAM 键缓存key_buffer.key_buffer_size = 1Gmysql&gt; CACHE INDEX t1 IN key_buffer;mysql&gt; LOAD INDEX INTO CACHE t1; 缓存块大小myisam_block_sizecreate table/index … key_block_sizze 4、 InnoDB 数据字典 – 表缓存控制 统计信息持久化InnoDB_analyze_is_persistent –InnoDB_stats_on_metadata 日志mysql&gt; SHOW INNODB STATUS innodb_log_file_sizeinnodb_log_files_in_groupinnodb_log_buffer_sizeinnodb_flush_log_at_trx_commit innodb_data_home_dirinnodb_data_file_path = ibdata1:1G:autoextend – 表空间名：大小：自动填充innodb_file_per_table – 为每张表使用一个文件 ， 在数据字典中生成 .iba 文件 双写缓冲目的是避免页没写完整所导致的的数据损坏，原理是将最近的写回的页面的备份拷贝。 5、 基本配置 12345678910111213141516171819202122232425tmp_table_size -- max_heap_table_sizemax_connectionsthread_cache_sizetable_cache_sizeexpire_logs_days -- 二进制日志的清理max_allowed_packetmax_connect_errorsskip_name_resolve -- DNS 查找sql_mode -- 改变服务器行为&lt;!-- 主从复制 --&gt;read_onlyskip_slave_startslave_net_timeoutsync_master_info,sync_relay_log,sync_relay_log_info&lt;!-- innodb 的高级配置 --&gt;mysql&gt; SHOW ENGINE INNODB STATUSinnodbinnodb_auto_lock_modeinnodb_buffer_pool_instancesinnodb_io_capacityinnodb_read/write_io_threadsinnodb_strict_mode 10. 复制原理： 主库上记录二进制日志， 备库启动一个 I/O 线程，并进入睡眠状态，当主库发送信号时，将其唤醒， 将日志复制到自己的中继日志中 备库的 SQL 线程 读取中继日志中的事件，并将其重放到备库数据中。 复制过程：1、 创建复制账号MySQL创建用户与授权mysql&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON . TO repl@ ‘192.168.0.%’ IDENTIFIED BY ‘p4ssword’,; 2、 配置主库和备库log_bin = mysql-bin – 建议是决定路径server_id = 10 log_bin = mysql-binserver_id = 2relay_log = mysql-relay-bin – 指定中继日志的位置和命名 //将备库 变成其他服务器 的 主库log_slave_updates = 1 – 允许备库将重放事件记录到自身的二进制日志中read_only 3、 通知备库连接主库，并复制数据mysql&gt; CHANGE MASTER TO MASTER_HOST = ‘server1’, -&gt; MASTER_USER = ‘repl’, -&gt; MASTER_PASSWORD= ‘p4ssword’, -&gt; MASTER_LOG_FILE= ‘mysql-bin.00001’ -&gt; MASTER_LOG_POS= 0； mysql&gt; START SLAVE; 4、 备份 冷备份 percona xtrabackup – 热备份 5、 推荐主库： sync_binlog = 1 – 每次提交事务会将二进制日志同步到磁盘上 innodb_flush_logs_at_trx_commit innodb_support_xa = 1 innodb_safe_binlog备库： read_only sync_master_info =1 sync_relay_log =1 sync_relay_log_info =1 争议： relay_log_space_limit – 防止复制延迟 6、 复制使用到的文件mysql-bin.index – 二进制日志文件mysql-relay-bin-index – 中继日志文件master.info – 备库连接主库需要的信息relay-log.info – 备库从主库复制的相关进度 7、 过滤数据SQL_LOG_BIN binlog_do_dbbinlog_ignore_db replicate_* 8、 复制拓扑结构 主主复制 主动主动 主动被动 环形结构 模拟多主库复制 ： mysql 不支持 一备库多主库复制，所以可以先采用*主主**复制，然后选择其中一个主库，给予其备库。 9、 高级问题 改变主库 备库与新主库的位置不同 过大的复制延迟 SHOW MASTER STATUS –SHOW MASTER LOGSSHOW SLAVE STATUSSHOW PROCESSLIST mysqlbinlog –分析日志 11、 可扩展性OLTP – 在线事务处理OLAP – 在线数据分析 复制 拆分 – 节点 数据分片 负载均衡 12、 高可用性MTBF – 平均失效时间 mean time between failuresMTTR – 平均回复时间 mean time to recovery 避免单点失效： – 提高冗余(增加空余容量，重复组件) 共享存储与磁盘复制 同步复制 15、 备份与恢复 逻辑备份： 将数据包含在一种mysql能够解析的格式中 SQL 导出 – mysqldump 符号分隔文件备份 1234567mysql&gt; SELECT * INTO OUTFILE &apos;&apos; &gt; FIELDS TERMINATED BY &apos;,&apos; OPTIONALLY ENCLOSED BY &apos;&quot;&quot;&apos; &gt; LINES TERMINATED BY &apos;\n&apos; &gt; FROM test.t1mysql&gt; LOAD DATA INFILE &apos;&apos; &gt; INTO TABLE test.t1 物理备份： 直接复制原始文件的物理备份。 备份文件：非显著数据，代码，复制配置，服务器配置，操作系统文件 二进制日志格式： 包含日志文件内的偏移字节值 包含如下几项： 事件日期和时间 原服务器的服务器ID end_log_pos, 下一个事件的偏移字节值 事件类型 原服务器上执行事件的线程ID 原服务器上执行事件产生的错误代码 文件系统快照：LVM：使用写时复制技术 。 原来存在 原始卷 与 预留区域。 当 原始卷中的一些数据发生变化， 则复制受影响的块到 预留区域中， 之后快照再次请求这些块时， LVM 会从复制块中，而非 原始卷中 读取。 vgs – 卷组 lvs – 查看逻辑卷 lvcreate –size 16G –snapshot –name backup_mysql /dev/vg/mysql mount /dev/mapper/vg-backup_mysql /tmp/backup lvremove –force /dev/vg/backup_mysql mysqldump 使用123456789101112131415161718192021-- 将服务器上所有的内容创建逻辑备份到单个文件中 -- $ mysqldump --all-databases &gt;dump.sql-- 创建只包含 xx 数据库的 逻辑备份 --$ mysqldump --databases sakila &gt; dump.sql-- 创建包含 xx 表 的逻辑备份 --$ mysqldump sakila actor &gt; dump.sql-- 防止在windows 上发生换行符转换 --$ mysqldump sakila actor --result-file=dump.sql&lt;!-- 相关选项 --&gt;--opt--allow-keywords --quote-names--complete-insert--tz-utc--lock-all-tables--tab--skip-extended-insert&lt;!-- innodb 相关 --&gt;--single-transaction--master-data 杂章ext3 文件系统http://os.51cto.com/art/201205/334497_all.htmhttp://blog.csdn.net/ljianhui/article/details/8604140http://wuchong.me/blog/2014/07/19/linux-file-system/ MySql windows 下安装my.ini 配置 12345678910111213141516[mysql]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]#设置3306端口port = 3306 # 设置mysql的安装目录basedir=D:\MySQL\mysql-5.7.16-winx64# 设置mysql数据库的数据的存放目录#datadir=D:\MySQL\mysql-5.7.16-winx64\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB MySQL 三种关联查询的方式: ON vs USING vs 传统风格 MySQL临时表 MySQL分组查询 Groupby 实现原理 MySQL Order By 实现原理分析和Filesort优化 where group by , having , order byhaving 筛选成组后的各种数据 MySQL 间隙锁http://www.cnblogs.com/zuoxingyu/archive/2012/09/27/2705285.htmlhttp://www.cnblogs.com/digdeep/p/4968453.htmlmysql mvcc 机制 SAN,NAS介绍 结语因为 《高性能MySQL》 这本书，我过去看过一部分，这次算是将之前的补足。 刚开始只是想记录一下相关的操作，不过发现很多自己不清楚的概念，因此就通过查阅网上的资料，将之整理下来。现在回顾一下，对 MySQL 有了更深的理解 ，不过书中的内容感觉比较深，自己的记忆与理解 还不够，因此 之后还需要多多学习。然后复习以及巩固。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[About]]></title>
    <url>%2Fblogs%2F74350de7.html</url>
    <content type="text"><![CDATA[AboutLive 的记录 mood – 生活，旅行日记。 tool – 使用的工具，电脑手机上的 app 等 ， recipe – 做饭的食谱。 tip – 提高效率的技巧。 moodmood 代表着自己的情绪，用以表达当时的 ♥ 心情 ♥ 。 tool还没想好要写什么 recipe tip]]></content>
      <categories>
        <category>Live</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[About]]></title>
    <url>%2Fblogs%2Fb5f422e3.html</url>
    <content type="text"><![CDATA[Aboutessay 的记录 书评 _ Book 影评 _ Movie 零散的知识 _ SerendipityBookNothing is impossible for a willing heart.心之所愿，无事不成。 MovieLogic will get you from A to B. Imagination will take you everywhere.逻辑带你从 A 到 B , 想象力将带你去任何地方。Albert Einstein SerendipitySerendipity 在词典中的含义是指：意外发现珍奇事物的本领；有意外发现珍宝的运气]]></content>
      <categories>
        <category>Essay</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[杂章]]></title>
    <url>%2Fblogs%2F2891c4c2.html</url>
    <content type="text"><![CDATA[Iterator接口的核心方法next()或者hasNext() 是依赖于迭代器的当前迭代位置的。 如果Collection直接实现Iterator接口，势必导致集合对象中包含当前迭代位置的数据(指针)。 当集合在不同方法间被传递时，由于当前迭代位置不可预置，那么next()方法的结果会变成不可预知。 除非再为Iterator接口添加一个reset()方法，用来重置当前迭代位置。 但即时这样，Collection也只能同时存在一个当前迭代位置。 而Iterable则不然，每次调用都会返回一个从头开始计数的迭代器。 多个迭代器是互不干扰的。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能数据库]]></title>
    <url>%2Fblogs%2Fd4f2e1f6.html</url>
    <content type="text"><![CDATA[5. 索引analyze table – 更新索引统计信息 OPTIMIZE TABLE – 减少碎片 6. 查询show fullprocesslist – 查询mysql 链接状态 查询优化器的提示 – 232optimizer_search_depth – 贪婪搜索模式 max_length_for_sort_data – mysql 排序算法的选择 优化 group by 和 distinctSQL_BIG_RESULT – SQL_SMALL_RESULT(临时表条件) group by with rollup 延迟关联 12345select film.film_id, film.description from sakila.film inner join ( select film_id from sakila.film order by title limit 50, 5 ) as lim using(film_id); 用户自定义变量 – 244SET @one := 1 ;避免重复查询刚刚更新的数据 – 247UPDATE t1 SET lastUpdated = NOW() WHERE ID=1 AND @now := NOW();SELECT @now; 7. 高级特性1、 分区表CREATE TABLE sales() ENGINE=InnoDB PARTITION BY RANGE( PARTITION 1 values LESS THAN (), …)MySQL 分区总结 2、视图 1. 合并算法 2. 临时表算法 EXPLAIN SELECT * FROM &lt;view_name&gt; 1234567891011121314CHECK OPTION -- 任何通过视图更新的行，都必须符合视图本身的where条件定义。查找视图创建的语句```SELECT REPLACE(REPLACE(REPLACE(REPLACE(REPLACE(REPLACE( REPLACE(REPLACE(REPLACE(REPLACE(REPLACE( SUBSTRING_INDEX(LOAD_FILE(&apos;/X.frm&apos;), &apos;\nsource=&apos;, -1), &apos;\\_&apos;,&apos;\_&apos;),&apos;\\%&apos;,&apos;\%&apos;),&apos;\\\\&apos;,&apos;\\&apos;),&apos;\\z&apos;,&apos;\z&apos;),&apos;\\t&apos;,&apos;\t&apos;), &apos;\\r&apos;,&apos;\r&apos;),&apos;\\n&apos;,&apos;\n&apos;),&apos;\\b&apos;,&apos;\b&apos;),&apos;\\\&quot;&apos;,&apos;\&quot;&apos;),&apos;\\\&apos;&apos;,&apos;\&apos;&apos;), &apos;\\o&apos;,&apos;\o&apos;)AS source;``` 3、 外键约束 1. 触发器 2. 显示限制取值 4、 全文索引innodb 的全文索引MATCH .. AGAINST ..修饰符a , ~a , +a , -a , a* , “a” 5、 分布式事务(XA)XA 协议- wikipedia 相关介绍http://www.importnew.com/15812.htmlhttps://segmentfault.com/a/1190000005718940http://blog.csdn.net/bluishglc/article/details/7612811 4、 查询缓存 如果查询语句中包含任何不确定的函数，那么在查询缓存中是不可能找到缓存结果的 占用内存 mysql 自己管理一大块内存， 在初始化创建查询缓存时执行，之后采用非贪婪策略，不断分配小的内存块。 配置与维护缓存12345678910111213141516query_cache_typequery_cache_sizequery_cache_min_res_unit -- 可能会造成 缓存碎片query_cache_limitquery_cache_wlock_invalidateqcache_free_memoryqcache_queries_in_cacheqcache_free_blocksqcache_total_blocksqcache_lowmem_prunessql_cachesql_no_cacheFLUSH QUERY CACHE 8. 优化服务器配置1、 常用变量1234567key_buffer_sizetable_cache_sizethread_cache_sizequery_cache_sizeread_buffer_sizeread_rnd_buffer_sizesort_buffer_size 注意： 将配置文件置于版本控制之下 2、 https://tools.percona.com/ 在线配置网站 3、 MyISAM 键缓存key_buffer.key_buffer_size = 1Gmysql&gt; CACHE INDEX t1 IN key_buffer;mysql&gt; LOAD INDEX INTO CACHE t1; 缓存块大小myisam_block_sizecreate table/index … key_block_sizze 4、 InnoDB 数据字典 – 表缓存控制 统计信息持久化InnoDB_analyze_is_persistent –InnoDB_stats_on_metadata 日志mysql&gt; SHOW INNODB STATUS innodb_log_file_sizeinnodb_log_files_in_groupinnodb_log_buffer_sizeinnodb_flush_log_at_trx_commit innodb_data_home_dirinnodb_data_file_path = ibdata1:1G:autoextend – 表空间名：大小：自动填充innodb_file_per_table – 为每张表使用一个文件 ， 在数据字典中生成 .iba 文件 双写缓冲目的是避免页没写完整所导致的的数据损坏，原理是将最近的写回的页面的备份拷贝。 5、 基本配置 12345678910111213141516171819202122232425tmp_table_size -- max_heap_table_sizemax_connectionsthread_cache_sizetable_cache_sizeexpire_logs_days -- 二进制日志的清理max_allowed_packetmax_connect_errorsskip_name_resolve -- DNS 查找sql_mode -- 改变服务器行为&lt;!-- 主从复制 --&gt;read_onlyskip_slave_startslave_net_timeoutsync_master_info,sync_relay_log,sync_relay_log_info&lt;!-- innodb 的高级配置&gt;mysql&gt; SHOW ENGINE INNODB STATUSinnodbinnodb_auto_lock_modeinnodb_buffer_pool_instancesinnodb_io_capacityinnodb_read/write_io_threadsinnodb_strict_mode 10. 复制原理： 主库上记录二进制日志， 备库启动一个 I/O 线程，并进入睡眠状态，当主库发送信号时，将其唤醒， 将日志复制到自己的中继日志中 备库的 SQL 线程 读取中继日志中的事件，并将其重放到备库数据中。 复制过程：1、 创建复制账号mysql&gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON . TO repl@ ‘192.168.0.%’ IDENTIFIED BY ‘p4ssword’,; 2、 配置主库和备库 3、 通知备库连接主库，并复制数据 杂章ext3 文件系统http://os.51cto.com/art/201205/334497_all.htmhttp://blog.csdn.net/ljianhui/article/details/8604140http://wuchong.me/blog/2014/07/19/linux-file-system/ MySql windows 下安装my.ini 配置 12345678910111213141516[mysql]# 设置mysql客户端默认字符集default-character-set=utf8 [mysqld]#设置3306端口port = 3306 # 设置mysql的安装目录basedir=D:\MySQL\mysql-5.7.16-winx64# 设置mysql数据库的数据的存放目录#datadir=D:\MySQL\mysql-5.7.16-winx64\data# 允许最大连接数max_connections=200# 服务端使用的字符集默认为8比特编码的latin1字符集character-set-server=utf8# 创建新表时将使用的默认存储引擎default-storage-engine=INNODB MySQL 三种关联查询的方式: ON vs USING vs 传统风格 MySQL临时表 MySQL分组查询 Groupby 实现原理 MySQL Order By 实现原理分析和Filesort优化 where group by , having , order byhaving 筛选成组后的各种数据 MySQL 间隙锁http://www.cnblogs.com/zuoxingyu/archive/2012/09/27/2705285.htmlhttp://www.cnblogs.com/digdeep/p/4968453.htmlmysql mvcc 机制]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killJtools -- Maven 入门详解]]></title>
    <url>%2Fblogs%2F10580.html</url>
    <content type="text"><![CDATA[目录1.更改仓库目录maven\conf\settings.xml 路径 2.目录结构12345678src main java resources（暂时省略）test java resources（暂时省略）pom.xm 3.pom.xmlHelloWorld123&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;!-- 模型版本号：4.0.0 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; 可以被当作其他项目的依赖项 1234567891011121314151617181920212223242526272829303132333435363738 &lt;!-- 组织名称：暂时使用 组织名称+项目名称 作为组织名称 --&gt; &lt;!-- 组织名称：实际名称 按照访问路径规范设置，通常以功能作为名称：eg: junit spring --&gt; &lt;groupId&gt;cn.itcast.maven&lt;/groupId&gt; &lt;!-- 项目名称 --&gt; &lt;artifactId&gt;HelloWorld&lt;/artifactId&gt; &lt;!-- 当前项目版本号：同一个项目开发过程中可以发布多个版本，此处标示0.0.1版 --&gt; &lt;!-- 当前项目版本号：每个工程发布后可以发布多个版本，依赖时调取不同的版本，使用不同的版本号 --&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;!-- 发布时的文件类型：默认jar包 --&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!-- 名称：可省略 --&gt; &lt;name&gt;Hello&lt;/name&gt; &lt;!-- 资源下载路径：存在默认值&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;!-- 依赖关系 --&gt; &lt;dependencies&gt; &lt;!-- 依赖设置 --&gt; &lt;dependency&gt; &lt;!-- 坐标 --&gt; &lt;!-- 依赖组织名称 --&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;!-- 依赖项目名称 --&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;!-- 依赖版本名称 --&gt; &lt;version&gt;4.9&lt;/version&gt; &lt;!-- 依赖范围：test包下依赖该设置 --&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 4.命令 打开cmd命令行，进入Hello项目根目录(包含有pom.xml文件的目录) 执行 mvn compile命令 执行完毕后，生成了maven工程编译完成后字节码文件的生成目录target cmd 中继续录入mvn clean命令 执行完毕后，字节码生成目录target被删除 cmd 中录入 mvn clean test命令 执行完毕后，字节码生成目录中生成了被测试类与测试类的编译字节码和测试执行过程日志与详细报告 cmd 中录入 mvn clean compile命令 组合指令，先执行clean，再执行compile，通常应用于上线前执行，清除测试类 cmd 中录入 mvn clean test命令 组合指令，先执行clean，再执行test，通常应用于测试环节 cmd 中录入 mvn clean package命令 组合指令，先执行clean，再执行package，将项目打包，通常应用于发布前 执行过程：- 清理————清空环境 - 编译————编译源码 - 测试————测试源码 - 打包————将编译的非测试类打包 cmd 中录入 mvn clean install 查看仓库，当前项目被发布到仓库中 组合指令，先执行clean，再执行install，将项目打包，通常应用于发布前 执行过程：清理————清空环境 编译————编译源码 测试————测试源码 打包————将编译的非测试类打包 部署————将打好的包发布到资源仓库中 5.坐标依赖查询地址 groupid: 定义当前Maven项目隶属项目 artifactld: 定义初建项目中的一个模块 version：定义当前项目的当前版本 packaging: 定义该项目的打包方式 scoge：范围 依赖范围 主代码 测试代码 运行时 例子 compile y y y jdk test - y - junit provided y y - servlet-api runtime - - y JDBC Drive 6.依赖 依赖传递： 直接依赖 间接依赖 依赖范围列是第一直接依赖，行是第二间接依赖 compile test provided runtime compile compile - - runtime test test - - test provided provided - provided provided runtime runtime - - runtime 可选依赖： 控制该依赖使用时，是否向下传递 123&lt;dependency&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; true : 代表不向下传递false：向下传递 排除依赖 :主动选择是否要使用传递的依赖。 123456789&lt;dependency&gt;&lt;-- 设置当前依赖中是否使用间接依赖 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;&lt;/groupId&gt; &lt;artifactId&gt;&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 依赖冲突 如果一个配置中依赖写了多个，以最后一个为准。 7.生命周期 三大生命周期：内有许多个按顺序执行的流程。 clean default site 自定义插件+插件1234567891011121314151617&lt;bulid&gt; &lt;plugin&gt; &lt;!-- 定义插件的坐标 --&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;groupId&gt; &lt;artifactId&gt;maven-source-plugins&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;!-- 具体的执行位置 --&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;phase&gt;process-classes&lt;/phase&gt; &lt;goals&gt; &lt;/exclusion&gt; &lt;executions&gt; &lt;/plugin&gt;&lt;/build&gt; 8.继承+聚合1. 继承：消除重复配置 父工程 1&lt;packaging&gt;pom&lt;/packaging&gt; 子工程 123456789101112131415161718192021222324252627&lt;parent&gt; &lt;!-- 与父工程版本一致，自身可以不写 --&gt; &lt;groupId&gt;cn.itcast&lt;/groupId&gt; &lt;!-- 父工程类名 --&gt; &lt;artifactId&gt;ZParent&lt;/artifactId&gt; &lt;!-- 与父工程版本一致，自身可以不写 --&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../ZParent&lt;/relativePath&gt;&lt;/parent&gt;&lt;!-- 版本统一管理 --&gt;&lt;!-- 父工程设置版本，子工程再次设置时不用写版本号 --&gt;&lt;!-- 不会被子工程直接继承，而是当子工程设置时，才会自己设置版本 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 设置常量 --&gt;&lt;properties&gt; &lt;log4j.version&gt;1.2.15&lt;/log4j.version&gt;&lt;/properties&gt;&lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; 2. 聚合:减少操作，将多个一同编译。 1234&lt;modules&gt; &lt;module&gt;&lt;/module&gt; &lt;module&gt;&lt;/module&gt;&lt;modules&gt; 9.本地仓库+私服+中央仓库流程：个人 –&gt; 私服 –&gt; 中央 私服： Nexus 1.将 Nexus.war 包 放入 tomcat/webapps/ 2.启动tomcat,打开网址http://localhost:8080/nexus/index.html#welcome 3. 介绍： Repository: central 中央仓库 central M1 shadow 镜像仓库，防止中央仓库出现问题 3rd party 第三方仓库 Artifact Upload Apache Sanpshots 还未完全开发好，试用 release snapshots Type: proxy 远程代理 hosted 本地 group 群组 vitual Browse Index:下载Index索引并进行构建搜索 1.可能通过这个 索引 下载文件出错。 解决方法：将本地仓库中的旧文件完全删除，然后重新下载。 作用：找到依赖配置 使用 配置所有构建均从私服下载 ~/.m2/setting.xml或~/config/setting.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;settings&gt; &lt;!-- 配置拦截 --&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;!--此处配置所有的构建均从私有仓库中下载 *代表所有，也可以写central --&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;!-- 下载东西的 id 在此处配置 --&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;!-- 私服网站上对应的 group 群组地址 --&gt; &lt;url&gt;http://192.168.1.100:8000/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;!-- 定义策略 --&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;!—所有请求均通过镜像 --&gt; &lt;!-- jar包 --&gt; &lt;repositories&gt; &lt;repository&gt; &lt;!-- 与网站上的名称对应 --&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;!-- 代表两种包的不同状态 --&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- maven插件包 --&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;url&gt;http://central&lt;/url&gt; &lt;releases&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/releases&gt; &lt;snapshots&gt;&lt;enabled&gt;true&lt;/enabled&gt;&lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- 使用策略 --&gt; &lt;activeProfiles&gt; &lt;!--make the profile active all the time --&gt; &lt;!-- 名称与 profile 的 id 名称一致 --&gt; &lt;activeProfile&gt;nexus&lt;/activeProfile&gt; &lt;/activeProfiles&gt; &lt;!-- 设置权限 --&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;servers&gt;&lt;settings&gt; 本地仓库与上文修改的xml文件一致。 pom.xml文件 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;name&gt;Internal Releases&lt;/name&gt; &lt;url&gt;http://localhost:8000/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;Internal Snapshots&lt;/name&gt; &lt;url&gt;http://localhost:8000/nexus/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 4. 上传 mvn -deploy &lt;!-- 对应上传的文件夹是 SNAPSHOT --&gt; &lt;version&gt; -SNAPSHOT &lt;/version&gt; &lt;!-- 对应上传的文件夹是 RELEASE --&gt; &lt;version&gt; -RELEASE &lt;/version&gt; &lt;!-- 对应对哪些项目打包 --&gt; &lt;modules&gt;&lt;/modules&gt;]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killTools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killBase系列 -- 密码学]]></title>
    <url>%2Fblogs%2F3152.html</url>
    <content type="text"><![CDATA[密码学一、基础 密码学算法分类： 消息编码：Base64 消息摘要：MD类， SHA类，MAC 对称密码：DES,3DES,AES 非对称密码：RSA,DH 数字签名：RSASignature,DSASignature 五元组1)明文：原始信息。2)加密算法：以密钥为参数，对明文进行多种置换和转换的规则和步骤，变换结果为密文。3)解密算法：加密算法的逆变换，以密文为输入、密钥为参数，变换结果为明文。:4)密钥：加密与解密算法的参数，直接影响对明文进行变换的结果。5)密文：对明文进行变换的结果。 Java编程中常用类 – java.security 包 消息编码：BASE64Encoder,BASE64Decoder – java.util 消息摘要：MessageDigest 对称密码：KeyGenerator,SeretkeyFactory – javax.crypto 包(提供给AES，DES，3DES，MD5，SHA1等 对称 和 单向加密算法。),Cipher 非对称密码：KeyPairGenerator,KeyFactory – java.security 包(提供给DSA，RSA， EC等 非对称加密算法。),KeyPair,PublicKey,PrivateKey,Cipher 数字重命名：Signature 常用开源工具 Commons.Codec Bouncy.Castle 二、Base64 算法 Base64 基于64个字符编码算法，以任意 8 位字节序列组合描述形式 , BASE加密后产生的字节位数是8的倍数，如果不够位数以=符号填充。对此 Base64 算法有一套字符映射表。 使用方法：1234567891011121314151617181920212223// 获取 Base64.Encoder encoder = Base64.getEncoder(); Base64.Decoder decoder = Base64.getDecoder();// 加密 public byte[] encode(byte[] src); * @param src * the byte array to encode * @param dst * the output byte array * @return The number of bytes written to the output byte array public int encode(byte[] src,byte[] dst); public String encodeToString(byte[] src); public ByteBuffer encode(ButeBuffer buffer);// 解密 public byte[] decode(byte[] src); * @param src * the byte array to encode * @param dst * the output byte array * @return The number of bytes written to the output byte array public int decode(byte[] src,byte[] dst); public byte[] decode(String src); public ByteBuffer decode(ButeBuffer buffer); 三、消息摘要 介绍：又称为 哈希算法。唯一对应一个消息或文体固定长度值，由一个单向的Hash加密函数对消息进行作用而产生。 分类： MD(Message Digest) 消息摘要算法，SHA(Secure Hash Algorithm) 安全散列算法， MAC(Message Authentication Code):消息认证算法 主要方法：12// xxx 可以为 md5,shaMessageDigest.getInstance("xxx") 1. MD5算法 原理：首先需要对信息进行填充，使其位长对512求余的结果等于448。因此，信息的位长（Bits Length）将被扩展至N512+448，N为一个非负整数，N可以是零。填充的方法如下，在信息的后面填充一个1和无数个0，直到满足上面的条件时才停止用0对信息的填充。然后，在这个结果后面附加一个以64位二进制表示的填充前信息长度。经过这两步的处理，信息的位长=N512+448+64=(N+1）*512，即长度恰好是512的整数倍MD5以512位分组来处理输入的信息，且每一分组又被划分为16个32位子分组，经过了一系列的处理后，算法的输出由四个32位分组组成，将这四个32位分组级联后将生成一个128位散列值。 代码实现 123456789101112131415161718192021222324252627282930313233public class MD5Util &#123; /*** * MD5加密 生成32位md5码 * @param 待加密字符串 * @return 返回32位md5码 */ public static String md5Encode(String inStr) throws Exception &#123; MessageDigest md5 = null; try &#123; md5 = MessageDigest.getInstance("MD5"); &#125; catch (Exception e) &#123; System.out.println(e.toString()); e.printStackTrace(); return ""; &#125; byte[] byteArray = inStr.getBytes("UTF-8"); byte[] md5Bytes = md5.digest(byteArray); StringBuffer hexValue = new StringBuffer(); // 转化为 16 进制 // 原理 ： byte 为 8 字节。 0xff --&gt; 11111111 // byte&amp;0xff 如果小于16 则小于00010000 // 所以由 toHexString() 只能转化为 1 位，所以要在前面加上 ‘0’。再加上实际的值。 for (int i = 0; i &lt; md5Bytes.length; i++) &#123; int val = ((int) md5Bytes[i]) &amp; 0xff; if (val &lt; 16) &#123; hexValue.append("0"); &#125; hexValue.append(Integer.toHexString(val)); &#125; return hexValue.toString(); &#125;&#125; 2. SHA 算法 原理：接收一段明文，然后以一种不可逆的方式将它转换成一段（通常更小）密文，也可以简单的理解为取一串输入码（称为预映射或信息），并把它们转化为长度较短、位数固定的输出序列即散列值（也称为信息摘要或信息认证代码）的过程。 特点：该算法输入报文的长度不限，产生的输出是一个160位的报文摘要。输入是按 512 位的分组进行处理的。 作用：通过散列算法可实现数字签名实现，数字签名的原理是将要传送的明文通过一种函数运算（Hash）转换成报文摘要（不同的明文对应不同的报文摘要），报文摘要加密后与明文一起传送给接受方，接受方将接受的明文产生新的报文摘要与发送方的发来报文摘要解密比较，比较结果一致表示明文未被改动，如果不一致表示明文已被篡改。 代码实现 12345678910111213141516171819202122232425262728public class SHAUtil &#123; /*** * SHA加密 生成40位SHA码 * @param 待加密字符串 * @return 返回40位SHA码 */ public static String shaEncode(String inStr) throws Exception &#123; MessageDigest sha = null; try &#123; sha = MessageDigest.getInstance("SHA"); &#125; catch (Exception e) &#123; System.out.println(e.toString()); e.printStackTrace(); return ""; &#125; byte[] byteArray = inStr.getBytes("UTF-8"); byte[] md5Bytes = sha.digest(byteArray); StringBuffer hexValue = new StringBuffer(); for (int i = 0; i &lt; md5Bytes.length; i++) &#123; int val = ((int) md5Bytes[i]) &amp; 0xff; if (val &lt; 16) &#123; hexValue.append("0"); &#125; hexValue.append(Integer.toHexString(val)); &#125; return hexValue.toString(); &#125; 3. HMAC 算法 原理:用公开函数和密钥产生一个固定长度的值作为认证标识，用这个 标识鉴别消息的完整性。使用一个密钥生成一个固定大小的小数据块，即MAC，并将其加入到消息中，然后传输。接收方利用与发送方共享的密钥进行鉴别认证 等。 代码实现 1234567891011121314151617181920212223242526272829303132// 构建密钥public static byte[] getSecretKey()&#123; // 初始化 KeyGenerator keyGen = null; try &#123; keyGen = KeyGenerator.getInstance("HmacMD5"); &#125; catch (NoSuchAlgorithmException e1) &#123; e1.printStackTrace(); &#125; // 产生密钥 SecretKey secretKey1 = keyGen.generateKey(); // 得到密钥字节数组 byte[] key = secretKey1.getEncoded(); return key;&#125;// 执行消息摘要public static void doHMAC(byte[] data,String key)&#123; // 从字节数组还原 SecretKey secretKey2 = new SecretKeySpec(key,"HmacMD5"); try &#123; // 实例化 Mac Mac mac = Mac.getInstance("HmacMD5"); // 密钥初始化 Mac mac.init(secretKey2); // 执行消息摘要 byte[] result = mac.doFinal(data); &#125; catch (InvalidKeyException e) &#123; e.printStackTrace(); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125;&#125; 4. SHA 与 MD5比较1）对强行攻击的安全性：最显著和最重要的区别是SHA-1摘要比MD5摘要长32 位。使用强行技术，产生任何一个报文使其摘要等于给定报摘要的难度对MD5是2^128数量级的操作，而对SHA-1则是2^160数量级的操作。这样，SHA-1对强行攻击有更大的强度。2）对密码分析的安全性：由于MD5的设计，易受密码分析的攻击，SHA-1显得不易受这样的攻击。3）速度：在相同的硬件上，SHA-1的运行速度比MD5慢。 四、对称加密 定义：在对称加密算法中，数据发信方将明文（原始数据）和加密密钥（mi yue）一起经过特殊加密算法处理后，使其变成复杂的加密密文发送出去。收信方收到密文后，若想解读原文，则需要使用加密用过的密钥及相同算法的逆算法对密文进行解密，才能使其恢复成可读明文。在对称加密算法中，使用的密钥只有一个，发收信双方都使用这个密钥对数据进行加密和解密，这就要求解密方事先必须知道加密密钥。 优缺点 优点：算法公开、计算量小、加密速度快、加密效率高。 缺点：（1）交易双方都使用同样钥匙，安全性得不到保证。（2）每对用户每次使用对称加密算法时，都需要使用其他人不知道的惟一钥匙，这会使得发收信双方所拥有的钥匙数量呈几何级数增长，密钥管理成为用户的负担。对称加密算法在分布式网络系统上使用较为困难，主要是因为密钥管理困难，使用成本较高。 常用的对称加密算法。DES（Data Encryption Standard）：数据加密标准，速度较快，适用于加密大量数据的场合。3DES（Triple DES）：是基于DES，对一块数据用三个不同的密钥进行三次加密，强度更高。AES（Advanced Encryption Standard）：高级加密标准，是下一代的加密算法标准，速度快，安全级别最高 对称密码常用的数学运算 移位和循环移位 移位就是将一段数码按照规定的位数整体性地左移或右移。循环右移就是当右移时，把数码的最后的位移到数码的最前头，循环左移正相反。例如，对十进制数码12345678循环右移1位（十进制位）的结果为81234567，而循环左移1位的结果则为23456781。 置换 就是将数码中的某一位的值根据置换表的规定，用另一位代替。它不像移位操作那样整齐有序，看上去杂乱无章。这正是加密所需,被经常应用。 扩展 就是将一段数码扩展成比原来位数更长的数码。扩展方法有多种,例如,可以用置换的方法，以扩展置换表来规定扩展后的数码每一位的替代值。 压缩 就是将一段数码压缩成比原来位数更短的数码。压缩方法有多种，例如，也可以用置换的方法，以表来规定压缩后的数码每一位的替代值。 异或 这是一种二进制布尔代数运算。异或的数学符号为⊕ ，它的运算法则如下：1⊕ 1 = 00⊕ 0 = 01⊕ 0 = 10⊕ 1 = 1 也可以简单地理解为，参与异或运算的两数位如相等，则结果为0，不等则为1。 迭代 迭代就是多次重复相同的运算，这在密码算法中经常使用，以使得形成的密文更加难以破解。 分组加密参考 分组加密的四种模式ECB模式 – 电子密码本模式CBC模式 – 密码分组链接模式CFB模式 – 密文反馈模式OFB模式 – 输出反馈模式CTR模式 – 计数器模式 常用的填充方式在Java进行DES、3DES和AES三种对称加密算法时，常采用的是NoPadding（不填充）、Zeros填充（0填充）、PKCS5Padding填充。 ZerosPadding 全部填充为0的字节，结果如下： F1 F2 F3 F4 F5 F6 F7 F8 //第一块 F9 00 00 00 00 00 00 00 //第二块 PKCS5Padding 每个填充的字节都记录了填充的总字节数，结果如下： F1 F2 F3 F4 F5 F6 F7 F8 //第一块 F9 07 07 07 07 07 07 07 //第二块注： 如果 1. DES(Data Encryption Standard)1、 介绍：DES算法的入口参数有三个：Key、Data、Mode。Key为8个字节共64位，其中密钥 56 位，校验位 8 位(每组的 第8位都被用作奇偶校验)，是DES算法的工作密钥；Data也为8个字节64位，是要被加密或被解密的数据；Mode为DES的工作方式,有两种：加密或解密。 2、 加密过程：简略版: 首先要生成一套加密密钥，从用户处取得一个64位长的密码口令，然后通过等分、移位、选取和迭代形成一套16个加密密钥，分别供每一轮运算中使用。 过程 1，2 DES对64位(bit)的明文分组M进行操作，M经过一个初始置换IP，置换成m0。将m0明文分成左半部分和右半部分m0 = (L0，R0)，各32位长。然后进行16轮完全相同的运算（迭代），这些运算被称为函数f，在每一轮运算过程中数据与相应的密钥结合。 过程 4 在每一轮中，密钥位移位，然后再从密钥的56位中选出48位。通过一个扩展置换将数据的右半部分扩展成48位，并通过一个异或操作替代成新的48位数据，再将其压缩置换成32位。这四步运算构成了函数f。然后，通过另一个异或运算，函数f的输出与左半部分结合，其结果成为新的右半部分，原来的右半部分成为新的左半部分。将该操作重复16次。 过程 3 ，5 ，6 ，7 ， 8 ， 9 经过16轮迭代后，左，右半部分合在一起经过一个逆置换（数据整理），恢复原先的顺序，这样就完成了加密过程。 过程 10. 详细版请见 附录 3、 解密过程 加密和解密使用相同的算法！ DES加密和解密唯一的不同是密钥的次序相反。如果各轮加密密钥分别是K1，K2，K3…K16，那么解密密钥就是K16，K15，K14…K1。这也就是DES被称为对称算法的理由吧。 4、流程如图： 5、注意：DES算法中只用到64位密钥中的其中56位，而第8、16、24、……64位8个位并未参与DES运算 6、3DES3DES（或称为Triple DES） 原理： 使用3条56位的密钥对 数据进行三次加密。 7、Java 实现相关的类：123456// 生成密钥KeyGenerator,SecretKeyFactory// 密钥SecretKey , SecretKeySpec// 密码Cipher 这里重点讲一下 Cipher 类 首先要设置参数Cipher.getInstance(加解密算法，加解密模式，填充模式) 初始化Cipher.init(加解密模式 – Cypher.ENCRIPT/DECRYPT，密钥） 完成加解密Cipher.doFinal(bytes) – 将bytes 内容 加密/解密 然后返回。 这里使用 SecretKeyFactory的密钥 选择CBC模式 进行加解密。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class DESCryptography &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub String content="aaaaaaaabbbbbbbbaaaaaaaa"; String key="01234567"; System.out.println("加密前："+byteToHexString(content.getBytes())); byte[] encrypted=DES_CBC_Encrypt(content.getBytes(), key.getBytes()); System.out.println("加密后："+byteToHexString(encrypted)); byte[] decrypted=DES_CBC_Decrypt(encrypted, key.getBytes()); System.out.println("解密后："+byteToHexString(decrypted)); &#125; public static byte[] DES_CBC_Encrypt(byte[] content, byte[] keyBytes)&#123; try &#123; DESKeySpec keySpec=new DESKeySpec(keyBytes); SecretKeyFactory keyFactory=SecretKeyFactory.getInstance("DES"); SecretKey key=keyFactory.generateSecret(keySpec); Cipher cipher=Cipher.getInstance("DES/CBC/PKCS5Padding"); cipher.init(Cipher.ENCRYPT_MODE, key, new IvParameterSpec(keySpec.getKey())); byte[] result=cipher.doFinal(content); return result; &#125; catch (Exception e) &#123; // TODO Auto-generated catch block System.out.println("exception:"+e.toString()); &#125; return null; &#125; public static byte[] DES_CBC_Decrypt(byte[] content, byte[] keyBytes)&#123; try &#123; DESKeySpec keySpec=new DESKeySpec(keyBytes); SecretKeyFactory keyFactory=SecretKeyFactory.getInstance("DES"); SecretKey key=keyFactory.generateSecret(keySpec); Cipher cipher=Cipher.getInstance("DES/CBC/PKCS5Padding"); cipher.init(Cipher.DECRYPT_MODE, key, new IvParameterSpec(keyBytes)); byte[] result=cipher.doFinal(content); return result; &#125; catch (Exception e) &#123; // TODO Auto-generated catch block System.out.println("exception:"+e.toString()); &#125; return null; &#125; public static String byteToHexString(byte[] bytes) &#123; StringBuffer sb = new StringBuffer(bytes.length); String sTemp; for (int i = 0; i &lt; bytes.length; i++) &#123; sTemp = Integer.toHexString(0xFF &amp; bytes[i]); if (sTemp.length() &lt; 2) sb.append(0); sb.append(sTemp.toUpperCase()); &#125; return sb.toString(); &#125; private static byte toByte(char c) &#123; byte b = (byte) "0123456789ABCDEF".indexOf(c); return b; &#125; &#125; 2. AES(Advanced Encryption Standard)有时间 再写。。。 看了一天的 加密 ，累死。。。 五、非对称加密1. 基础定义：需要两个密钥，一个是公开密钥，另一个是私有密钥；一个用作加密的时候，另一个则用作解密。使用其中一个密钥把明文加密后所得的密文，只能用相对应的另一个密钥才能解密得到原本的明文；甚至连最初用来加密的密钥也不能用作解密。由于加密和解密需要两个不同的密钥，故被称为非对称加密 数论知识： 非对称加密运用了一部分数论知识，有兴趣的自己去看下。。。 这里提供一下链接。阮一峰大神写了一部分，可以帮助理解 一、互质关系： 如果两个正整数，除了1以外，没有其他公因子，我们就称这两个数是互质关系（coprime）。比如，15和32没有公因子，所以它们是互质关系。这说明，不是质数也可以构成互质关系。二、欧拉函数三、欧拉定理)四、模反元素(模逆元)五、扩展欧几里得算法 2. RSA 算法2.1 过程 随机选择两个不相等的质数 p 和 q p = 61, q = 53 计算 p 和 q 的乘积 n n = 61*53 = 3233 计算 n 的欧拉函数 φ(n) φ(n) = (p-1)(q-1) = 60 * 52 = 3120 随机选择一个整数 e ， 条件是 1 &lt; e &lt; φ(n) , 且 e 与 φ(n) 互质 e = 17 ( 实际应用中，常常选择 65537 ) 计算 e 对于 φ(n) 的模反元素 d 12345678910所谓"模反元素"就是指有一个整数d，可以使得ed被φ(n)除的余数为1。 ed ≡ 1 (mod φ(n))这个式子等价于 ed - 1 = kφ(n)于是，找到模反元素d，实质上就是对下面这个二元一次方程求解。 ex + φ(n)y = 1已知 e=17, φ(n)=3120， 17x + 3120y = 1这个方程可以用"扩展欧几里得算法"求解，此处省略具体过程。总之，爱丽丝算出一组整数解为 (x,y)=(2753,-15)，即 d=2753。至此所有计算完成。 将 n 和 e 封装成公钥， n 和 d 封装成私钥 公钥 (3233,17), 私钥 (3233，2753) 加密与解密 加密用 (n , e) 加密信息 – 明文为 m , m 小于 n $m^e$ ≡ c (mod n) 公钥是 (3233，17), m 假设为 65 $65^{17}$ ≡ 2790(mod 3233) 所以 c = 2790 解密用 (n , d) 密文 为 c $c^d$ ≡ m(mod n) $2790^{2753}$ ≡ 65 (mod 3233) 所以 m = 65 私钥解密的证明 – 有兴趣的同学自己去找资料看下,也是数论的知识。 2.2 RSA 算法的可靠性 与 破解以上密钥的生成步骤，出现了六个数字 p, q, n, φ(n), e, d公钥为 n, e如果想要得到 d，需要进行以下逆推123 （1）ed≡1 (mod φ(n))。只有知道e和φ(n)，才能算出d。 （2）φ(n)=(p-1)(q-1)。只有知道p和q，才能算出φ(n)。 （3）n=pq。只有将n因数分解，才能算出p和q。 所以 如果将 n 进行 因数分解，就意味着私钥被破解。 可是，大整数的因数分解，是一件非常困难的事情。目前，除了暴力破解，还没有发现别的有效方法。 注意:这里说大整数，不是 像上文 3233 这样的数字，历史上最大的已经进行因数分解的整数为123456789 12301866845301177551304949 58384962720772853569595334 79219732245215172640050726 36575187452021997864693899 56474942774063845925192557 32630345373154826850791702 61221429134616704292143116 02221240479274737794080665 351419597459856902143413 它等于这样两个质数的乘积1234567891011 33478071698956898786044169 84821269081770479498371376 85689124313889828837938780 02287614711652531743087737 814467999489 × 36746043666799590428244633 79962795263227915816434308 76426760322838157396665112 79233373417143396810270092 798736308917 破解： 这里有一篇关于 RSA 破解的文章，有兴趣的同学可以看一下。RSA计时攻击 2.3 Java 实现使用到的类： java.security12345678910// 生成 公钥，密钥KeyPairGenerator --&gt; KeyPair , KeyFactory --&gt; RSA XXX Spec// 公钥 密钥KeyPairRSAPublicKeySpec --&gt; RSAPublicKeyRSAPrivateKeySpec --&gt; RSAPrivateKey// 密码Cipher -- 1.Cipher.getInstance("RSA") 2.init(mode, key) 3.cipher.doFinal() 12345678910111213141516171819202122232425public static void main(String[] args) throws Exception &#123; // TODO Auto-generated method stub HashMap&lt;String, Object&gt; map = RSAUtils.getKeys(); //生成公钥和私钥 RSAPublicKey publicKey = (RSAPublicKey) map.get("public"); RSAPrivateKey privateKey = (RSAPrivateKey) map.get("private"); //模 String modulus = publicKey.getModulus().toString(); //公钥指数 String public_exponent = publicKey.getPublicExponent().toString(); //私钥指数 String private_exponent = privateKey.getPrivateExponent().toString(); //明文 String ming = "123456789"; //使用模和指数生成公钥和私钥 RSAPublicKey pubKey = RSAUtils.getPublicKey(modulus, public_exponent); RSAPrivateKey priKey = RSAUtils.getPrivateKey(modulus, private_exponent); //加密后的密文 String mi = RSAUtils.encryptByPublicKey(ming, pubKey); System.err.println(mi); //解密后的明文 ming = RSAUtils.decryptByPrivateKey(mi, priKey); System.err.println(ming); &#125; RSAUtils.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202public class RSAUtils &#123; /** * 生成公钥和私钥 * @throws NoSuchAlgorithmException * */ public static HashMap&lt;String, Object&gt; getKeys() throws NoSuchAlgorithmException&#123; HashMap&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance("RSA"); keyPairGen.initialize(1024); KeyPair keyPair = keyPairGen.generateKeyPair(); RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate(); map.put("public", publicKey); map.put("private", privateKey); return map; &#125; /** * 使用模和指数生成RSA公钥 * 注意：【此代码用了默认补位方式，为RSA/None/PKCS1Padding，不同JDK默认的补位方式可能不同，如Android默认是RSA * /None/NoPadding】 * * @param modulus * 模 * @param exponent * 指数 * @return */ public static RSAPublicKey getPublicKey(String modulus, String exponent) &#123; try &#123; BigInteger b1 = new BigInteger(modulus); BigInteger b2 = new BigInteger(exponent); KeyFactory keyFactory = KeyFactory.getInstance("RSA"); RSAPublicKeySpec keySpec = new RSAPublicKeySpec(b1, b2); return (RSAPublicKey) keyFactory.generatePublic(keySpec); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 使用模和指数生成RSA私钥 * 注意：【此代码用了默认补位方式，为RSA/None/PKCS1Padding，不同JDK默认的补位方式可能不同，如Android默认是RSA * /None/NoPadding】 * * @param modulus * 模 * @param exponent * 指数 * @return */ public static RSAPrivateKey getPrivateKey(String modulus, String exponent) &#123; try &#123; BigInteger b1 = new BigInteger(modulus); BigInteger b2 = new BigInteger(exponent); KeyFactory keyFactory = KeyFactory.getInstance("RSA"); RSAPrivateKeySpec keySpec = new RSAPrivateKeySpec(b1, b2); return (RSAPrivateKey) keyFactory.generatePrivate(keySpec); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 公钥加密 * * @param data * @param publicKey * @return * @throws Exception */ public static String encryptByPublicKey(String data, RSAPublicKey publicKey) throws Exception &#123; Cipher cipher = Cipher.getInstance("RSA"); cipher.init(Cipher.ENCRYPT_MODE, publicKey); // 模长 int key_len = publicKey.getModulus().bitLength() / 8; // 加密数据长度 &lt;= 模长-11 String[] datas = splitString(data, key_len - 11); String mi = ""; //如果明文长度大于模长-11则要分组加密 for (String s : datas) &#123; mi += bcd2Str(cipher.doFinal(s.getBytes())); &#125; return mi; &#125; /** * 私钥解密 * * @param data * @param privateKey * @return * @throws Exception */ public static String decryptByPrivateKey(String data, RSAPrivateKey privateKey) throws Exception &#123; Cipher cipher = Cipher.getInstance("RSA"); cipher.init(Cipher.DECRYPT_MODE, privateKey); //模长 int key_len = privateKey.getModulus().bitLength() / 8; byte[] bytes = data.getBytes(); byte[] bcd = ASCII_To_BCD(bytes, bytes.length); System.err.println(bcd.length); //如果密文长度大于模长则要分组解密 String ming = ""; byte[][] arrays = splitArray(bcd, key_len); for(byte[] arr : arrays)&#123; ming += new String(cipher.doFinal(arr)); &#125; return ming; &#125; /** * ASCII码转BCD码 * */ public static byte[] ASCII_To_BCD(byte[] ascii, int asc_len) &#123; byte[] bcd = new byte[asc_len / 2]; int j = 0; for (int i = 0; i &lt; (asc_len + 1) / 2; i++) &#123; bcd[i] = asc_to_bcd(ascii[j++]); bcd[i] = (byte) (((j &gt;= asc_len) ? 0x00 : asc_to_bcd(ascii[j++])) + (bcd[i] &lt;&lt; 4)); &#125; return bcd; &#125; public static byte asc_to_bcd(byte asc) &#123; byte bcd; if ((asc &gt;= '0') &amp;&amp; (asc &lt;= '9')) bcd = (byte) (asc - '0'); else if ((asc &gt;= 'A') &amp;&amp; (asc &lt;= 'F')) bcd = (byte) (asc - 'A' + 10); else if ((asc &gt;= 'a') &amp;&amp; (asc &lt;= 'f')) bcd = (byte) (asc - 'a' + 10); else bcd = (byte) (asc - 48); return bcd; &#125; /** * BCD转字符串 */ public static String bcd2Str(byte[] bytes) &#123; char temp[] = new char[bytes.length * 2], val; for (int i = 0; i &lt; bytes.length; i++) &#123; val = (char) (((bytes[i] &amp; 0xf0) &gt;&gt; 4) &amp; 0x0f); temp[i * 2] = (char) (val &gt; 9 ? val + 'A' - 10 : val + '0'); val = (char) (bytes[i] &amp; 0x0f); temp[i * 2 + 1] = (char) (val &gt; 9 ? val + 'A' - 10 : val + '0'); &#125; return new String(temp); &#125; /** * 拆分字符串 */ public static String[] splitString(String string, int len) &#123; int x = string.length() / len; int y = string.length() % len; int z = 0; if (y != 0) &#123; z = 1; &#125; String[] strings = new String[x + z]; String str = ""; for (int i=0; i&lt;x+z; i++) &#123; if (i==x+z-1 &amp;&amp; y!=0) &#123; str = string.substring(i*len, i*len+y); &#125;else&#123; str = string.substring(i*len, i*len+len); &#125; strings[i] = str; &#125; return strings; &#125; /** *拆分数组 */ public static byte[][] splitArray(byte[] data,int len)&#123; int x = data.length / len; int y = data.length % len; int z = 0; if(y!=0)&#123; z = 1; &#125; byte[][] arrays = new byte[x+z][]; byte[] arr; for(int i=0; i&lt;x+z; i++)&#123; arr = new byte[len]; if(i==x+z-1 &amp;&amp; y!=0)&#123; System.arraycopy(data, i*len, arr, 0, y); &#125;else&#123; System.arraycopy(data, i*len, arr, 0, len); &#125; arrays[i] = arr; &#125; return arrays; &#125; &#125; 2.4 问题 公钥(n,e) 只能 加密小于 n 的整数 m ，那么如果要加密大于 n 的整数，怎么办？在 Java 中 进行 RSA 加密时，有 一个 错误为 ArrayIndexOutOfBoundsException: too much data for RSA block该错误就是加密数据过长导致的。 这里涉及到几个知识点 – 密钥长度/密文长度/明文长度 明文长度 明文长度(bytes) &lt;= 密钥长度(bytes)-11. 如果 明文长度 大于 规定，则出现上述的问题，可以按照下文中的解决方法处理 密钥长度 下限是96bits(12bytes) 上限未知。不过目前为止，被破解的最长的密钥长度 为 768位，所以 1024 位基本安全， 2048 位绝对安全 密文长度 不分片加密 – 密文长度 == 密钥长度 分片加密– 密文长度 == 密钥长度分片数 例如 明文 8 bytes , 密钥 128 bits 每片明文长度 = 128/8 - 11 = 5 bytes 分片数 = 8/5 +1 = 2 密文长度 = 128/8 2 = 32 bytes 解决方法 分片加密 – 是把长信息分割成若干段短消息，每段分别加密； 先选择一种”对称性加密算法”（比如DES），用这种算法的密钥加密信息，再用RSA公钥加密DES密钥。 附录1. DES 详细加密过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031. **对输入的密钥进行变换**。 用户的64bit密钥，其中第8， 16， 24， 32， 40， 48， 56， 64位是校验位， 使得每个密钥都有奇数个1。所以密钥事实上是56位。对这56位密钥进行如下表的换位。57, 49, 41, 33, 25, 17, 9, 1, 58, 50, 42, 34, 26, 18, 10, 2, 59, 51, 43, 35, 27, 19, 11, 3, 60, 52, 44, 36, 63, 55, 47, 39, 31, 23, 15, 7, 62, 54, 46, 38, 30, 22, 14, 6, 61, 53, 45, 37, 29, 21, 13, 5, 28, 20, 12, 4,表的意思是第57位移到第1位，第49位移到第2位，...... 以此类推。变换后得到56bit数据，将它分成两部分，C[0][28], D[0][28]。2. **计算16个子密钥**，计算方法C[i][28] D[i][28]为对前一个C[i-1][28], D[i-1][28]做循环左移操作。16次的左移位数如下表: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16 （第i次) 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1 (左移位数)3. **串联**计算出来的C[i][28] D[i][28] 得到56位，然后对它进行如下变换得到48位子密钥K[i][48]14, 17, 11, 24, 1, 5, 3, 28, 15, 6, 21, 10, 23, 19, 12, 4, 26, 8, 16, 7, 27, 20, 13, 2,41, 52, 31, 37, 47, 55, 30, 40, 51, 45, 33, 48, 44, 49, 39, 56, 34, 53, 46, 42, 50, 36, 29, 32,表的意思是第14位移到第1位，第17位移到第2位，以此类推。在此过程中，发现第9，18，22，25， 35，38，43，54位丢弃。4. 对64bit的明文输入进行换位变换。换位表如下:58, 50, 12, 34, 26, 18, 10, 2, 60, 52, 44, 36, 28, 20, 12, 4,62, 54, 46, 38, 30, 22, 14, 6, 64, 56, 48, 40, 32, 24, 16, 8,57, 49, 41, 33, 25, 17, 9, 1, 59, 51, 43, 35, 27, 19, 11, 3,61, 53, 45, 37, 29, 21, 13, 5, 63, 55, 47, 39, 31, 23, 15, 7表的意思就是第一次变换时，第58位移到第1位，第50位移到第2位，...... 依此类推。得到64位数据，将这数据前后分成两块L[0][32], R[0][32]。5. 加密过程，对R[i][32]进行扩展变换成48位数，方法如下， 记为E(R[i][32])32, 1, 2, 3, 4, 5, 4, 5, 6, 7, 8, 9, 8, 9, 10, 11, 12, 13, 12, 13, 14, 15, 16, 17,16, 17, 18, 19, 20, 21,20, 21, 22, 23, 24, 25, 24, 25, 26, 27, 28, 29,28, 29, 30, 31, 32, 1,6. 将E(R[i][32])与K[i][48]作异或运算，得到48位数，将48位数顺序分成8份，6位一份，B[8][6]。7. 使用S[i]替换B[i][6]。过程如下: 取出B[i][6]的第1位和第6位连成一个2位数m， m就是S[i]中对应的行数(0-3)，取出B[i][6]的第2到第5位连成一个4位数n(0-15)，n就是S[i]中对应的列数，用S[i][m][n]代替B[i][6]。S是4行16列的对应表，里面是4位的数，一共有8个S，定义如下:S[1]: 14,4,13,1,2,15,11,8,3,10,6,12,5,9,0,7, 0,15,7,4,14,2,13,1,10,6,12,11,9,5,3,8, 4,1,14,8,13,6,2,11,15,12,9,7,3,10,5,0, 15,12,8,2,4,9,1,7,5,11,3,14,10,0,6,13,S[2]: 15,1,8,14,6,11,3,4,9,7,2,13,12,0,5,10, 3,13,4,7,15,2,8,14,12,0,1,10,6,9,11,5, 0,14,7,11,10,4,13,1,5,8,12,6,9,3,2,15, 13,8,10,1,3,15,4,2,11,6,7,12,0,5,14,9,S[3]: 10,0,9,14,6,3,15,5,1,13,12,7,11,4,2,8, 13,7,0,9,3,4,6,10,2,8,5,14,12,11,15,1, 13,6,4,9,8,15,3,0,11,1,2,12,5,10,14,7, 1,10,13,0,6,9,8,7,4,15,14,3,11,5,2,12,S[4]: 7,13,14,3,0,6,9,10,1,2,8,5,11,12,4,15, 13,8,11,5,6,15,0,3,4,7,2,12,1,10,14,9, 10,6,9,0,12,11,7,13,15,1,3,14,5,2,8,4, 3,15,0,6,10,1,13,8,9,4,5,11,12,7,2,14, S[5]: 2,12,4,1,7,10,11,6,8,5,3,15,13,0,14,9, 14,11,2,12,4,7,13,1,5,0,15,10,3,9,8,6, 4,2,1,11,10,13,7,8,15,9,12,5,6,3,0,14, 11,8,12,7,1,14,2,13,6,15,0,9,10,4,5,3, S[6]: 12,1,10,15,9,2,6,8,0,13,3,4,14,7,5,11, 10,15,4,2,7,12,9,5,6,1,13,14,0,11,3,8, 9,14,15,5,2,8,12,3,7,0,4,10,1,13,11,6, 4,3,2,12,9,5,15,10,11,14,1,7,6,0,8,13, S[7]: 4,11,2,14,15,0,8,13,3,12,9,7,5,10,6,1, 13,0,11,7,4,9,1,10,14,3,5,12,2,15,8,6, 1,4,11,13,12,3,7,14,10,15,6,8,0,5,9,2, 6,11,13,8,1,4,10,7,9,5,0,15,14,2,3,12, S[8]: 13,2,8,4,6,15,11,1,10,9,3,14,5,0,12,7, 1,15,13,8,10,3,7,4,12,5,6,11,0,14,9,2, 7,11,4,1,9,12,14,2,0,6,10,13,15,3,5,8, 2,1,14,7,4,10,8,13,15,12,9,0,3,5,6,11,8. 将从B[i][6]经过S得到的8个4位数连起来得到32位数。对这个数进行如下变换: 16,7,20,21,29,12,28,17, 1,15,23,26, 5,18,31,10, 2,8,24,14,32,27, 3, 9,19,13,30, 6,22,11, 4,25, 得到的结果与L[i][32]作异或运算，把结果赋给R[i][32]。9. 把R[i-1][32]的值赋给L[i]，从5开始循环。直到K[16][48]结束。10. 将最后的L,R合并成64位，然后进行如下转化得到最后的结果。这是对第4步的一个逆变化。 40, 8, 48, 16, 56, 24, 64, 32, 39, 7, 47, 15, 55, 23, 63, 31, 38, 6, 46, 14, 54, 22, 62, 30, 37, 5, 45, 13, 53, 21, 61, 29, 36, 4, 44, 12, 52, 20, 60, 28, 35, 3, 43, 11, 51, 19, 59, 27, 34, 2, 42, 10, 50, 18, 58, 26, 33, 1, 41, 9, 49, 17, 57, 25 2. https 的加密算法 由于之前看过 https 是 由 secure socket layer 实现的。 也是通过 公钥私钥 保证其安全性，所以在学习这篇文章的时候，就想 https 是由哪种 加密算法 做为其 底层实现的呢。 因此，就有了下面这部分。 关于 https 与 http 的区别 请看我的这篇博客，不再赘述。网络基础知识 原理： 浏览器把自身支持的一系列Cipher Suite（密钥算法套件，后文简称Cipher）[C1,C2,C3, …]发给服务器； 服务器接收到浏览器的所有Cipher后，与自己支持的套件作对比，如果找到双方都支持的Cipher，则告知浏览器； 浏览器与服务器使用匹配的Cipher进行后续通信。如果服务器没有找到匹配的算法，浏览器（以 Chrome 56为例）将给出错误信息: 下面讲一下如何分析。 准备： 通过可以抓取网络包的工具，这里通过 Wireshark 分析。关于wireshark 的介绍请点击这里.查看浏览器发送给服务器的 Ciper服务器的 Ciper 流程： 浏览器首先发起握手协议， 一个’Client Hello’消息，如下图，按照Protocol协议顺序排序，然后，找到Client Hello，选中，依次查找 ‘Secure Sockets Layer’ -&gt; TLSv1.2 Record Layer -&gt; Handshake protocal -&gt;Ciper Suites. 可以看到， Cipher有很多。总共16，第一个是Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b)。 如果按照顺序继续寻找第一个 Info 为’Sever Hello’ 的报文，可以找到相应的Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b) 。. Cipher介绍： 密钥交换算法，用于决定客户端与服务器之间在握手的过程中如何认证，用到的算法包括RSA，Diffie-Hellman，ECDH，PSK等 加密算法，用于加密消息流，该名称后通常会带有两个数字，分别表示密钥的长度和初始向量的长度，比如DES 56/56, RC2 56/128, RC4 128/128, AES 128/128, AES 256/256 报文认证信息码（MAC）算法，用于创建报文摘要，确保消息的完整性（没有被篡改），算法包括MD5，SHA等。 PRF（伪随机数函数），用于生成“master secret”。 TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b): 基于TLS协议 使用 ECDHE,ECDSA作为密钥交换算法 加密算法 AES(密钥与初始向量的长度为128) MAC 算法 SHA 总结：Client端密钥算法套件[C1,C2,C3],Server端密钥算法套件[C4,C2,C1,C3]，则，IIS(Internet Infomation Services)，C2将被优先返回 3. wireshark 的使用问题问题:第一次使用 wireshark 的时候，不显示接口。原因是。。。刚开始使用 在windows 上需要 winpacp 并且开启 npf 服务。注： 如果 没有安装 winpacp ，想直接 通过 net start npf 开启服务，将会提示。 发生系统错误2 winpacp 安装 。。。这里是下载网站直接安装即可。 开启 npf 服务打开 cmd ,输入 net start npf ,提示：服务已经启动。 进入界面，选择相应的网卡。这里，可以通过 网络连接 看出来。所以，我的是无线网络连接。 最终界面WireShark 主要分为这几个界面 Display Filter(显示过滤器)， 用于过滤 Packet List Pane(封包列表)， 显示捕获到的封包， 有源地址和目标地址，端口号。 颜色不同，代表 Packet Details Pane(封包详细信息), 显示封包中的字段 Dissector Pane(16进制数据) Miscellanous(地址栏，杂项) 结语都看到这里了，点个关注,点波赞再走，QAQ。你的小手轻点，是我最大的动力哦。 一只想当程序员的1米88处女座大可爱如此说。 参考 DES 加密算法解析 分组加密的四种模式 阮一峰–RSA算法原理 java中RSA加解密的实现 关于RSA算法密钥长度/密文长度/明文长度 https背后的加密算法]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逐梦offer -- 网络基础知识总结]]></title>
    <url>%2Fblogs%2F28952.html</url>
    <content type="text"><![CDATA[1. 网络基础1.1 OSI 7层模型 与 TCP/IP 四层模型OSI 7层模型 物理层：负责 0，1 比特流与电压高低、光的闪灭之间的互换 设备： 中继器：将电缆传过来的电信号与光信号经中继器的波形调整与放大传给另一个。 数据链路层： 负责数据帧与比特流的转换 设备： 网桥：通过 MAC 地址连接两个网络。通过CRC（cyclic redundancy check 循环冗余校验）的方式对数据链路层中的 FCS（frame check sequence) 验证。从而确保数据的完整性。 网络层：负责寻址与路由的选择 设备： 路由器：根据IP 地址进行处理。 传输层：管理两个节点之间数据的传输。确保数据被可靠的传送到目标地址，检测是否有数据丢失。 会话层：负责建立和断开通信连接 表示层：负责数据格式的转换 应用层：针对特定应用的协议 4-7层交换机 网关：负责从传输层到应用层的数据进行转换和转发的设备。 TCP/IP 四层模型包为描述数据的全能型单位。 网络接口层 单位：帧 相关技术： MAC 地址: 使用网卡(NIC) , 有唯一性 共享介质型网络：半双工通信，只发送或只接收的方式1、争用方式（CSMA （carrier sense multiple access) - 载波监听多路访问）2、令牌传递方式 非共享介质型网络：双工通信每个站直连交换机，由交换机负责转发数据帧。 以太网帧格式： MAC(介质访问控制层)+LLC(逻辑链路控制层)+SNAP+IP+TCP+上层数据+FCS 网络层 协议：IP / ICMP / ARP（Address Resolution Protocol) / NAT / DHCP / DNS 相关技术： Hop : 数据链路层以下分层的传输数据帧的一个区间。是主机或路由器网卡不经其他路由器而能直接到达的对象之间的一个区间。 MTU (Maximum Transmission Unit): 最大传输单位 ARP : 通过 IP 地址 得到 MAC 地址 – RARP ： MAC 得到 IP ICMP ：确认网络的正常使用，以及异常的排查 消息类型： 类型3 ：目标不可达 类型5 ：重定向 类型11 ：超时 TTL Time To Live 防止IP 包无限制的传递下去 类型0 ：向对方发送消息 类型8 ：接收对方发送的消息 ping 命令就是 类型0、8 。 NAT(Network Adddress Translator) : 由本地网络中的私有地址转换为全局 IP 地址。 DNS ：域名命名系统 – 使用 TCP 53号端口 DHCP ：动态域名控制协议 路由控制 传输层 协议：TCP / UDP 应用层 协议：WWW / HTTP / MIME，SMTP、POP、IMPA / FTP / TELNET - SSH / SNMP 相关技术： FTP ：用两条 TCP 连接： 1、数据控制 ， 使用 21号端口 2、数据传输 ， 使用 20号端口 3、状态码： 1-提供信息，2-连接管理，3-用户相关，4-错误，5-文件系统 HTTP : 使用 80 端口 1、 主要命令：GET.PUT.POST.DELETE.OPTIONS.HEAD.TRACE 2、 状态码： 1-提供信息，2-肯定应答，3-重写向请求，4-客户端请求内容错误，5-服务器错误 HTTPS : 使用 443 端口 1.2 TCP / UDPSYN (Synchronize Flag) ACK(Acknowledgement Flag) FIN(Fin Flag)TCP 的三次握手 客户端 –》 SYN SYN ACK 《– 服务器 客户端 –》SYN 四次挥手 客户端 –》 FIN ACK 《– 服务器 FIN 《– 服务器 客户端 –》 ACK MSS(Maximum Segment Size) 最大消息长度：由三次握手的时候，两端主机会在TCP首部写入 MSS 长度，通过比较，取得其中比较少的值 窗口控制原先的缺点：TCP 以一个段为单位，每发一个段进行一次确认应答的处理。包的往返时间越长，通信性能越低。因此引入窗口这个概念。窗口大小是指无需等待确认应答，而可以继续发送数据的最大值。使用大量的缓冲区，如果有部分数据丢包，发送端主机设置缓存保留这些数据，直至收到它们的确认应答。如果没有丢包，就滑动窗口到下一个位置 重发控制窗口在一定程度上较大时，即使有少部分的确认应答丢失也不会进行数据重发。可以通过下一个确认应答确认。当某一报文段丢失后，发送端会一直收到序号为原数据的确认应答。连续 3 次 同一个确认应答，会进行重发 流控制TCP 首部中有专门的字段用来通知窗口的大小接收主机将自己可以接收的缓冲区大小放入这个字段中通知给发送端，这个字段的值越大，说明网络的吞吐量越高 拥塞控制慢启动：通过拥塞窗口，第一次大小为 1 MSS ， 以后每次 收到一次确认应答（ACK）,拥塞窗口的值 加 1.然后比较 两端 窗口的 大小，发送比小值还的小的数。 1.3 路由协议 静态路由 与 动态路由 AS (Autonomous System) 与 路由选择域(Routing Domain) 内部使用 IGP (Interior Gateway Protocol) 外部使用 EGP (Exterior Gateway Protocol). IGP 中可以使用 RIP (Routing Information Protocol) , OSPF(Open Shortest Path First); RIP – 距离向量(Distance-Vector)协议:通过距离与方向决定目标网络或主机位置。 OSPF – 链路状态(Link-State)协议：了解网络整体连接状态的基础上生成路由控制表。 将每条链路赋予一个权重，采用 Dijkstra 算法(最短路径优先算法)生成相应的路由控制表。 权重，是通过 HELLO 协议， HELLO包在LAN中传递，3 次以上空等后，使用链路状态更新包(Link state update package) 通知状态的改变。 链路状态更新包 传达 ： 网络 LSA(Link State Advertisement 链路状态通告) , 路由器 LSA 信息。 从而让 路由器生成链路状态数据库。 EGP 中使用 BGP(Border Gateway Protocol) BGP – 路径向量(Path-Vector)协议： 总结 ： 路由选择时的度量 ， RIP表现为 路由器个数， OSPF则是每个子网的成本， BGP 为 AS 的个数。 1.4 HTTP1. get与postHttp 定义了服务器交互的不同方法 ，最基本的有四种 ：GET查, POST改,PUT增,DELETE删。 get一般用于信息获取，是安全与幂等的。 安全指。该操作用于获取信息，所以不会对数据有什么破坏。 幂等意味着 对同一URL 的多个请求返回同样的结果。 post表示可能修改服务器上的资源的请求。 区别： GET请求的数据会附在URL之后，以 ？分割URL和传输数据，参数之间用&amp;相连。 post 方式则是将提交的数据放置在 HTTP 包的 包体中。 GET方式提交的数据有限制，是因为特定的浏览器及服务器对它的限制，URL不存在参数上限的问题。HTTP规范中并没有对URL长度进行限制。 post方式提交的大小是没有限制的，限制的是服务器的处理程序的处理能力。 POST比GET 提交的安全性高，是因为GET提交数据，用户名和密码是明文出现在URL上，POST数据是隐藏到HTTP包的包体中的。抓包时，仍然可以看见。 2. session与cookieHTTP协议 （ http://www.w3.org/Protocols/ ）是“一次性单向”协议。服务端不能主动连接客户端，只能被动等待并答复客户端请求。客户端连接服务端，发出一个HTTP Request，服务端处理请求，并且返回一个HTTP Response给客户端，本次HTTP Request-Response Cycle结束。Session ID实际上是在客户端和服务端之间通过HTTP Request和HTTP Response传来传去的。 Session对象在浏览器中的有效范围：IE中: Session对象只在建立Session对象的窗口中有效。 在建立Session对象的窗口中新开链接的窗口也有效。Session只会在内存中，他会随着IE窗口的关闭而死亡。也就是说单用seesion是不会有产生自动登入的效果的。 Cookie 是在服务器给客户端IE一个命令后在客户端产生并存的，它可以存放用户信息，存到客户端硬盘上，在COOKIE记录被删除或者失效日期之前，就可以实现自动登入的现象。 Session 和 Cookie 是不同的，但是他们确实是相关的。当打开IE登入后，会向服务器发出一个指令请求SESSIONID以及页面内容，服务器会返回页面内容和一个没有被使用的SESSIONID让此IE使用，当时IE就对返回SESSIONID做存储；而当此IE再访问任何这个站点的JSP程序的时候,都会给服务器这个 SESSIONID，来确认客户端的身份。（在没有Cookie 的情况下session死亡 SESSIONID被取消就需要重新登入） 3. http 与 https 的区别一、HTTP1.支持客户/服务器模式。2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。3.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。5.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 1) HTTP协议详解之请求篇 http请求由三部分组成，分别是：请求行、消息报头、请求正文 1、请求行以一个方法符号开头，以空格分开，后面跟着请求的URI和协议的版本，格式如下： Method Request-URI HTTP-Version CRLF 其中 Method表示请求方法；Request-URI是一个统一资源标识符；HTTP-Version表示请求的HTTP协议版本；CRLF表示回车和换行（除了作为结尾的CRLF外，不允许出现单独的CR或LF字符）。 请求方法（所有方法全为大写）有多种，各个方法的解释如下： GET 请求获取Request-URI所标识的资源 POST 在Request-URI所标识的资源后附加新的数据 HEAD 请求获取由Request-URI所标识的资源的响应消息报头 PUT 请求服务器存储一个资源，并用Request-URI作为其标识 DELETE 请求服务器删除Request-URI所标识的资源 TRACE 请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT 保留将来使用 OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求 2、请求报头后述 3、请求正文(略) 2) HTTP协议详解之响应篇 在接收和解释请求消息后，服务器返回一个HTTP响应消息。 HTTP响应也是由三个部分组成，分别是：状态行、消息报头、响应正文 1、状态行格式如下： HTTP-Version Status-Code Reason-Phrase CRLF 其中，HTTP-Version表示服务器HTTP协议的版本；Status-Code表示服务器发回的响应状态代码；Reason-Phrase表示状态代码的文本描述。 状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值： 1xx：指示信息–表示请求已接收，继续处理 2xx：成功–表示请求已被成功接收、理解、接受 3xx：重定向–要完成请求必须进行更进一步的操作 4xx：客户端错误–请求有语法错误或请求无法实现 5xx：服务器端错误–服务器未能实现合法的请求 常见状态代码、状态描述、说明： 200 OK //客户端请求成功 400 Bad Request //客户端请求有语法错误，不能被服务器所理解 401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务 404 Not Found //请求资源不存在，eg：输入了错误的URL 500 Internal Server Error //服务器发生不可预期的错误 503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 eg：HTTP/1.1 200 OK （CRLF） 2、响应报头后述 3、响应正文就是服务器返回的资源的内容 3) HTTP协议详解之消息报头篇 HTTP消息报头包括普通报头、请求报头、响应报头、实体报头。 普通报头 请求报头 响应报头 实体报头 Cache-Control Accept Location(重定向) Date Accept-Charset Server（服务器用来处理软件的信息 Connection Accept-Encoding Content-Encoding Accept-Language Content-Language Authorization WWW-Authenticate Content-Type Host Last-Modified User-Agent Expires 二、HTTPS HTTPS（Hypertext Transfer Protocol over Secure Socket Layer，基于SSL的HTTP协议）使用了HTTP协议，但HTTPS使用不同于HTTP协议的默认端口及一个加密、身份验证层（HTTP与TCP之间）。提供了身份验证与加密通信方法，现在它被广泛用于互联网上安全敏感的通信。 客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤。（1）客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。（2）Web服务器收到客户端请求后，会将网站的证书信息（证书中包含公钥）传送一份给客户端。（3）客户端的浏览器与Web服务器开始协商SSL连接的安全等级，也就是信息加密的等级。（4）客户端的浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。（5）Web服务器利用自己的私钥解密出会话密钥。（6）Web服务器利用会话密钥加密与客户端之间的通信。 1.5 RESTful（Representational State Transfer)（1）每一个URI代表一种资源；（2）客户端和服务器之间，传递这种资源的某种表现层；（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。 (1)客户-服务器：客户-服务器约束背后的原则是分离关注点。通过分离用户接口和数据存储这两个关注点，改善了用户接口跨多个平台的可移植性；同时通过简化服务器组件，改善了系统的可伸缩性。 (2)无状态：通信在本质上是无状态的，改善了可见性、可靠性、可伸缩性. (3)缓存：改善了网络效率减少一系列交互的平均延迟时间，来提高效率、可伸缩性和用户可觉察的性能。 (4)统一接口：REST架构风格区别于其他基于网络的架构风格的核心特征是，它强调组件之间要有一个统一的接口。 1.6 网络安全1. CSRF (Cross-Site Request Forgeries)csrf 跨站点请求伪造 ： 冒充用户发起请求。本质：通过已经认证的用户权限搞事情。模拟攻击： user – webA – webB user 浏览 webA webA 上发送给 user 一个 cookie user 浏览 webB webB 要求 user 访问 webA user 此时带着 cookie 访问 webA cookie 验证合格，所以 webB 可以 通过 user 的权限操控 webA 与 xss 区别：通常来说 CSRF 是由 XSS 实现的，CSRF 时常也被称为 XSRF（CSRF 实现的方式还可以是直接通过命令行发起请求等）。本质上讲，XSS 是代码注入问题，CSRF 是 HTTP 问题。XSS 是内容没有过滤导致浏览器将攻击者的输入当代码执行。CSRF 则是因为浏览器在发送 HTTP 请求时候自动带上 cookie，而一般网站的 session 都存在 cookie里面。 2. XSS (Cross Site Scripting)xss 跨站脚本攻击 ： 通过注入非法的 html 标签 以及 javascript 代码，从而当用户浏览网页时，控制用户的浏览器 xss 主要分为三类： DOM xss :DOM即文本对象模型，DOM通常代表在html、xhtml和xml中的对象，使用DOM可以允许程序和脚本动态的访问和更新文档的内容、结构和样式。它不需要服务器解析响应的直接参与，触发XSS靠的是浏览器端的DOM解析，可以认为完全是客户端的事情。 反射型 xss :反射型XSS也被称为非持久性XSS，是现在最容易出现的一种XSS漏洞。发出请求时，XSS代码出现在URL中，最后输入提交到服务器，服务器解析后在响应内容中出现这段XSS代码，最后浏览器解析执行。 存储型 xss :存储型XSS又被称为持久性XSS，它是最危险的一种跨站脚本，相比反射型XSS和DOM型XSS具有更高的隐蔽性，所以危害更大，因为它不需要用户手动触发。 允许用户存储数据的web程序都可能存在存储型XSS漏洞，当攻击者提交一段XSS代码后，被服务器端接收并存储，当所有浏览者访问某个页面时都会被XSS，其中最典型的例子就是留言板。 跨站脚本攻击可能造成以下影响： 利用虚假输入表单骗取用户个人信息。 利用脚本窃取用户的 Cookie 值，被害者在不知情的情况下，帮助攻击者发送恶意请求。 显示伪造的文章或图片。 防御： httpOnly: 在cookie 中设置 HttpOnly ,使得 js 脚本无法读取到 cookie 信息。 过滤 ： 输入检查 HtmlEncode : 对一些标签进行转化，将之转化为文本内容，而非一段可以执行的代码 JavaScriptEncode : 对一些字符加上反斜杠 3. DDos因为自己没有这方面的经验与系统的学习，所以就大概了解了一下，没有过多的分析。漫画告诉你什么是DDoS攻击？DDoS的攻击原理与防御方法 1.7 socket编程过去整理过，请点这里的这么明显的清楚的链接 1.8 补充在论坛上看到一个问题：ICMP 用的什么端口？有人是这么回答的，ICMP在网络层协议，不是用端口来说的，它的功能用类型来区别。 重点是下面这些消息类型，可以防止 DDoS 攻击 , 所以补充一下 .Echo Request和Reply（类型8和0）： 允许Echo Request消息出站以便于内部用户能够PING一个远程主机。阻止入站Echo Request和出站Echo Reply可以防止外部网络的主机对内部网络进行扫描。如果您使用了位于外部网络的监视器来监视内部网络，就应该只允许来自于特定外部IP的Echo Request进入您的网络。限制ICMP Echo包的大小可以防止“Ping Floods”攻击，并且可以阻止那些利用Echo Request和Reply来“偷运”数据通过防火墙的木马程序。Destination unreachable （类型3）： 允许其入站以便于内部网用户可以使用traceroute。需要注意的是，有些攻击者可以使用它来进行针对会话的DoS攻击，如果您曾经历过类似的攻击，也可以阻止它。阻止出站的ICMP Destination unreachable消息，因为它可能会泄漏内部网络的结构。不过有一个例外，对于那些允许外部网络通过TCP访问的内部主机（如位于DMZ区的Web 服务器）发出的Destination unreachable，则应该允许它通过。为了能够支持“Path MTU Discovery”，您应该允许出站的“Packet Too Big”消息（类型3，代码4）到达那些主机。Source quench（类型4）： 阻止其入站，因为它可以作为一种DoS攻击，能够降低发送者的发送速度。允许其出站以便于内部主机能够控制发送端发送数据的速度。有些防火墙会忽略所有直接发送到防火墙端口的Source Quench消息，以防止针对于防火墙的DoS攻击。Redirect（类型5，9，10）： Redirect、Router announcement、 Router selection（类型5，9，10）：这些消息都存在潜在危险，因为它们可以用来把数据重定向到攻击者的机器。这些消息都应该被阻止。TTL exceeded（类型11）： 允许其进站以便于内部用户可以使用traceroute。“firewalking”使用很低的TTL值来对网络进行扫描，甚至可以通过防火墙对内网进行扫描，所以应该禁止其出站。一些防火墙可以阻止TTL值小于设定值的数据包进入防火墙。Parameter problem（类型12）： 禁止其入站和出站。通过使用一个能够进行数据包一致性检查的防火墙，错误和恶意的数据包都会被阻塞。 结语都看到这里了，点个关注好不啦。你的关注，是我最大的动力哦。不定期干货更新。一只相当程序员的1米88处女座大可爱。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逐梦offer -- JVM知识总结]]></title>
    <url>%2Fblogs%2F25914.html</url>
    <content type="text"><![CDATA[4. JVM4.1 GC1. 垃圾收集基础 ： 可达性分析算法 GC ROOTS 复制算法 标记清除 标记整理 分代收集 – 1. 新生代 ; 2.3 老年代注： Oop Map – 安全点 – 安全区 以下部分内容 来自 这个博主的文章 1. 3种基本算法标记清除法/标记压缩法、复制收集算法、引用计数法 这里的 引用计数法 因为书中讲解少，所以讲一下：引用计数法，它的基本原理是，在每个对象中保存该对象的引用计数，当引用发生增减时对计数进行更新。引用计数的增减，一般发生在变量赋值、对象内容更新、函数结束（局部变量不再被引用）等时间点。当一个对象的引用计数变为0时，则说明它将来不会再被引用，因此可以释放相应的内存空间。缺点： 无法释放循环引用的对象。 必须在引用发生增减时对引用计数做出正确的增减，而如果漏掉了某个增减的话，就会引发很难找到原因的内存错误。引用数忘了增加的话，会对不恰当的对象进行释放；而引用数忘了减少的话，对象会一直残留在内存中，从而导致内存泄漏。 引用计数管理并不适合并行处理: 就如同 ConcurrenHashMap源码分析 中的算法一样，无法在并行情况下对数量进行准确的计算。 2. 3种进阶算法 分代回收分代回收的目的，正是为了在程序运行期间，将GC所消耗的时间尽量缩短。分代回收的基本思路，是利用了一般性程序所具备的性质，即大部分对象都会在短时间内成为垃圾，而经过一定时间依然存活的对象往往拥有较长的寿命。HotSpot 虚拟机中，在新生代用复制算法，老年代使用标记清除/整理算法。 问题：如果存在老生代对象对新生代对象的引用。如果只扫描新生代区域的话，那么从老生代对新生代的引用就不会被检测到。这样一来，如果一个年轻的对象只有来自老生代对象的引用，就会被误认为已经“死亡”了。因此，在分代回收中，会对对象的更新进行监视，将从老生代对新生代的引用，记录在一个叫做记录集 Rset（remembered set）的表中。在执行小回收(Minor Gc)的过程中，这个记录集也作为一个根来对待。 解决方案：在老生代到新生代的引用产生的瞬间，就必须对该引用进行记录，而负责执行这个操作的子程序，需要被嵌入到所有涉及对象更新操作的地方。这个负责记录引用的子程序是这样工作的。设有两个对象：A和B，当对A的内容进行改写，并加入对B的引用时，如果①A属于老生代对象，②B属于新生代对象，则将该引用添加到记录集中。这种检查程序需要对所有涉及修改对象内容的地方进行保护，因此被称为写屏障（Write barrier）。 增量回收为了维持程序的实时性，不等到GC全部完成，而是将GC操作细分成多个部分逐一执行。这种方式被称为增量回收 并行回收并行回收的基本原理是，是在原有的程序运行的同时进行GC操作，这一点和增量回收是相似的。不过，相对于在一个CPU上进行GC任务分割的增量回收来说，并行回收可以利用多CPU的性能，尽可能让这些GC任务并行（同时）进行。 3. Card Table 数据结构为了支持高频率的新生代的回收，虚拟机使用一种叫做卡表（Card Table）的数据结构.卡表作为一个比特位的集合，每一个比特位可以用来表示年老代的某一区域中的所有对象是否持有新生代对象的引用。 一、作用卡表中每一个位表示年老代4K的空间，卡表记录为 0 的年老代区域没有任何对象指向新生代，卡表记录为 1 的区域才有对象包含新生代引用，因此在新生代GC时，只需要扫描卡表位为1所在的年老代空间。使用这种方式，可以大大加快新生代的回收速度。 二、结构卡表是个单字节数组，每个数组元素对应堆中的一张卡。每次年老代对象中某个引用新生代的字段发生变化时，Hotspot VM就必须将该卡所对应的卡表元素设置为适当的值，从而将该引用字段所在的卡标记为脏。如下图：在Minor GC过程中，垃圾收集器只会在脏卡中扫描查找年老代-新生代引用。 Hotspot VM的字节码解释器和JIT编译器使用写屏障 维护卡表。写屏障 (Write barrier) 是一小段将卡状态设置为脏的代码。 解释器每次执行更新引用的字节码时，都会执行一段写屏障，JIT编译器在生成更新引用的代码后，也会生成一段写屏障。虽然写屏障使得应用线程增加了 – 性能开销，但Minor GC变快了许多，整体的垃圾收集效率也提高了许多，通常应用的吞吐量也会有所改善。 4. 评价指标 1、 吞吐量应用系统的生命周期内，应用程序所花费的时间和系统总运行时间的比值系统总运行时间=应用程序耗时+GC耗时2、 垃圾回收器负载垃圾回收器负载=GC耗时/系统总运行时间3、 停顿时间垃圾回收器运行时，应用程序的暂停时间4、 垃圾回收频率垃圾回收器多长时间运行一次。一般而言，频率越低越好，通常增大堆空间可以有效降低垃圾回收发生的频率，但是会增加回收时产生的停顿时间。5、 反应时间当一个对象成为垃圾后，多长时间内，它所占用的内存空间会被释放掉。 2. 内存分配1. 基础知识-Xms 堆大小-Xmx 可扩展大小-Xmn 老年代大小-XX:SurvivorRatio Eden 区与 Survivor 区大小比例 注： surivor 区分为 from 区与 to 区 - 在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。 - 紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，仍存活的对象会根据他们的年龄值来决定去向。 - 年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，没有达到阈值的对象会被复制到“To”区域 - 经过这次GC后，Eden区和From区已经被清空。这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From” - 新的“From”就是上次GC前的“To”。 - 不管怎样，都会保证名为To的Survivor区域是空的。Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。 大对象直接进入老年代 ：很长的字符串以及数组 长期存活的对象进入老年代 -XX:MaxTenuringThreshold 动态对象年龄判定 ：如果在Survivor 中，相同年龄所有对象的大小总和大于 Survivor 空间的一半， 大于或等于此年龄的对象就可以直接进入老年代。 分配担保机制 检查老年代最大可用连续空间 与 新生代所有对象的总空间 –&gt; yes –&gt; MinorGc HandlePromotionFailure 是否允许担保失败 –&gt; yes –&gt; 检查老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小 –&gt; MinorGC 2. Minor GC ，Major GC ， Full GC 触发条件堆内存空间： Eden、Survivor 和 Tenured/Old 空间 Minor GC触发条件：当Eden区满时，触发Minor GC。Major GC触发条件：http://www.importnew.com/15820.htmlFull GC触发条件：（1）调用System.gc时，系统建议执行Full GC，但是不必然执行（2）老年代空间不足（3）方法区空间不足（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 3. 垃圾收集器1. CMS (Concurrent Mark Sweep) 4个步骤： 初始标记：标记 GC ROOTS 可以直接关联的对象 并发标记：GC TRACING 重新标记：修正并发标记期间，用户程序继续动作而导致的标记产生变动的那一部分对象的标记记录 并发清除 3个缺点： 对 CPU 资源非常敏感 无法处理浮动垃圾(并发清理阶段，用户线程仍旧在运行，因此一直在产生垃圾，而无法在当次收集中处理掉它们) 产生大量的空间碎片 2. G1 (Garbage-First)4个特点： 并行与并发： 使用多个 CPU 或 CPU 核心来缩短 Stop-The-World 停顿的时间 分代收集 空间整合： 基于标记-整理算法 可预测的停顿： 可以建立可预测的停顿时间模型，让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不超过 N 毫秒。 4个步骤： 初始标记 并发标记 最终标记 筛选回收： 首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。 G1的GC模式 Young GC：选定所有年轻代里的Region。通过控制年轻代的region个数，即年轻代内存大小，来控制young GC的时间开销。Mixed GC：选定所有年轻代里的Region，外加根据global concurrent marking统计得出收集收益高的若干老年代Region。在用户指定的开销目标范围内尽可能选择收益高的老年代Region。注意：Mixed GC不是full GC，它只能回收部分老年代的Region，如果mixed GC实在无法跟上程序分配内存的速度，导致老年代填满无法继续进行Mixed GC，就会使用serial old GC（full GC）来收集整个GC heap。 global concurrent marking:类似CMS，为Mixed GC提供标记服务。四个过程： 初始标记（initial mark，STW）。它标记了从GC Root开始直接可达的对象。 并发标记（Concurrent Marking）。这个阶段从GC Root开始对heap中的对象标记，标记线程与应用程序线程并行执行，并且收集各个Region的存活对象信息。 最终标记（Remark，STW）。标记那些在并发标记阶段发生变化的对象，将被回收。 清除垃圾（Cleanup）。清除空Region（没有存活对象的），加入到free list。 G1 中的几个重要概念 – 原文链接–美团点评 一、Region 传统的GC收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。 如下图所示：而G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region，每个Region占有一块连续的虚拟内存地址。如下图所示：在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。H-obj有如下几个特征： H-obj直接分配到了old gen (老年代)，防止了反复拷贝移动。 H-obj在global concurrent marking 阶段的 cleanup 和 full GC 阶段回收。 在分配H-obj之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动 global concurrent marking，为的是提早回收，防止 evacuation failures 和 full GC。为了减少连续H-objs分配对GC的影响，需要把大对象变为普通的对象，建议增大Region size。 二、SATB 全称是Snapshot-At-The-Beginning，由字面理解，是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。 那么它是怎么维持并发GC的正确性的呢？根据三色标记算法，我们知道对象存在三种状态： 白：对象没有被标记到，标记阶段结束后，会被当做垃圾回收掉。 灰：对象被标记了，但是它的field还没有被标记或标记完。 黑：对象被标记了，且它的所有field也被标记完了。 由于并发阶段的存在，Mutator(更改器和)Garbage Collector线程同时对对象进行修改，就会出现白对象漏标的情况，这种情况发生的前提是： Mutator赋予一个黑对象该白对象的引用。 Mutator删除了所有从灰对象到该白对象的直接或者间接引用。 对于第一个条件，在并发标记阶段，如果该白对象是new出来的，并没有被灰对象持有，那么它会不会被漏标呢？Region中有两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。在TAMS以上的对象是新分配的，这是一种隐式的标记。对于在GC时已经存在的白对象，如果它是活着的，它必然会被另一个对象引用，即条件二中的灰对象。如果灰对象到白对象的直接引用或者间接引用被替换了，或者删除了，白对象就会被漏标，从而导致被回收掉，这是非常严重的错误，所以SATB破坏了第二个条件。也就是说，一个对象的引用被替换时，可以通过 write barrier 将旧引用记录下来。(并没有 看懂在说什么) SATB也是有副作用的，如果被替换的白对象就是要被收集的垃圾，这次的标记会让它躲过GC，这就是float garbage。因为SATB的做法精度比较低，所以造成的float garbage也会比较多。 三、RSet 全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了 GC要收集的Region集合 ，集合里的Region可以是任意年代的。在GC的时候，对于old-&gt;young和old-&gt;old的跨代对象引用，只要扫描对应的CSet中的RSet即可。 Rset : 属于points-into结构（谁引用了我的对象）Card Table : 则是一种points-out（我引用了谁的对象）的结构G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。这个RSet其实是一个Hash Table，Key – 别的Region的起始地址，Value是一个集合 – 里面的元素是Card Table的Index。这里解释一下 :上图有三个 Region 。红色代表 Rset ， 灰色大方框代表 Card Table。Region2 的 Rset2 中有两个 Region 的起始地址，分别指向 Region1 , Region3。 – 代表 Region1 与 Region3 引用了我的对象。Region1 的 Card Table 位置上，存在一个 对 Region2 的引用。 – 代表 Region1 引用了 Region2 的对象。Region3 同理。 作用：在做YGC(Minor GC)的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation。而mixed gc的时候，old generation中记录了old-&gt;old的RSet，young-&gt;old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。 四、Pause Prediction Model G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target.G1 GC是一个响应时间优先的GC算法，它与CMS最大的不同是，用户可以设定整个GC过程的期望停顿时间，参数‘-XX:MaxGCPauseMillis’指定一个G1收集过程目标停顿时间，默认值200ms。G1 通过这个模型统计计算出来的历史数据来预测本次收集需要选择的Region数量，从而尽量满足用户设定的目标停顿时间。停顿预测模型是以衰减标准偏差为理论基础实现的。这里就不详细介绍了，有兴趣的，可以看 美团大神的文章 4.2 Java 内存 程序计数器 虚拟机栈 ： 局部变量表、操作数栈、动态链接、方法出口 本地方法栈 ： native 方法 堆 ： 所有的对象实例以及数组 方法区 ： 已被加载的类信息、常量、静态变量、即时编译器编译后的代码 运行时常量池 ： 编译期生成的各种字面量和符号引用 直接内存 ： NIO类引入了一种基于通道（channel) 与 缓冲区(buffer) 的 I/O 方式，使用 Native 函数库直接分配堆外内存 ， 通过存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。 1. Java 对象的内存布局 对象头 : 哈希码(2bit)-分代年龄(4)、轻量级锁定（标志位 00）、重量级锁定、GC标记、可偏向（标志位 01），补充： 类型指针、数组长度 实例数据 ： 对齐填充 2. OOM 异常 堆溢出： 不断创建对象，并且存在可达路径，不被清除。那么对象在达到最大堆容量限制后就会产生内存溢出通过 内存映像分析工具 （Eclipse Memory Analyzer） 对 Dump 出来的堆转存储快照进行分析。判断是内存泄漏还是内存溢出。 虚拟机栈与本地方法栈溢出：如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出 StackOverFlowError 异常。如果虚拟机在扩展栈时无法申请到足够的内存空间，则抛出 OutOfMemoryError 异常。 方法区方法区存放 Class 的相关信息。如果存在大量的类 填满 方法区。则会产生溢出。通过 动态代理 或 通过 CGLIB 动态生成大量的类，以及大量 JSP与 动态JSP 文件的应用 。 3. OOM 异常的解决一. 可通过命令定期抓取heap dump或者启动参数OOM时自动抓取heap dump文件。二. 通过对比多个heap dump，以及heap dump的内容，分析代码找出内存占用最多的地方。三. 分析占用的内存对象，是否是因为错误导致的内存未及时释放，或者数据过多导致的内存溢出。 4.3 类加载器1. 类加载过程 加载 ：可以通过自定义类加载器参与 通过一个类的全限定名获取定义此类的二进制字节流 将这个字节流代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口 验证 文件格式验证 元数据验证 : 语义校验 字节码验证 ：逻辑校验 符号引用验证 ：发生在解析阶段中，将符号引用转化为直接引用 准备 ： 为类变量分配内存并设置类变量初始值的阶段 解析 : 将符号引用 替换 为直接引用的过程。 初始化 ： () 类构造器 : 将类中的赋值语句与静态代码块合并而成 – () 实例构造器 2. 双亲委派模型启动（Bootstrap）类加载器：采用 C++ 实现，它负责将 &lt;Java_Runtime_Home&gt;/lib下面的核心类库或-Xbootclasspath选项指定的jar包加载到内存中。由于启动类加载器到本地代码的实现，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替. 扩展（Extension）类加载器：扩展类加载器是由Sun的ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将&lt; Java_Runtime_Home &gt;/lib/ext或者由系统变量-Djava.ext.dir指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器。 系统（System）类加载器：系统类加载器是由 Sun的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。它负责将系统类路径java -classpath或-Djava.class.path变量所指的目录下的类库加载到内存中。开发者可以直接使用系统类加载器。 工作过程：如果一个类加载器收到了类的加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成。直到顶层的启动类加载器中，当父加载器反馈自己无法完成这个加载请求时，子加载器会尝试自己去加载。 3. 线程上下文类加载器方便 JNDI 服务：SPI 的接口是 Java 核心库的一部分，是由引导类加载器来加载的；SPI 实现的 Java 类一般是由系统类加载器来加载的。引导类加载器是无法找到 SPI 的实现类的，因为它只加载 Java 的核心库。它也不能代理给系统类加载器，因为它是系统类加载器的祖先类加载器。也就是说，类加载器的代理模式无法解决这个问题。解决方法：Java 应用的线程的上下文类加载器 默认 就是系统上下文类加载器。在 SPI 接口的代码中使用线程上下文类加载器，就可以成功的加载到 SPI 实现的类。线程上下文类加载器在很多 SPI 的实现中都会用到。Java默认的线程上下文类加载器是系统类加载器(AppClassLoader)。以下代码摘自sun.misc.Launch的无参构造函数Launch()。可以通过 java.lang.Thread类 的 setContextClassLoader() 设置。 4. OSGI（open service gataway initiative)方便执部署的实现。可以在不重启服务器的情况下，对其中的逻辑代码进行更新。由 父类加载器 与 Bundle 组成 , 每个 Bundle 的功能都是 发布 export 与依赖 import。从而形成复杂的网状结构原理：OSGi 中的每个模块都有对应的一个类加载器。它负责加载模块自己包含的 Java 包和类。当它需要加载 Java 核心库的类时（以 java开头的包和类），它会代理给父类加载器（通常是启动类加载器）来完成。当它需要加载所导入的 Java 类时，它会代理给导出此 Java 类的模块来完成加载。 5. Tomcat在双亲委派模型的基础上加入了 Common类加载器，Catalina类加载器，Shared类加载器，WebApp类加载器，Jsp类加载器Common类加载器， /common 目录 被 Tomcat 与 所以 Web 应用程序共同使用Catalina类加载器， /server 目录中， 被 Tomcat 使用Shared类加载器， /shared 目录中 ，被所有 Web 应用程序共同使用WebApp类加载器，Jsp类加载器 ， /WebApp/WEB-INF 目录中，只能被此 Web 应用程序使用。 4.4 解释器与编译器1. 编译模式 Mixed Mode – 混合模式默认为混合模式，解释器与编译器搭配使用。 Interpreted Mode – 解释模式使用 “-Xint” 参数。只使用解释。 Compiled Mode – 编译模式使用 “-Xcomp” 参数。 优先采用编译，当编译无法进行时，使用解释。 -version 命令，可以输出显示这三种模式 2. 分层编译(Tiered Compilation)JDK1.7 中的 Server 模式虚拟机中被作为默认编译策略。 0层，程序解释执行，解释器不开启性能监控功能(Profiling)，可触发第一层编译 1层，也叫C1 编译(下文有解释)，将字节码编译为本地代码，进行简单、可靠的优化 2层，C2编译。 3. OSR编译因为存在多次执行的循环体，所以触发 OSR 编译，以整个方法 作为编译对象。发生在方法执行过程中，所以叫( On Stack Replacement ) 方法栈帧还在栈上，方法就被替换了。 4. 编译对象以及触发条件热点代码的分类： 被多次调用的方法 被多次执行的方法体 – OSR 编译 热点探测(Hot Spot Detection) 基于采样 : 如果周期性的检查各个线程的栈顶，如果发现某个方法经常出现在栈顶，则这个方法就是“热点方法”。 基于计数器 – HotSpot 虚拟机中采用。 原理： 为每个方法建立计数器，统计方法的次数，如果执行次数超过一定的阈值，就认为它是“热点方法” 计数器分类： 方法调用计数器(Invocation Counter) : 统计一段时间内，方法被调用的次数，如果超过时间限度，则将这个方法的调用计数器减少一半，称为衰减 回边计数器(Back Edge Counter) ： 统计一个方法中循环体被执行的次数 – OSR 编译 在字节码中遇到控制流向后跳转的指令，称为回边。 5. 优化措施hotspot中内嵌有2个JIT编译器，分别为Client Compiler，Server Compiler，但大多数情况下我们称之为C1编译器和C2编译器。 5.1 C1 编译器client compiler，又称C1编译器，较为轻量，只做少量性能开销比较高的优化，它占用内存较少，适合于桌面交互式应用。在寄存器分配策略上，JDK6以后采用的为线性扫描寄存器分配算法，其他方面的优化，主要有方法内联、去虚拟化、冗余消除等。 A、方法内联 多个方法调用，执行时要经历多次参数传递，返回值传递及跳转等，C1采用方法内联，把调用到的方法的指令直接植入当前方法中。-XX:+PringInlining来查看方法内联信息，-XX:MaxInlineSize=35控制编译后文件大小。B、去虚拟化是指在装载class文件后，进行类层次的分析，如果发现类中的方法只提供一个实现类，那么对于调用了此方法的代码，也可以进行方法内联，从而提升执行的性能。C、冗余消除在编译时根据运行时状况进行代码折叠或消除。 5.2 C2 编译器Server compiler，称为C2编译器，较为重量，采用了大量传统编译优化的技巧来进行优化，占用内存相对多一些，适合服务器端的应用。和C1的不同主要在于寄存器分配策略及优化范围.寄存器分配策略上C2采用的为传统的图着色寄存器分配算法，由于C2会收集程序运行信息，因此其优化范围更多在于全局优化，不仅仅是一个方块的优化。收集的信息主要有：分支的跳转/不跳转的频率、某条指令上出现过的类型、是否出现过空值、是否出现过异常等。 逃逸分析(Escape Analysis) 是C2进行很多优化的基础，它根据运行状态来判断方法中的变量是否会被外部读取，如不会则认为此变量是不会逃逸的，那么在编译时会做标量替换、栈上分配和同步消除等优化。如果证明一个对象不会逃逸到方法或线程之外，则： - 栈上分配(Stack Allocation) ：确定不会逃逸到**方法外**，让这个对象在栈上分配内存，对象占用的内存空间可以随栈帧的出栈而销毁。 - 同步消除(Synchronization Elimination) ：确定不会逃逸到**线程外**，则无法被其他线程访问，所以可以取消同步措施。 - 标量替换(Scalar Repalcement) : 标量(Scalar)指一个数据无法再分解成更小的数据来表示 -- Java 中的原始数据类型 聚合量(Aggregate)指一个数据可以继续分解 -- Java 中的对象 **原理：**直接创建若干个可以被方法使用的成员变量来替代。 5.3 其他措施（注： 不知是 C1 还是 C2) 语言无关的经典优化技术 – 公共子表达式消除(Common Subexpression Elimination) 如果一个表达式E 已经计算过，并且从先前的计算 到现在 值未曾改变，那么如果 E 再次出现，则可以直接使用之前的表达式结果，代替 E 。 语言相关的经典优化技术 – 数组边界检查消除(Array Bounds Checking Elimination)这个不是很了解，做一个重点。。。 以后整理 4. 零散知识点1. 静态多分派与动态单分派静态分派 ： 依靠静态类型 定位方法。编译阶段：Human man = new Man(); // 静态类型为 Human运行阶段：man.sayHello() // 动态类型为 Man 重载的优先级sayHello(char arg);char -&gt; int -&gt; long -&gt; float -&gt; double // 不可转化为 byte short ， 因为char 转化是不安全的。-&gt; Character -&gt; Serializable/Comparable -&gt; Object -&gt; char…(变长参数) 宗量：方法的接收者与方法的参数统称为宗量单分派 根据一个宗量对目标方法进行选择多分派 根据多个宗量对目标方法进行选择 123456789101112131415161718public class QQ&#123;&#125;;public class _360&#123;&#125;;public static class Father &#123; public void hardChoice(QQ arg); public void hardChoice(_360 arg);&#125;public static class Son extends Father&#123; public void hardChoice(QQ arg); public void hardChoice(_360 arg);&#125;Father father = new Father();Father son = new Son();// 静态多分派 - 编译 ： 方法的接收者 Father - Son, 参数 QQ - _360father.hardChoice(_360);// 动态多分派 - 运行 ： 已经确定 参数为 QQ ，再判断 实际类型 , son的实际类型为 Son 。son.hardChoice(QQ); 结语都看到这里了，点个关注,点波赞再走，QAQ。你的小手轻点，是我最大的动力哦。 一只想当程序员的1米88处女座大可爱如此说。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索为将 -- lucene 6.6 学习心得]]></title>
    <url>%2Fblogs%2F43623.html</url>
    <content type="text"><![CDATA[前言本文首发于segmentfault的个人专栏学习的资料是 lucene 4.10 版本，比较沉旧，查阅最新的 lucene 版本 6.6 的官方文档，整理出以下几个使用中的不同。从浅入深依次为 （注：不是根据版本先后） IndexWriterConfig 的构造方法 Directory 的生成方法 FSDirectory.open() legacyXXField 与legacyNumericRangeQuery 的废弃 BooleanQuery() 方法的改变 setBoost()方法的废除 中文分词器的改进 下面，就让我详细的整理出不同。 1.IndexWriterConfig以下是 IndexWriterConfig 4.10 的源码部分123456public IndexWriterConfig(Version matchVersion, Analyzer analyzer) &#123; super(analyzer, matchVersion);&#125;//这里的version 一般要写为 Version 类中public static final Version LATEST; 而 IndexWriterConfig 6.6 中123456789//无参构造方法 public IndexWriterConfig() &#123; this(new StandardAnalyzer());&#125;//有参构造方法public IndexWriterConfig(Analyzer analyzer) &#123; super(analyzer); this.writer = new SetOnce();&#125; 可以看出，在 6.6 版本中 version 不再是必要的，并且，存在无参构造方法，可以直接使用默认的 StandardAnalyzer 分词器。 2.Directory正常创建 Directory 类的方法如下1Directory di = FSdirectory.open(); 以下是 IndexWriterConfig 4.10 的源码部分123public static FSDirectory open(File path) throws IOException &#123; return open(path, (LockFactory)null);&#125; 这里可以看出 open 方法 用的参数类型 为File 而 IndexWriterConfig 6.6 中123public static FSDirectory open(Path path) throws IOException &#123; return open(path, FSLockFactory.getDefault());&#125; open 方法使用了 Path 类，这个类是 NIO 中的类，可以提高查询的效率。由 File 转化为 Path 的 方法—&gt;12File file = new File (absolutePath);Path path = file.toPath() 3.legacyXXField 与legacyNumericRangeQuery1. 分析根据 官方的 Migration Guide 中的说法 PointValues replaces NumericField (LUCENE-6917) PointValues provides faster indexing and searching, a smaller index size, and less heap used at search time. See org.apache.lucene.index.PointValues for an introduction. Legacy numeric encodings from previous versions of Lucene are deprecated as LegacyIntField, LegacyFloatField, LegacyLongField, and LegacyDoubleField, and can be searched with LegacyNumericRangeQuery. 以及开发者的测试 DimensionalValues seems to be better across the board (indexing time, indexing size, search-speed, search-time heap required) than NumericField, at least in my testing so far.I think for 6.0 we should move IntField, LongField, FloatField, DoubleField and NumericRangeQuery to backward-codecs, and rename with Legacy prefix? 2.结论： PointValues 取代了NumericField 因为PointValues 更快，更小，更便于资源的利用。所以，所有的 legacy**都被取代了。 3.代码对比代码的话，lucene 的官方文档给了一个简单的例子12345678// add year 1970 to documentdocument.add(new IntPoint(&quot;year&quot;, 1970));// index documentwriter.addDocument(document);...// issue range query of 1960-1980Query query = IntPoint.newRangeQuery(&quot;year&quot;, 1960, 1980);TopDocs docs = searcher.search(query, ...); 另外我自己写了一个 已经@Deprecated的方法 与上面 进行对比12345678 // add year 1970 to documentdocument.add(new IntField(&quot;year&quot;, 1970));// index documentwriter.addDocument(document);...// issue range query of 1960-1980Query query = new NumericRangeQuery(&quot;year&quot;, 1960, 1980,false,false);TopDocs docs = searcher.search(query, ...); 还要注意的是: 如果要存储，必须创建同名的StoredField类 如果要排序使用，必须同时创建同名的StoredField类与NumericDocValuesField类 例：123doc.add(new NumericDocValuesField(&quot;price&quot;,price)); doc.add(new IntPoint(&quot;price&quot;,price)); doc.add(new StoredField(&quot;price&quot;,price)); 4.BooleanQuery() 的构造方法改变1.分析根据 官方的 Migration Guide 中的说法 PhraseQuery, MultiPhraseQuery, and BooleanQuery made immutable (LUCENE-6531 LUCENE-7064 LUCENE-6570)也就是说， BooleanQuery这个类 一旦建立就不能再改变了。 从源码中我们可以更好的看出改变lucene 4.10 的源码里 BooleanQuery 的类 主要方法如下123456789101112131415/* 构造器*/public BooleanQuery() &#123; this.disableCoord = false;&#125;public BooleanQuery(boolean disableCoord) &#123; this.disableCoord = disableCoord;&#125;/*主要方法*/public void add(BooleanClause clause) &#123; if(this.clauses.size() &gt;= maxClauseCount) &#123; throw new BooleanQuery.TooManyClauses(); &#125; else &#123; this.clauses.add(clause); &#125;&#125; lucene 6.6 的源码里， BooleanQuery 的主要方法如下：1private BooleanQuery(boolean disableCoord, int minimumNumberShouldMatch, BooleanClause[] clauses) 可以看出 ， BooleanQuery 的构造器的范围是 private 的，只能在类的内部调用。并且最大的改变是多出了静态内部类 Builder以下是 Builder 的部分源码1234567891011121314151617public static class Builder &#123; private boolean disableCoord; private int minimumNumberShouldMatch; private final List&lt;BooleanClause&gt; clauses = new ArrayList(); /* 无参构造器 */ // 相当于 BooleanQuery 的 构造器 public Builder() &#123; &#125; //相当于 BooleanQuery 的 add 方法 public BooleanQuery.Builder add(Query query, Occur occur) &#123; return this.add(new BooleanClause(query, occur)); &#125; //返回值是 BooleanQuery, 构造一个BooleanQuery 类。 public BooleanQuery build() &#123; return new BooleanQuery(this.disableCoord, this.minimumNumberShouldMatch, (BooleanClause[])this.clauses.toArray(new BooleanClause[0]), null); &#125;&#125; 2.结论通过用静态内部类实例化自身的方法，加强了类自身的稳定性与安全性。避免可能发生的小意外，而导致代码出现问题的可能性 3.代码对比下面给出代码，可以更好的看出差别1234567891011//原先的 使用方法BooleanQuery bq = new BooleanQuery(); bq.add(q1, Occur.SHOULD); bq.add(q2, Occur.SHOULD); bq.add(q3, Occur.MUST); //现在的 使用方法BooleanQuery bq = new BooleanQuery.Builder() .add(q1, Occur.SHOULD) .add(q2, Occur.SHOULD) .add(q3, Occur.SHOULD) .build(); 5. setBoost()方法的废除在 lucene 4.10 包中， setBoost方法被用于 相关度 的排序中。改变创建索引时的 Boost – 权值。根据一系列计算方法 （旧版采用的 空间向量模型算法），最终得出其打分。代码如下 ： 12345Field fi1 = new Field("id" , 1, STORE.YES)；// Boost 值默认为 1.0f fi1.setBoost(100f)Document do = new Document();do.add(fi1); 而在新版 lucene 6.6 中， setBoost 方法被 废除根据lucene 的官方文档中的说法 org.apache.lucene.document.Field.setBoost(float)Index-time boosts are deprecated, please index index-time scoring factors into a doc value field and combine them with the score at query time using eg. FunctionScoreQuery. 中文翻译后：索引时权值被废除，请将索引时打分因素添加入field域中，然后在查询时，使用功能性打分查询语句，进行关联查询。 我在查看了 大部分关联的 api 后，发现了几个与之相关的 类 BoostAttribute termsEnum MultiQuery lucene 的官方文档中对 BoostAttribute 的描述是这样的。BoostAttribute — &gt;Add this Attribute to a TermsEnum returned by MultiTermQuery.getTermsEnum(Terms,AttributeSource) and update the boost on each returned term.方法描述如下 1234protected abstract TermsEnum getTermsEnum(Terms terms,AttributeSource atts) //Construct the enumeration to be used, expanding the pattern term.//很明显，这是个抽象方法，必须由子类实现` BoostAttribute 是个接口，其实现类 BoostAttributeImpl 中源码如下 123456public BoostAttributeImpl() &#123;&#125;public void setBoost(float boost) &#123; this.boost = boost;&#125; 推测使用如下 — 以下是伪代码 1234567//设置 Boost 属性BoostAttribute ba = new BoostAttributeImpl();ba.setBoost(100f);//设置 Query 的实现类Query query = new MultiTermqueryChildren(new Terms（)）;TermEnum te = query.getTermsEnum(Terms,ba); 具体方法还不清楚，希望知道的大神可以给我解答 另外，还有两个便于操作的类： BoostQuery MultiFieldQueryParser 1.BoostQuery源码如下： 1234public BoostQuery(Query query, float boost) &#123; this.query = (Query)Objects.requireNonNull(query); this.boost = boost;&#125; 分析：相当于一个包装类，将 Query 设置 Boost 值 ，然后包装起来。再通过复合查询语句，可以突出 Query 的优先级。 使用如下： 12345678910111213//查询 索引域 中的 file_name , file_contentQuery q1 = new TermQuery(new Term(“file_name” ,”springmvc.txt”);Query q2 = new TermQuery(new Term(“file_content”,”springmvc.txt”);//将 q1 设置 Boost 值 BoostQuery q3 = new BoostQuery(q1,100f);//复合语句查询BooleanQuery.Builder() builder = new new BooleanQuery.Builder();builder.add(q3, Occur.MUST)builder.add(q2, Occur.MUST)//由于 file_name 的查询语句经过 BoostQuery 的包装//因此 file_name 的优先级更高。BooleanQuery query = builder.build(); 2.MultiFieldQueryParser和原先版本相同 ， 就不阐述源码，直接上使用方法使用如下 ： 1234567891011//设置组合查询域String[] fields = &#123;"file_name","file_content"&#125;;//设置评分,文件名称中包括关键字的评分高Map&lt;String,Float&gt; boosts = new HashMap&lt;String,Float&gt;();boosts.put("file_name", 10.0f);//创建查询解析器QueryParser queryParser = new MultiFieldQueryParser(fields, new IKAnalyzer(), boosts);//查询文件名、文件内容中包括“springmvc.txt”关键字的文档，由于设置了文件名称域的加权值高，所以名称中匹配到关键字的应该排在前边Query query = queryParser.parse("springmvc.txt"); 6. 中文分词器 – iKAnalyzer 的 lucene 6.6 适配 调皮的超链接个人博客中有更多]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从 Socket 编程 到 OkHttp 框架]]></title>
    <url>%2Fblogs%2F21184.html</url>
    <content type="text"><![CDATA[前言最近在做一个项目的时候，因为项目要求跨域连接。所以，使用了Okhttp框架。其内部原理是基于 socket 网络编程的。因为自己在这方面比较薄弱，所以写这一篇文章进行相关的总结。 基础知识（参考 图解TCP/IP 与 深入理解计算机系统） TCP/IP 参考模型网络基础知识 socket 套接字每个套接字都是连接的一个端点，有相应的套接字地址。由一个IP地址与16位的整数端口组成.一个连接由两端的套接字地址唯一确定。叫套接字对。如:(cliaddr:cliport, servaddr:servport)端口号分为：标准既定的端口号： 0~49151. 其中知名端口号由 0~1023 组成。FTP 一般使用 21号端口号，HTTP 通信一般使用 80 号端口号。 动态分配的端口号**： 49152~65535. 操作系统为之分配不同的端口号。然后应用程序使用时，由操作系统将连接建立。 java 中的网络编程类 InetAddress:用于标识网络上的硬件资源，主要是IP地址 URL：统一资源定位符，通过URL可以直接读取或写入网络上的数据 Sockets：使用TCP协议实现的网络通信Socket相关的类 Datagram:使用UDP协议，将数据保存在用户数据报中，通过网络进行通信。UDP协议中，使用 数据报 为传输单位。 java 网络编程类介绍1. InetAddressInetAddress类用于标识网络上的硬件资源，标识互联网协议(IP)地址。123456789101112//获取本机的InetAddress实例InetAddress address =InetAddress.getLocalHost();//获取计算机名address.getHostName();//获取IP地址address.getHostAddress();//获取字节数组形式的IP地址,以点分隔的四部分byte[] bytes = address.getAddress();//获取其他主机的InetAddress实例InetAddress address2 =InetAddress.getByName("其他主机名");InetAddress address3 =InetAddress.getByName("IP地址"); 2. URLURL(Uniform Resource Locator)统一资源定位符，表示Internet上某一资源的地址，协议名：资源名称 基础使用 12345678910//创建一个URL的实例URL myBlog =new URL("https://3dot141.cn");URL url =new URL(myBlog,"/blogs/33521.html?username=3dot141#test");//？表示参数，#表示锚点url.getProtocol();//获取协议url.getHost();//获取主机url.getPort();//如果没有指定端口号，根据协议不同使用默认端口。此时getPort()方法的返回值为 -1url.getPath();//获取文件路径url.getFile();//文件名，包括文件路径+参数url.getRef();//相对路径，就是锚点，即#号后面的内容url.getQuery();//查询字符串，即参数 读取网页内容 1234567891011121314//使用URL读取网页内容//创建一个URL实例URL url =new URL("http://www.baidu.com");InputStream is = url.openStream();//通过openStream方法获取资源的字节输入流InputStreamReader isr =newInputStreamReader(is,"UTF-8");//将字节输入流转换为字符输入流,如果不指定编码，中文可能会出现乱码BufferedReader br =newBufferedReader(isr);//为字符输入流添加缓冲，提高读取效率String data = br.readLine();//读取数据while(data!=null)&#123;System.out.println(data);//输出数据data = br.readerLine();&#125;br.close();isr.colose();is.close(); 3. Socket首先介绍下关于 linux 下的套接字连接原理，帮助理解 下面介绍java 下 Socket的使用 1.Socket 的构造方法1234567891011（1）Socket()（2）Socket(InetAddress address, int port)throws UnknownHostException,IOException// 设定远程服务器地址与客户端地址（3）Socket(InetAddress address, int port, InetAddress localAddr, int localPort)throws IOException（4）Socket(String host, int port) throws UnknownHostException,IOException// 设定远程服务器地址与客户端地址（5）Socket(String host, int port, InetAddress localAddr, int localPort) throws IOException 2.获取Socket信息12345678910111. getInetAddress()：获得远程服务器的IP地址。2. getPort()：获得远程服务器的端口。3. getLocalAddress()：获得客户本地的IP地址。4. getLocalPort()：获得客户本地的端口。5. getInputStream()：获得输入流。如果Socket还没有连接，或者已经关闭，或者已经通过shutdownInput()方法关闭输入流，那么此方法会抛出IOException。6. getOutputStream()：获得输出流。如果Socket还没有连接，或者已经关闭，或者已经通过shutdownOutput()方法关闭输出流，那么此方法会抛出IOException。 3.Socket 状态 关闭状态 1234561. close()// 状态测试方法1. isClosed()2. IsConnected()3. isBound() 半关闭状态 1234561. shutdownInput()2. shutdownOutput()// 状态测试方法1. isInputShutDown()2. isOutputShutdown() 4.Socket 使用实例以上就是 Socket 类的基本方法。 下面让我们进入实战，来看一下，Socket 类如何使用 服务器端 1234567891011121314151617181920212223242526272829303132/** * 基于TCP协议的Socket通信，实现用户登录，服务端*///1、创建一个服务器端Socket，即ServerSocket，指定绑定的端口，并监听此端口ServerSocket serverSocket =newServerSocket(33521);//1024-65535的某个端口//2、调用accept()方法开始监听，等待客户端的连接Socket socket = serverSocket.accept();//3、获取输入流，并读取客户端信息InputStream is = socket.getInputStream();InputStreamReader isr =newInputStreamReader(is);BufferedReader br =newBufferedReader(isr);String info =null;while((info=br.readLine())!=null)&#123;System.out.println("我是服务器，客户端说："+info)；&#125;socket.shutdownInput();//关闭输入流//4、获取输出流，响应客户端的请求OutputStream os = socket.getOutputStream();PrintWriter pw = new PrintWriter(os);pw.write("欢迎您！");pw.flush();//5、关闭资源pw.close();os.close();br.close();isr.close();is.close();socket.close();serverSocket.close(); 客户端 1234567891011121314151617181920212223//客户端//1、创建客户端Socket，指定服务器地址和端口Socket socket =newSocket("localhost",33521);//2、获取输出流，向服务器端发送信息OutputStream os = socket.getOutputStream();//字节输出流PrintWriter pw =newPrintWriter(os);//将输出流包装成打印流pw.write("用户名：3dot141；密码：hahah");pw.flush();socket.shutdownOutput();//3、获取输入流，并读取服务器端的响应信息InputStream is = socket.getInputStream();BufferedReader br = new BufferedReader(new InputStreamReader(is));String info = null;while((info=br.readLine())!null)&#123; System.out.println("我是客户端，服务器说："+info);&#125;//4、关闭资源br.close();is.close();pw.close();os.close();socket.close(); 结果 12我是服务器，客户端说：用户名：3dot141；密码：hahah我是客户端，服务器说：欢迎您! 多线程中的运用 服务器端创建ServerSocket，使用while(true)循环调用accept()等待客户端连接 客户端创建一个socket并请求和服务器端连接 服务器端接受请求，创建socket与该客户建立专线连接 建立连接的两个socket在一个单独的线程上对话 服务器端继续等待新的连接 12345678910111213141516171819202122232425public class ServerThread implements runnable&#123;//服务器线程处理//和本线程相关的socketSocket socket =null;//public ServerThread(Socket socket)&#123;this.socket = socket;&#125;publicvoid run()&#123;//服务器处理代码&#125;&#125;//服务器代码ServerSocket serverSocket =newServerSocket(33521);Socket socket =null;int count =0;//记录客户端的数量while(true)&#123;socket = serverScoket.accept();ServerThread serverThread =new ServerThread(socket); serverThread.start(); count++;System.out.println(&quot;客户端连接的数量：&quot;+count);&#125; 4. UDP 编程1. 简单介绍UDP 是面向无连接的协议，反应迅速，适用于适时场景，但是丢包后不能发现。用于 直播等网速要求较高的应用 DatagramSocket 端到端的通信类.12345678910//本机地址// 随机DatagramSocket()// 指定DatagramSocket(int port, InetAddress)// 发送与接收send(DatagramPacket) receive(DatagramPacket) DatagramPacket 数据报, 为 IP 和 UDP 等网络层以上的包的单位 。虽然这些都是包，但不同的层拥有不同的称呼。数据链路层中 叫 帧 , TCP 则表示 为 段 .方法 ：1234567891011// 构造方法// 接收时DatagramPacket(byte[] buf, int length);// 发送时DatagramPacket(byte[] buf, int length, InetAddress iAdrr, int Port);// 使用方法// 用于服务器获得 客户端地址getAddress()// 用于服务器获得 客户端接口getPort() 2. 基本使用 服务器端 1234567891011121314151617181920212223242526//服务器端，实现基于UDP的用户登录//1、创建服务器端DatagramSocket，指定端口DatagramSocket socket =new datagramSocket(33521);//2、创建数据报，用于接受客户端发送的数据byte[] data =newbyte[1024];//DatagramPacket packet =newDatagramPacket(data,data.length);//3、接受客户端发送的数据socket.receive(packet);//此方法在接受数据报之前会一致阻塞//4、读取数据String info =newString(data,o,data.length);System.out.println(&quot;我是服务器，客户端告诉我&quot;+info);//=========================================================//向客户端响应数据//1、定义客户端的地址、端口号、数据// 这里也可以自己设置InetAddress address = packet.getAddress();int port = packet.getPort();byte[] data2 = &quot;欢迎您！&quot;.geyBytes();//2、创建数据报，包含响应的数据信息DatagramPacket packet2 = new DatagramPacket(data2,data2.length,address,port);//3、响应客户端socket.send(packet2);//4、关闭资源socket.close(); 客户端 123456789101112131415161718192021222324//客户端//1、定义服务器的地址、端口号、数据InetAddress address =InetAddress.getByName(&quot;localhost&quot;);int port =33521;byte[] data =&quot;用户名：3dot141;密码：hahah&quot;.getBytes();//2、创建数据报，包含发送的数据信息DatagramPacket packet = newDatagramPacket(data,data,length,address,port);//3、创建DatagramSocket对象DatagramSocket socket =newDatagramSocket();//4、向服务器发送数据socket.send(packet);//接受服务器端响应数据//======================================//1、创建数据报，用于接受服务器端响应数据byte[] data2 = new byte[1024];DatagramPacket packet2 = new DatagramPacket(data2,data2.length);//2、接受服务器响应的数据socket.receive(packet2);String raply = new String(data2,0,packet2.getLenth());System.out.println(&quot;我是客户端，服务器说：&quot;+reply);//4、关闭资源socket.close(); OkHttp 框架在项目中，我对 OkHttp 进行了简单的封装，基本满足我在项目中的需要。下面贴上我的 工具类 1234567891011121314151617181920212223242526272829303132333435363738394041public class OkhttpUtil &#123; public static final MediaType JSON = MediaType.parse("application/json;charset=UTF-8"); public static String doGet(String url) throws IOException &#123; OkHttpClient client = new OkHttpClient(); Request get = new Request.Builder().url(url).build(); Response response = client.newCall(get).execute(); return response.body().string(); &#125; public static String doGet(String url, Map&lt;String, String&gt; map) throws IOException &#123; OkHttpClient client = new OkHttpClient(); String newUrl = url; if (map != null) &#123; int loop = 0; for (String key : map.keySet()) &#123; if (loop == 0) &#123; newUrl = newUrl + "?" + key + "=" + map.get(key); &#125; else &#123; newUrl = newUrl + "&amp;" + key + "=" + map.get(key); &#125; loop = 1; &#125; &#125; Request get = new Request.Builder().url(newUrl).build(); Response response = client.newCall(get).execute(); return response.body().string(); &#125; public static String doPost(String url, String requestBody) throws IOException &#123; OkHttpClient client = new OkHttpClient(); Request post = new Request.Builder().url(url).post(RequestBody.create(JSON, requestBody)).build(); Response response = client.newCall(post).execute(); if (!response.isSuccessful()) &#123; throw new IOException("没能得到数据" + response); &#125; return response.body().string(); &#125;&#125; 如果有对 okhttp 框架感兴趣的，可以参阅下面的网址。我就不献丑了。okhttp 源码解析okhttp 使用教程 结语路漫漫其修远兮，吾将上下而求索。在程序员的道路上，我还只是一个刚上路的小学生，怀着对代码世界的向往，砥砺前行。 stay hungry, stay foolish与诸君共勉。您的每一次点赞，关注都是对我的一种激励。我的个人博客 – killCode谢谢。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索为将 -- Solr 从入门到进阶(二)]]></title>
    <url>%2Fblogs%2F5049.html</url>
    <content type="text"><![CDATA[前言上一篇已经介绍了 solr 的基本操作。传送门： 搜索为将 – solr 入门现在介绍如何 与数据库 整合。 solr managed-scheme 文档这个文档位于 solrhome\new_core\conf 下如图所示 : 这个文档中可以设置一些属性，便于之后与数据库整合后，在搜索中使用。 1. Field1&lt;field name="id" type="string" indexed="true" stored="true" required="true" multiValued="false" /&gt; Name：指定域的名称Type：指定域的类型 – 指定使用的分词器。Indexed：是否索引Stored：是否存储Required：是否必须multiValued：是否多值，比如商品信息中，一个商品有多张图片，一个Field像存储多个值的话，必须将multiValued设置为true。 2. dynamicField动态域，通过 通配符 进行匹配 1&lt;dynamicField name="*_i" type="int" indexed="true" stored="true"/&gt; 3. uniqueKey指定唯一键1&lt;uniqueKey&gt;id&lt;/uniqueKey&gt; 其中的id 是在 Field标签 中已经定义好的域名，而且该域要设置为 required为true 。一个 schema.xml 文件中必须有且仅有一个唯一键. 4. copyField从已有的 field中直接复制属性，被复制的field 必须拥有multiValued = “true” 属性。 1&lt;copyField source="cat" dest="text"/&gt; 5. FieldType也就是设置的 field 域的类型。通过各种分词器以及内置的类型设置。常用类型都已经被设置好了，如下如果还需要其他类型的 域 ,通过分词器设置。可以参考我 之前的文章.搜索为将 – solr 入门这里介绍了 将 smart_cn 以及 IKAnalyzer 设置为 相应的 field 域的方法. solr 插件 – DataimportHandler第一步、将 solr/dist 目录下的 solr-dataimporthandler.jar 文件拷贝到 solrhome/contrib/dataimporthandler/lib 目录下.将 自己准备好的 mysql 连接的 jar 包 拷贝到 solrhome/contrib/db/lib 下这里是用 linux 建立的服务器,所以使用了 xshell 中的 xftp,帮助对文件进行管理 第二步、进入 core 文件夹 , 分别修改 solrConfig.xml 、 managed-scheme 文档solrConfig.xml 文档下添加相应的内容123&lt;!-- 新建相应的 lib 标签 --&gt;&lt;lib dir="$&#123;solr.install.dir:../..&#125;/contrib/dataimporthandler/lib" regex=".*\.jar" /&gt;&lt;lib dir="$&#123;solr.install.dir:../..&#125;/contrib/db/lib" regex=".*\.jar" /&gt; lib 的修改原则，我的上篇文章写的很清楚，不再阐述。123456 &lt;!-- 添加相应的 requestHandler -- &gt;&lt;requestHandler name=&quot;/dataimport&quot; class=&quot;org.apache.solr.handler.dataimport.DataImportHandler&quot;&gt; &lt;lst name=&quot;defaults&quot;&gt; &lt;str name=&quot;config&quot;&gt;data-config.xml&lt;/str&gt; &lt;/lst&gt;&lt;/requestHandler&gt; managed-scheme 文档下添加 与 数据库中的文件相应的属性，以我的为例。123456789101112131415161718192021222324&lt;!-- IKAnalyzer --&gt; &lt;fieldType name="text_ik" class="solr.TextField"&gt; &lt;analyzer type="index"&gt; &lt;tokenizer class="org.wltea.analyzer.lucene.IKTokenizerFactory"/&gt; &lt;/analyzer&gt; &lt;analyzer type="query"&gt; &lt;tokenizer class="org.wltea.analyzer.lucene.IKTokenizerFactory"/&gt; &lt;/analyzer&gt; &lt;/fieldType&gt; &lt;!-- taotao_shop --&gt; &lt;field name="item_title" type="text_ik" indexed="true" stored="true"/&gt; &lt;field name="item_sell_point" type="text_ik" indexed="true" stored="true"/&gt; &lt;field name="item_price" type="long" indexed="true" stored="true"/&gt; &lt;field name="item_image" type="string" indexed="false" stored="true" /&gt; &lt;field name="item_category_name" type="string" indexed="true" stored="true" /&gt; &lt;field name="item_desc" type="text_ik" indexed="true" stored="false" /&gt; &lt;field name="item_keywords" type="text_ik" indexed="true" stored="false" multiValued="true"/&gt; &lt;copyField source="item_title" dest="item_keywords"/&gt; &lt;copyField source="item_sell_point" dest="item_keywords"/&gt; &lt;copyField source="item_category_name" dest="item_keywords"/&gt; &lt;copyField source="item_desc" dest="item_keywords"/&gt; 第三步、同级目录下创建 data-config.xml 文件 在其中加入相应的内容1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;dataConfig&gt; &lt;dataSource type="JdbcDataSource" driver="com.mysql.jdbc.Driver" url="jdbc:mysql://192.168.1.101:3306/taotao" user="root" password="1996915" /&gt; &lt;document&gt; &lt;entity name="item" query="SELECT id,title,sell_point,price,image FROM tb_item"&gt; &lt;field column="id" name="id"/&gt; &lt;field column="title" name="item_title"/&gt; &lt;field column="sell_point" name="item_sell_point"/&gt; &lt;field column="price" name="item_price"/&gt; &lt;field column="image" name="item_image"/&gt; &lt;/entity&gt; &lt;/document&gt;&lt;/dataConfig&gt; 第四步、然后打开 tomcat 。 进入网站 192.168.1.102:8080/solr/index.html,出现如下画面 按照我在图片上标明的 步骤 ， 就可以达到如下的效果。 问题总结问题：不同服务器部属后， mysql 的访问权限设置详情：因为我的 solr 服务器是在 虚拟机上 通过 静态ip 地址的桥接设置的，所以 IP 地址与主机的 IP 地址不同，不能使用 localhost 作为 域名。当我使用 192.168.1.101 (注： 我主机的 IP 地址)时， mysql 的用户 root 没有相应的访问权限。如图：解决：那么只需要重新创建一个用户，并赋予相应的权限即可。这样，我们就拥有了 root@% 账户， % 代表着所有的域名。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killJava系列 -- 文件类相关]]></title>
    <url>%2Fblogs%2F21748.html</url>
    <content type="text"><![CDATA[前言最近作项目的时候，用java获取文件。虽然用框架很容易，但是其内部的原理让我很疑惑。在自己写相似的代码的时候，往往会出现各种各样的错误。所以这里，对相关的类以及方法进行一个整合。比如 file 类，path 类。 绝对路径与相对路径。 getResource 方法 ， getRealPath方法等。 绝对路径与相对路径在使用 File 类的时候，发现绝对路径和相对路径的使用有很大的区别。大家都知道：File类是用来构造文件或文件夹的类,在其构造函数中要求传入一个String类型的参数,用于指示文件所在的路径绝对路径名是完整的路径名，不需要任何其他信息就可以定位自身表示的文件。相对路径名必须使用来自其他路径名的信息进行解释 因为我使用的是 idea ，所以下面，我就用idea 给大家演示一下，他们的区别。废话不多说，直接上代码 123456789101112131415161718192021222324public class testFile &#123; public static void main(String[] args) throws IOException &#123; // 绝对路径 File fi1 = new File("D://sy.ini"); // 相对路径 File fi2 = new File("sy.ini"); String test = "000"; try &#123; // 将 test 分别写入 fi1 fi2 FileOutputStream fo1 = new FileOutputStream(fi1); FileOutputStream fo2 = new FileOutputStream(fi2); fo1.write(test.getBytes()); fo2.write(test.getBytes()); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; // 验证 getPath 与 getAbsolubtePath 的区别。 System.out.println(fi1.getPath()); System.out.println(fi1.getAbsolutePath()); System.out.println(fi2.getPath()); System.out.println(fi2.getAbsolutePath()); &#125;&#125; 输出的结果如下 1234D:\sy.iniD:\sy.inisy.iniD:\Programme\0-Java\J_Example\Arithmetic\sy.ini 用两张图片辅助结果 从这个结果中，我们可以看出两点 getPath 只是简单的返回 你赋予的String 值，不管是 相对路径还是绝对路径。 相对路径是相对于自身的项目地址。并且不加 “/“。 getResource用代码说话。。。1234URL resource = testFile.class.getClassLoader().getResource(&quot;.&quot;);URL resource1 = testFile.class.getResource(&quot;.&quot;);System.out.println(resource);System.out.println(resource1); 输出的结果为 12file:/D:/Programme/0-Java/J_Example/Arithmetic/out/production/3_basic/file:/D:/Programme/0-Java/J_Example/Arithmetic/out/production/3_basic/test_01/ 所以对于 getResource 来说 。 如果使用 Class 类 ，则代表该类所在的包为 相对路径的起点。 如果使用 ClassLoader类 , 则代表该类所在的 模块为 相对路径的起点。 JSP 中的路径使用 EL 表达式${pageContext.request.contextPath} 这里的路径指的是 web 的根目录. File类 与 Path类Path 类 是 JDK 7 中加入的新内容。比File 类更快，而且有报错机制，所以更容易使用。 他们两个的 区别 我会写在内部的 注释中。就不单独拿出来写了。 创建文件123456789101112// 如果存在重复 会报错。Path path = Paths.get(&quot;D://test.txt&quot;);Files.createFile(path);// 这里有一个 方法，可直接设置文件的属性。Set perms= PosixFilePermissions.fromString(&quot;rw-rw-rw-&quot;)Files.crateFile(path,perms);// 如果存在重复，会重新创建。// 可以使用 file.exists() 来确认是否存在重复。File file = new File(&quot;D://test02.txt&quot;);file.createNewFile(); 共同点： 想要创建多级目录下的文件，都必须先创建目录，才能创建文件。 创建目录 123456789// 可以直接创建多级目录Path path = Paths.get(&quot;D://test/test01/&quot;);Files.createDirectories(path);// mkdir 只能创建一级目录// mkdirs 可以创建多级目录File file = new File(&quot;D://test02/test3/test3&quot;);file.mkdir();file.mkdirs(); 删除 12345678// 如果文件夹下存在多级目录，则报错// DirectoryNotEmptyExceptionPath path = Paths.get(&quot;D://test/&quot;);Files.delete(path);// 如果文件夹下存在多级目录，则没有反应。。File file = new File(&quot;D://test02&quot;);file.delete(); 如果想要删除相应的文件，直接将 路径更改为文件的路径即可。 遍历文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public static void fileForEach(String path) &#123; File file = new File(path); File[] files = file.listFiles(); for (File f : files) &#123; // 判断是 文件还是 目录 if (f.isFile()) &#123; System.out.println(f.getName() + &quot;是文件!&quot;); &#125; else if (f.isDirectory()) &#123; System.out.println(f.getName()); fileForEach(f.getPath()); &#125; &#125;&#125;public static void main(String[] args) throws IOException &#123; Path path = Paths.get(&quot;D://test/&quot;); Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;() &#123; // 访问文件夹前使用 @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException &#123; System.out.println(dir.getFileName()); return super.preVisitDirectory(dir, attrs); &#125; // 访问文件夹后使用 @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException &#123; return super.postVisitDirectory(dir, exc); &#125; // 访问文件时使用 @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; if (file.toString().endsWith(&quot;.txt&quot;)) &#123; System.out.println(file.getFileName()); &#125; return super.visitFile(file, attrs); &#125; // 访问文件失败使用 @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException &#123; return super.visitFileFailed(file, exc); &#125; &#125;); fileForEach(&quot;D://test02/&quot;);&#125;&#125; 这里出现了 SimpleFileVisitor 这个类，具体使用方法就是覆写其内部方法。经过我的测试 ， 因为这个类的方法， 可以比 fileForEach 快大约 30% 。 复制与移动移动的同时可以更改名字。这一点，都一样。并且与 linux 的操作也类似 Path 类1234Path path = Paths.get(&quot;D://test/test01/cs.txt&quot;);Path to = Paths.get(&quot;D://test/test01/test2.txt&quot;);Files.move(path, to, StandardCopyOption.REPLACE_EXISTING);Files.copy(path, to, StandardCopyOption.REPLACE_EXISTING); 这里的 StandardCopyOption 有三个属性。注意： ATOMIC_MOVE 方法只支持 move 方法。如果将之使用到 copy 方法，则会报错。 123456789101112/* 如果存在则覆盖 * Replace an existing file if it exists. */REPLACE_EXISTING,/* 将属性一同拷贝。 * Copy attributes to the new file. */COPY_ATTRIBUTES,/* 只支持 move 方法，不支持 copy 方法 * Move the file as an atomic file system operation. */ATOMIC_MOVE; 下面是file 类 123456789101112131415161718192021222324252627282930313233// 拷贝 方法public void copyFile(String oldFile,String newFile)&#123;try&#123;int bytesum = 0;int byteread = 0;File oldfile = new File(oldFile);//判断文件是否存在，如果文件存在则实现该文件向新文件的复制if(oldfile.exists())&#123; //读取原文件 InputStream ins = new FileInputStream(oldFile); //创建文件输出流，写入文件 FileOutputStream outs = new FileOutputStream(newFile); //创建缓冲区，大小为500字节 byte[] buffer = new byte[500]; //每次从文件流中读取500字节数据，计算当前为止读取的数据总数 while((byteread = ins.read(buffer)) != -1)&#123; bytesum += byteread; System.out.println(bytesum); //把当前缓冲区中的数据写入新文件 outs.write(buffer,0,byteread); &#125; ins.close();&#125;else //如果原文件不存在，则扔出异常 throw new Exception();&#125;catch(Exception ex)&#123;System.out.print(&quot;原文件不存在！&quot;);ex.printStackTrace();&#125;// 移动 方法File file = new File(&quot;D://test02/test02/test02.txt&quot;);file.renameTo(new File(&quot;D://test02/test02/test.txt&quot;)); 从这里我们可以看出， path 类相对应的 复制方法 非常简单，不需要使用 直接使用输入输出流就可以复制文件。 输入输出流 Path类 File类123File file = new File(&quot;D://test02/test02/test02.txt&quot;);FileInputStream fileInputStream = new FileInputStream(file);FileReader fileReader = new FileReader(file); 相对比，我们也可以看出，Path类相对 file类也简化了很多操作。更有利于开发。 相互转化123path.toFile()File.toPath() 总结 关于路径的使用总结。 关于Path 与 File 类的使用总结。Path 类 相比较于 File 类 ，在操作上更直观，没有涉及到更深的层面.可以看出 研发人员 从中作出了很多改进。 可以让人更专注于逻辑的编写，而非是 底层的基础。虽然并没有针对其 性能作出确切的比较，不过就现有的网络统计来说， Path 类在使用中大都会比 File 类快 , 并且在最新的 lucene 中，也是用 Path 代替了 file 的操作， 相关的文章请参考 []。综上，推荐使用 Path 类替代 File 类。 前言最近作项目的时候，用java获取文件。虽然用框架很容易，但是其内部的原理让我很疑惑。在自己写相似的代码的时候，往往会出现各种各样的错误。所以这里，对相关的类以及方法进行一个整合。比如 file 类，path 类。 绝对路径与相对路径。 getResource 方法 ， getRealPath方法等。 绝对路径与相对路径在使用 File 类的时候，发现绝对路径和相对路径的使用有很大的区别。大家都知道：File类是用来构造文件或文件夹的类,在其构造函数中要求传入一个String类型的参数,用于指示文件所在的路径绝对路径名是完整的路径名，不需要任何其他信息就可以定位自身表示的文件。相对路径名必须使用来自其他路径名的信息进行解释 因为我使用的是 idea ，所以下面，我就用idea 给大家演示一下，他们的区别。废话不多说，直接上代码 123456789101112131415161718192021222324public class testFile &#123; public static void main(String[] args) throws IOException &#123; // 绝对路径 File fi1 = new File("D://sy.ini"); // 相对路径 File fi2 = new File("sy.ini"); String test = "000"; try &#123; // 将 test 分别写入 fi1 fi2 FileOutputStream fo1 = new FileOutputStream(fi1); FileOutputStream fo2 = new FileOutputStream(fi2); fo1.write(test.getBytes()); fo2.write(test.getBytes()); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; // 验证 getPath 与 getAbsolubtePath 的区别。 System.out.println(fi1.getPath()); System.out.println(fi1.getAbsolutePath()); System.out.println(fi2.getPath()); System.out.println(fi2.getAbsolutePath()); &#125;&#125; 输出的结果如下 1234D:\sy.iniD:\sy.inisy.iniD:\Programme\0-Java\J_Example\Arithmetic\sy.ini 用两张图片辅助结果 从这个结果中，我们可以看出两点 getPath 只是简单的返回 你赋予的String 值，不管是 相对路径还是绝对路径。 相对路径是相对于自身的项目地址。并且不加 “/“。 getResource用代码说话。。。1234URL resource = testFile.class.getClassLoader().getResource(&quot;.&quot;);URL resource1 = testFile.class.getResource(&quot;.&quot;);System.out.println(resource);System.out.println(resource1); 输出的结果为 12file:/D:/Programme/0-Java/J_Example/Arithmetic/out/production/3_basic/file:/D:/Programme/0-Java/J_Example/Arithmetic/out/production/3_basic/test_01/ 所以对于 getResource 来说 。 如果使用 Class 类 ，则代表该类所在的包为 相对路径的起点。 如果使用 ClassLoader类 , 则代表该类所在的 模块为 相对路径的起点。 JSP 中的路径使用 EL 表达式${pageContext.request.contextPath} 这里的路径指的是 web 的根目录. File类 与 Path类Path 类 是 JDK 7 中加入的新内容。比File 类更快，而且有报错机制，所以更容易使用。 他们两个的 我会写在内部的 注释中。123就不单独拿出来写了。1. 创建文件 // 如果存在重复 会报错。 Path path = Paths.get(&quot;D://test.txt&quot;); Files.createFile(path); // 这里有一个 方法，可直接设置文件的属性。 Set perms= PosixFilePermissions.fromString(&quot;rw-rw-rw-&quot;) Files.crateFile(path,perms); // 如果存在重复，会重新创建。 // 可以使用 file.exists() 来确认是否存在重复。 File file = new File(&quot;D://test02.txt&quot;); file.createNewFile(); 1234共同点： 想要创建多级目录下的文件，都必须先创建目录，才能创建文件。2. 创建目录 // 可以直接创建多级目录 Path path = Paths.get(&quot;D://test/test01/&quot;); Files.createDirectories(path); // mkdir 只能创建一级目录 // mkdirs 可以创建多级目录 File file = new File(&quot;D://test02/test3/test3&quot;); file.mkdir(); file.mkdirs(); 123. 删除 // 如果文件夹下存在多级目录，则报错 // DirectoryNotEmptyException Path path = Paths.get(&quot;D://test/&quot;); Files.delete(path); // 如果文件夹下存在多级目录，则没有反应。。 File file = new File(&quot;D://test02&quot;); file.delete(); 123如果想要删除相应的文件，直接将 路径更改为文件的路径即可。4. 遍历文件 public static void fileForEach(String path) { File file = new File(path); File[] files = file.listFiles(); for (File f : files) { // 判断是 文件还是 目录 if (f.isFile()) { System.out.println(f.getName() + &quot;是文件!&quot;); } else if (f.isDirectory()) { System.out.println(f.getName()); fileForEach(f.getPath()); } } } public static void main(String[] args) throws IOException { Path path = Paths.get(&quot;D://test/&quot;); Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;() { // 访问文件夹前使用 @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException { System.out.println(dir.getFileName()); return super.preVisitDirectory(dir, attrs); } // 访问文件夹后使用 @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException { return super.postVisitDirectory(dir, exc); } // 访问文件时使用 @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { if (file.toString().endsWith(&quot;.txt&quot;)) { System.out.println(file.getFileName()); } return super.visitFile(file, attrs); } // 访问文件失败使用 @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException { return super.visitFileFailed(file, exc); } }); fileForEach(&quot;D://test02/&quot;); }} 12345678这里出现了 **SimpleFileVisitor** 这个类，具体使用方法就是覆写其内部方法。经过我的测试 ， 因为这个类的方法， 可以比 ** fileForEach** 快大约 ** 30% ** 。5. 复制与移动移动的同时可以更改名字。这一点，都一样。并且与 linux 的操作也类似Path 类 Path path = Paths.get(&quot;D://test/test01/cs.txt&quot;); Path to = Paths.get(&quot;D://test/test01/test2.txt&quot;); Files.move(path, to, StandardCopyOption.REPLACE_EXISTING); Files.copy(path, to, StandardCopyOption.REPLACE_EXISTING); 123这里的 ** StandardCopyOption ** 有三个属性。注意： ATOMIC_MOVE 方法只支持 move 方法。如果将之使用到 copy 方法，则会报错。 /* 如果存在则覆盖 * Replace an existing file if it exists. */ REPLACE_EXISTING, /* 将属性一同拷贝。 * Copy attributes to the new file. */ COPY_ATTRIBUTES, /* 只支持 move 方法，不支持 copy 方法 * Move the file as an atomic file system operation. */ ATOMIC_MOVE; 12下面是file 类 // 拷贝 方法 public void copyFile(String oldFile,String newFile){ try{ int bytesum = 0; int byteread = 0; File oldfile = new File(oldFile); //判断文件是否存在，如果文件存在则实现该文件向新文件的复制 if(oldfile.exists()){ //读取原文件 InputStream ins = new FileInputStream(oldFile); //创建文件输出流，写入文件 FileOutputStream outs = new FileOutputStream(newFile); //创建缓冲区，大小为500字节 byte[] buffer = new byte[500]; //每次从文件流中读取500字节数据，计算当前为止读取的数据总数 while((byteread = ins.read(buffer)) != -1){ bytesum += byteread; System.out.println(bytesum); //把当前缓冲区中的数据写入新文件 outs.write(buffer,0,byteread); } ins.close(); } else //如果原文件不存在，则扔出异常 throw new Exception(); }catch(Exception ex){ System.out.print(&quot;原文件不存在！&quot;); ex.printStackTrace(); } // 移动 方法 File file = new File(&quot;D://test02/test02/test02.txt&quot;); file.renameTo(new File(&quot;D://test02/test02/test.txt&quot;)); 123456789从这里我们可以看出， path 类相对应的 复制方法 非常简单，不需要使用 直接使用输入输出流就可以复制文件。6. 输入输出流Path类![](http://ovmspkp0s.bkt.clouddn.com/201709172336_740.png)File类 File file = new File(&quot;D://test02/test02/test02.txt&quot;); FileInputStream fileInputStream = new FileInputStream(file); FileReader fileReader = new FileReader(file); 1234相对比，我们也可以看出，Path类相对 file类也简化了很多操作。更有利于开发。7. 相互转化 path.toFile()File.toPath() ` 总结 关于路径的使用总结。 关于Path 与 File 类的使用总结。Path 类 相比较于 File 类 ，在操作上更直观，没有涉及到更深的层面.可以看出 研发人员 从中作出了很多改进。 可以让人更专注于逻辑的编写，而非是 底层的基础。虽然并没有针对其 性能作出确切的比较，不过就现有的网络统计来说， Path 类在使用中大都会比 File 类快 , 并且在最新的 lucene 中，也是用 Path 代替了 file 的操作， 相关的文章请参考 []。综上，推荐使用 Path 类替代 File 类。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killJava系列 -- ConcurrentHashmap源码分析]]></title>
    <url>%2Fblogs%2F29869.html</url>
    <content type="text"><![CDATA[前言私信请在SegmentFault转发请注明出处 改进一取消segments字段，直接采用transient volatile HashEntry&lt;K,V&gt;[] table保存数据，采用table数组元素作为锁，从而实现了对每一行数据进行加锁，进一步减少并发冲突的概率。 改进二将原先table数组＋单向链表的数据结构，变更为table数组＋单向链表＋红黑树的结构。对于hash表来说，最核心的能力在于将key hash之后能均匀的分布在数组中。如果hash之后散列的很均匀，那么table数组中的每个队列长度主要为0或者1。但实际情况并非总是如此理想，虽然ConcurrentHashMap类默认的加载因子为0.75，但是在数据量过大或者运气不佳的情况下，还是会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为O(n)；因此，对于个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)，可以改进性能。 1. 内部参数12345678910111213141516171819202122232425262728293031323334353637//初始容积为 16 private static final int DEFAULT_CAPACITY = 16;//加载因子 0.75private static final float LOAD_FACTOR = 0.75f;/** * 盛装Node元素的数组 它的大小是2的整数次幂 * Size is always a power of two. Accessed directly by iterators. */ transient volatile Node&lt;K,V&gt;[] table; /* * hash表初始化或扩容时的一个控制位标识量。 * 负数代表正在进行初始化或扩容操作 * -1代表正在初始化 * -N 表示有N-1个线程正在进行扩容操作 * 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小 * * **既代表 HashMap 的 threshold** * 又代表 **进行扩容时的进程数***/private transient volatile int sizeCtl;// 以下两个是用来控制扩容的时候 单线程进入的变量 // resize校验码private static int RESIZE_STAMP_BITS = 16; // resize校验码的位移量。private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS; /* * Encodings for Node hash fields. See above for explanation. */ static final int MOVED = -1; // hash值是-1，表示这是一个forwardNode节点 static final int TREEBIN = -2; // hash值是-2 表示这时一个TreeBin节点 static final int RESERVED = -3; // hash for transient reservations //在 spread() 方法中 用来对 hashcode 进行 高位hash 减少可能发生的碰撞。 static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash 上面的 sizectl 很重要。是解决 concurrenthashmap 扩容的基础 2. 内部类2.1. Node与 HashMap 最大的区别是 加入了对val 与 next 用了volatile关键字修饰并且 setValue() 方法 直接抛出异常，可以看出，val 是不能直接改变的。是通过 Unsafe 类的 方法进行全部替换 123456789101112131415161718192021static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; //相比于 HashMap ，加入了 volatile 关键字 volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return val; &#125; public final int hashCode() &#123; return key.hashCode() ^ val.hashCode(); &#125; public final String toString()&#123; return key + &quot;=&quot; + val; &#125; public final V setValue(V value) &#123; throw new UnsupportedOperationException(); &#125; 2.2 TreeNode与 HashMap 不同的是 这次 TreeNode 不再是继承自 LinkedHashMap.Entry 而是继承自本类中的 Node. 并不直接用于红黑树的结点，而是将 结点包装成 TreeNode 后，用下面的 TreeBin 进行二次包装。 优点是可以使用 Node 类的 next 指针，方便TreeBin 后续 从 链表 到 红黑树 的转换。构造函数可以看出，原先对TreeNode 的初始化只是设置了其的后续结点。组成了链表。 123456789101112static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123;TreeNode&lt;K,V&gt; parent; // red-black tree linksTreeNode&lt;K,V&gt; left;TreeNode&lt;K,V&gt; right;TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletionboolean red;TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent;&#125; 2.3. TreeBin特点： 1. 不持有key与val ，指向TreeNode 的 root 与 list。 2. 加入读写锁。方便并发的访问。 12345678910static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; //通过锁的状态 ， 判断锁的类型。 volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock 构造方法如下root 代表 TreeNode 的根结点使用first ，是用于第一次初始化时，因为root的特殊性，所以不便于 this.root = b 因此通过 first代替第一次的初始化过程。然后在 过程中 用r 代表root ，直到结束 红黑树的初始化后，再 root =r保证root的安全性。 12345678910111213141516171819202122232425262728293031323334353637383940414243TreeBin(TreeNode&lt;K,V&gt; b) &#123; super(TREEBIN, null, null, null); this.first = b; TreeNode&lt;K,V&gt; r = null; for (TreeNode&lt;K,V&gt; x = b, next; x != null; x = next) &#123; next = (TreeNode&lt;K,V&gt;)x.next; x.left = x.right = null; if (r == null) &#123; x.parent = null; x.red = false; r = x; &#125; else &#123; K k = x.key; int h = x.hash; Class&lt;?&gt; kc = null; for (TreeNode&lt;K,V&gt; p = r;;) &#123; int dir, ph; K pk = p.key; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; if (dir &lt;= 0) xp.left = x; else xp.right = x; r = balanceInsertion(r, x); break; &#125; &#125; &#125; &#125; this.root = r; assert checkInvariants(root); &#125; 2.4. ForwardingNode作用是在 transfer() 过程中，插入到 TreeBin 之间，用作链接作用。 123456static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125; 3. Unsafe 类 与 常用的操作3.1. Unsafe 与 静态代码块Unsafe提供了硬件级别的原子操作。内部的方法均为 native方法 ,可以访问系统底层。这里用了 CAS 算法（compare and swap) 大大的避免了使用时对性能的消耗，以及保证了使用时的安全性。 注： CAS 算法的核心是 将需要改变的参数，与内存中已经存在的变量的值进行对比，一致就改变，不一致就放弃这次操作。与之相类似的优化操作还有 LL/SC(Load-Linked/Store-Conditional : 加载链接/条件存储) 、 Test-and-Set(测试并设置)这里额外介绍一下 Unsafe 类的 compareAndSwapInt 方法。12345678910/*** 比较obj的offset处内存位置中的值和期望的值，如果相同则更新。此更新是不可中断的。* * @param obj 需要更新的对象* @param offset obj中整型field的偏移量* @param expect 希望field中存在的值* @param update 如果期望值expect与field的当前值相同，设置filed的值为这个新值* @return 如果field的值被更改返回true*/public native boolean compareAndSwapInt(Object obj, long offset, int expect, int update); 下面是 ConcurrentHashMap 中有关的应用123456789101112131415161718192021222324252627282930313233343536373839404142434445// Unsafe mechanicsprivate static final sun.misc.Unsafe U;//对应于 类中的 sizectlprivate static final long SIZECTL;//在 transfer() 方法的使用时，计算索引private static final long TRANSFERINDEX;// 用于对 ConcurrentHashMap 的 size 统计。// 下文 第8点关于 size 会说明。private static final long BASECOUNT;// 辅助类 countercell 类中的属性，用于分布式计算// 是实现 java8 中 londAddr 的基础private static final long CELLSBUSY;private static final long CELLVALUE;// 用来确定在数组中的位置// 数组中的偏移地址private static final long ABASE;// 数组中的增量地址private static final int ASHIFT;static &#123; try &#123; //通过反射调用 类中的值，从而对 这些变量赋值 U = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = ConcurrentHashMap.class; SIZECTL = U.objectFieldOffset (k.getDeclaredField(&quot;sizeCtl&quot;)); TRANSFERINDEX = U.objectFieldOffset (k.getDeclaredField(&quot;transferIndex&quot;)); BASECOUNT = U.objectFieldOffset (k.getDeclaredField(&quot;baseCount&quot;)); CELLSBUSY = U.objectFieldOffset (k.getDeclaredField(&quot;cellsBusy&quot;)); Class&lt;?&gt; ck = CounterCell.class; CELLVALUE = U.objectFieldOffset (ck.getDeclaredField(&quot;value&quot;)); Class&lt;?&gt; ak = Node[].class; ABASE = U.arrayBaseOffset(ak); int scale = U.arrayIndexScale(ak); if ((scale &amp; (scale - 1)) != 0) throw new Error(&quot;data type scale not a power of two&quot;); ASHIFT = 31 - Integer.numberOfLeadingZeros(scale); &#125; catch (Exception e) &#123; throw new Error(e); &#125;&#125; 3.2 常用方法在操作过程中，经常会看到以下几个，或者相类似的方法。其核心是12345678910111213 //获得 i 位置上的 Node 节点static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE); &#125; //利用CAS算法设置i位置上的Node节点。 static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v); &#125; //利用volatile方法设置节点位置的值 static final &lt;K,V&gt; void setTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; v) &#123; U.putObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, v); &#125; 4. 初始化函数 initTable调用ConcurrentHashMap的构造方法仅仅是设置了一些参数而已，而整个table的初始化是在向ConcurrentHashMap中插入元素的时候发生的。当向 map 插入数据的时候 table == null , 则会调用 initTable()方法 。用 put 方法 简单展示一下。12345678910final V putVal(K key, V value, boolean onlyIfAbsent) &#123; ... ... for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); ... ...&#125; initTable() 方法展示如下其中有 sizectl 变量，这里回顾一下 hash表初始化或扩容时的一个控制位标识量。 负数代表正在进行初始化或扩容操作 -1代表正在初始化 -N 表示有N-1个线程正在进行扩容操作 正数或0代表hash表还没有被初始化，这个数值表示初始化或下一次进行扩容的大小1234567891011121314151617181920212223242526272829303132/** * Initializes table, using the size recorded in sizeCtl. */ private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; //sizeCtl &lt;0 表示有其他线程正在进行初始化操作，把线程挂起。对于table的初始化工作，只能有一个线程在进行。 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //利用CAS方法把sizectl的值置为-1 表示本线程正在进行初始化 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //相当于0.75*n 设置一个扩容的阈值 // sc = n - n/4 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // 更新 sizectl sizeCtl = sc; &#125; break; &#125; &#125; return tab; &#125; 5. transfer() 扩容操作当ConcurrentHashMap容量不足的时候，需要对table进行扩容。这个方法的基本思想跟HashMap是很像的，但是由于它是支持并发扩容的，所以要复杂的多。原因是它支持多线程进行扩容操作，而并没有加锁。我想这样做的目的不仅仅是为了满足concurrent的要求，而是希望利用并发处理去减少扩容带来的时间影响。因为在扩容的时候，总是会涉及到从一个“数组”到另一个“数组”拷贝的操作，如果这个操作能够并发进行，那真真是极好的了。 整个扩容操作分为两个部分: 1. 第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。这个单线程的保证是通过RESIZE_STAMP_SHIFT这个常量经过一次运算来保证的，这个地方在后面会有提到； 2. 第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。 先来看一下单线程是如何完成的：它的大体思想就是遍历、复制的过程。首先根据运算得到需要遍历的次数i，然后利用tabAt方法获得i位置的元素： 1. 如果这个位置为空，就在原table中的i位置放入forwardNode节点，这个也是触发并发扩容的关键点； 2. 如果这个位置是Node节点（fh&gt;=0），就构造两个链表，一个代表高位为 0 ， 一个代表高位为 1 。将原来的结点 分别放在nextTable的i和i+n的位置上，并且除了lastRun的位置相对位于链表的底部外，其余元素均为 **反序** 。 3. 如果这个位置是TreeBin节点（fh&lt;0），也做一个处理，并且判断是否需要untreefi，把处理的结果分别放在nextTable的i和i+n的位置上 遍历过所有的节点以后就完成了复制工作，这时让nextTable作为新的table，并且更新sizeCtl为新容量的0.75倍 ，完成扩容。 再看一下多线程是如何完成的： 123//如果遍历到ForwardingNode节点 说明这个点已经被处理过了,直接跳过 这里是控制并发扩容的核心 else if ((fh = f.hash) == MOVED) advance = true; // already processed 这是一个判断，如果遍历到的节点是forward节点，就向后继续遍历，再加上给节点上锁的机制，就完成了多线程的控制。多线程遍历节点，处理了一个节点，就把对应点的值set为forward，另一个线程看到forward，就向后遍历。这样交叉就完成了复制工作。而且还很好的解决了线程安全的问题。 下面是源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181/** * 一个过渡的table表 只有在扩容的时候才会使用 */private transient volatile Node&lt;K, V&gt;[] nextTable;/** * Moves and/or copies the nodes in each bin to new table. See * above for explanation. */private final void transfer(Node&lt;K, V&gt;[] tab, Node&lt;K, V&gt;[] nextTab) &#123; int n = tab.length, stride; // 通过计算 NCPU CPU的核心数与 表的大小的比值，将表进行范围的细分，以方便 并发。 // 感觉上 有点像 segment 分段锁的意思。 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; //构造一个nextTable对象 它的容量是原来的两倍。 @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K, V&gt;[] nt = (Node&lt;K, V&gt;[]) new Node&lt;?, ?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME //原来的 容量限制为 1&lt;&lt;30 //HashMap 在扩容时，会用 resize（） 方法，扩大 threshold 的值 //当大于 MAXIMUM_CAPACITY 时，会将 threshold 设置为 Integer.MAX_VALUE sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; ForwardingNode&lt;K, V&gt; fwd = new ForwardingNode&lt;K, V&gt;(nextTab);//构造一个连节点指针 用于标志位 boolean advance = true;//并发扩容的关键属性 如果等于true 说明这个节点已经处理过 boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0; ; ) &#123; Node&lt;K, V&gt; f; int fh; //这个while循环体的作用就是在控制i递减 通过i可以依次遍历原hash表中的节点 while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; //如果所有的节点都已经完成复制工作 就把nextTable赋值给table 清空临时对象nextTable nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1);//扩容阈值设置为原来容量的1.5倍 依然相当于现在容量的0.75倍 return; &#125; //利用CAS方法更新这个扩容阈值，在这里面sizectl值减一，说明新加入一个线程参与到扩容操作 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true; i = n; // recheck before commit &#125; &#125; //如果遍历到的节点为空 则放入ForwardingNode指针 else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); //如果遍历到ForwardingNode节点 说明这个点已经被处理过了,直接跳过 这里是控制并发扩容的核心 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; //节点上锁 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K, V&gt; ln, hn; //如果fh&gt;=0 证明这是一个Node节点 if (fh &gt;= 0) &#123; // runBit 代表正在 运行的 Node 节点的 分类 // 因此链表根据高位为0或者1分为两个子链表，高位为0的节点桶位置没有发生变化，高位为1的节点桶位置增加了n， // 所以有setTabAt(nextTab, i, ln);和 setTabAt(nextTab, i + n, hn); // n = 2的幂 。 二进制 0001000 // fh &amp; n = 1. 1000 // 2. 0000 所以划分出两个链表。 int runBit = fh &amp; n; // lastRun 是正在运行的节点 Node&lt;K, V&gt; lastRun = f; //以下的部分在完成的工作是构造两个链表 一个是高位为 0 的链表 另一个是高位为 1 的链表 // 找出最后一个 与后面的结点不同的 结点 for (Node&lt;K, V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; // 将最后一个 结点保存起来 if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K, V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; //这个链表是从低层向上构建 // ln 或 hn = lastRun, 构建一个 node 结点 // 其下一个结点为 lastRun 。 if ((ph &amp; n) == 0) // 构建低位链表 ln = new Node&lt;K, V&gt;(ph, pk, pv, ln); else // 构建高位链表 hn = new Node&lt;K, V&gt;(ph, pk, pv, hn); &#125; //在nextTable的i位置上插入一个链表 setTabAt(nextTab, i, ln); //在nextTable的i+n的位置上插入另一个链表 setTabAt(nextTab, i + n, hn); //在table的i位置上插入forwardNode节点 表示已经处理过该节点 setTabAt(tab, i, fwd); //设置advance为true 返回到上面的while循环中 就可以执行 --i 操作 advance = true; &#125; //对TreeBin对象进行处理 与上面的过程类似 else if (f instanceof TreeBin) &#123; TreeBin&lt;K, V&gt; t = (TreeBin&lt;K, V&gt;) f; TreeNode&lt;K, V&gt; lo = null, loTail = null; TreeNode&lt;K, V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; //构造高位和低位两个链表 for (Node&lt;K, V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K, V&gt; p = new TreeNode&lt;K, V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; //如果扩容后已经不再需要tree的结构 反向转换为链表结构 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K, V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K, V&gt;(hi) : t; //在nextTable的i位置上插入一个链表 setTabAt(nextTab, i, ln); //在nextTable的i+n的位置上插入另一个链表 setTabAt(nextTab, i + n, hn); //在table的i位置上插入forwardNode节点 表示已经处理过该节点 setTabAt(tab, i, fwd); //设置advance为true 返回到上面的while循环中 就可以执行 --i 操作 advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 6. put 方法 put方法依然沿用HashMap的put方法的思想，根据hash值计算这个新插入的点在table中的位置i。 注： 1. hash = spread(key.hashCode()) 2. spread(int h) --&gt; return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS; --&gt; 通过hashCode()的高16位异或低16位优化高位运算的算法 3. else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin } 如果i位置是空的，直接放进去，否则进行判断，如果i位置是树节点，按照树的方式插入新的节点，否则把i插入到链表的末尾不同点：ConcurrentHashMap不允许key或value为null值。 多线程的情况下： 如果一个或多个线程正在对ConcurrentHashMap进行扩容操作，当前线程也要进入扩容的操作中。这个扩容的操作之所以能被检测到，是因为transfer方法中在空结点上插入forward节点，如果检测到需要插入的位置被forward节点占有，就帮助进行扩容； –&gt; helpTransfer() 方法。 如果检测到要插入的节点是非空且不是forward节点，就对这个节点加锁，这样就保证了线程安全。尽管这个有一些影响效率，但是还是会比hashTable的synchronized要好得多。 首先判断这个节点的类型。如果是链表节点（fh&gt;0）,则得到的结点就是hash值相同的节点组成的链表的头节点。需要依次向后遍历确定这个新加入的值所在位置。如果遇到hash值与key值都与新加入节点是一致的情况，则只需要更新value值即可。否则依次向后遍历，直到链表尾插入这个结点。 如果加入这个节点以后链表长度大于8，就把这个链表转换成红黑树。 如果这个节点的类型已经是树节点的话，直接调用树节点的插入方法进行插入新的值。 源码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //不允许 key或value为null if (key == null || value == null) throw new NullPointerException(); //计算hash值 int hash = spread(key.hashCode()); //计算该链表 节点的数量 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 第一次 put 操作的时候初始化，如果table为空的话，初始化table if (tab == null || (n = tab.length) == 0) tab = initTable(); //根据hash值计算出在table里面的位置 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 根据对应的key hash 到具体的索引，如果该索引对应的 Node 为 null，则采用 CAS 操作更新整个 table // 如果这个位置没有值 ，直接放进去，不需要加锁 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //当遇到表连接点时，需要进行整合表的操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; // 结点上锁，只是对链表头结点作锁操作 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //fh &gt; 0 说明这个节点是一个链表的节点 不是树的节点 if (fh &gt;= 0) &#123; binCount = 1; //在这里遍历链表所有的结点 //并且计算链表里结点的数量 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果hash值和key值相同 则修改对应结点的value值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; //如果遍历到了最后一个结点，那么就证明新的节点需要插入 就把它插入在链表尾部 if ((e = e.next) == null) &#123; // 插入到链表尾 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //如果这个节点是树节点，就按照树的方式插入值 else if (f instanceof TreeBin) &#123; // 如果是红黑树结点，按照红黑树的插入 Node&lt;K,V&gt; p; // 如果为树节点， binCount一直为2，不会引发扩容。 binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 如果这个链表结点达到了临界值8，那么把这个链表转换成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //将当前ConcurrentHashMap的元素数量+1，table的扩容是在这里发生的 addCount(1L, binCount); return null;&#125; 6.1 helpTransfer() 方法出现于 put 方法 如下地点123//当遇到表连接点时，需要进行整合表的操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); helpTransfer() 方法的源码如下1234567891011121314151617181920212223final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; // 当前 table 不为 null , 且 f 为 forwardingNode 结点 ， 且存在下一张表 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length);//计算一个扩容校验码 // 当 sizeCtl &lt; 0 时，表示有线程在 transfer(). while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; //正常情况下 sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT == resizeStamp(tab.length); if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; //将 扩容的线程先行减一，表示，这是来辅助 transfer，而非进行 transfer的线程。 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table; &#125; 6.2 treeifyBin() 方法涉及变量 MIN_TREEIFY_CAPACITY = 64;如果数组长度n小于阈值MIN_TREEIFY_CAPACITY，默认是64，则会调用tryPresize方法把数组长度扩大到原来的两倍，并触发transfer方法，重新调整节点的位置。出现于 put 方法 如下地点12345678if (binCount != 0) &#123; // TREEIFY_THRESHOLD 默认为 8. if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break;&#125; 其中源码如下：123456789101112131415161718192021222324252627private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 将原来的数组扩大为原来的两倍 tryPresize(n &lt;&lt; 1); else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; 6.3 tableSizeFor 方法这里讲一个 JDK8 中设计的非常巧妙的算法。看了好久才看懂。出自 tryPresize 方法中的以下位置12345//数组的最大容积为 1&lt;&lt;30 。如果数组大小超过 1&lt;&lt;29 ，则将最大大小设置为 MAXIMUM_CAPACITY//否则，设置为原来的两倍。private final void tryPresize(int size) &#123; int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); 下面让我们来分析一下，tableSizeFor()这个算法的目的，是得出相比较于给定参数，返回一个刚好比参数大的 2次幂 整数。123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 先来分析有关n位操作部分：先来假设n的二进制为01xxx…xxx。接着对n右移1位：001xx…xxx，再位或：011xx…xxx对n右移2为：00011…xxx，再位或：01111…xxx此时前面已经有四个1了，再右移4位且位或可得8个1同理，有8个1，右移8位肯定会让后八位也为1。综上可得，该算法让最高位的1后面的位全变为1。 最后再让结果n+1，即得到了2的整数次幂的值了。 现在回来看看第一条语句：int n = cap - 1; 让cap-1再赋值给n的目的是另找到的目标值大于或等于原值。例如二进制1000，十进制数值为8。如果不对它减1而直接操作，将得到答案10000，即16。显然不是结果。减1后二进制为111，再进行操作则会得到原来的数值1000，即8。 引用自(http://www.cnblogs.com/loading4/p/6239441.html) 7. get 方法通过 key值 搜索 value 值。并且要 通过分辨 结点的种类，进行不同形式的寻找。 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //计算hash值 int h = spread(key.hashCode()); //根据hash值确定节点位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //如果搜索到的节点key与传入的key相同且不为null,直接返回这个节点 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //如果eh&lt;0 说明这个节点在树上 直接寻找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //否则遍历链表 找到对应的值并返回 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; 8. Size相关《并发编程实战》中有提到，size返回的结果在计算时可能已经过期了，它实际上只是一个估计值，因此允许size返回一个近似值，而不是一个精确值。 8.1 CounterCell 类从注释中可以看出，这是从 LongAdder 类中的思想，拷贝过来的一个类。LongAdder 类 是 JDK 1.8 新引进的类，其思想： 多个线程持有自己的加数（cell),线程个数增加时，会自动提供新的加数。当所有工作做完后，再提供新的加数。 有时间写一篇相关的源码分析. 不过，这里一样不能精确统计，这里的 CounterCell 等同于 LongAdder.Cell sumCount() 等同于 LongAdder.sum()方法。执行逻辑是一样的。就 LongAdder 类中的 sum 方法所说， 当有线程在运行时，一样只是估计值，只有当所有线程执行完毕，才是实际值。而统计 Size ，不能够像垃圾清除一样，有 Safe point 或 Safe region ，所以，这个假设不成立。。。 其相关的源码如下。 123456789101112131415161718192021 /** * A padded cell for distributing counts. Adapted from LongAdder * and Striped64. See their internal docs for explanation. */ @sun.misc.Contended static final class CounterCell &#123; volatile long value; CounterCell(long x) &#123; value = x; &#125; &#125; //执行逻辑 final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 8.2 mappingCount 方法就官方文档中所说， mappingCount 方法，应该取代 size 方法，但这个方法得出的值一样在线程运行的时候，只是一个估计的值。从源码中就可以看出，使用的是上文分析的 sumCount() 方法。 1234public long mappingCount() &#123; long n = sumCount(); return (n &lt; 0L) ? 0L : n; // ignore transient negative values&#125; 8.3 addCount 方法出自于 put 方法的如下位置 1234 //将当前ConcurrentHashMap的元素数量+1 addCount(1L, binCount); return null; &#125; 统计上：这里用到 CounterCell类，并且统计的值的计算一样是采用的 sumCount() 方法。所以缺点如上，不再阐述。扩容上：逻辑与 helpTransfer() 类似，都是判断是否有多个线程在执行扩容，然后判断是否需要辅助 transfer();源码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445private final void addCount(long x, int check) &#123; //用到了 CounterCell 类 CounterCell[] as; long b, s; //利用CAS方法更新baseCount的值 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; //如果check值大于等于0 则需要检验是否需要进行扩容操作 //下面的逻辑与 helpTransfer() 类似，可以与 helpTransfer() 一起参考。 if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); //如果已经有其他线程在执行扩容操作 if (sc &lt; 0) &#123; //校验失效，直接退出。 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //当前线程是唯一的或是第一个发起扩容的线程 此时nextTable=null else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); s = sumCount(); &#125; &#125; &#125; 结语喜欢的小伙伴可以点个关注，不定期干货更新加油加油]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库范式与优化]]></title>
    <url>%2Fblogs%2Ffacc1860.html</url>
    <content type="text"><![CDATA[1NF的定义为：符合1NF的关系中的每个属性都不可再分。 2NF: 消除了非主属性对于码的部分函数依赖。 函数依赖：若在一张表中，在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说Y函数依赖于X，写作 X → Y 完全函数依赖 ： 在一张表中，若 X → Y，且对于 X 的任何一个真子集（假如属性组 X 包含超过一个属性的话），X ‘ → Y 不成立，那么我们称 Y 对于 X 完全函数依赖 部分函数依赖 传递函数依赖 码，最小完全依赖 非主属性。3NF: 消除了非主属性对于码的传递函数依赖。 优化5.1.SELECT子句中避免使用 “*”当你想在SELECT子句中列出所有的COLUMN时，使用动态SQL列引用‘’是一个方便的方法。不幸的是，这是一个非常低效的方法。 实际上，ORACLE在解析的过程中, 会将“” 依次转换成所有的列名, 这个工作是通过查询数据字典完成的, 这意味着将耗费更多的时间。 5.2.删除重复记录！最高效的删除重复记录方法 ( 因为使用了ROWID) 1DELETE FROM EMP E WHERE E.ROWID &gt; (SELECT MIN(X.ROWID) FROM EMP X WHERE X.EMP_NO = E.EMP_NO) 5.3. 用TRUNCATE替代DELETE 当删除表中的记录时，在通常情况下，回滚段(rollback segments ) 用来存放可以被恢复的信息，如果你没有COMMIT事务，ORACLE会将数据恢复到删除之前的状态(准确地说是恢复到执行删除命令之前的状况)，而当运用TRUNCATE时, 回滚段不再存放任何可被恢复的信息.当命令运行后,数据不能被恢复.因此很少的资源被调用,执行时间也会很短. 5.4.计算记录条数！ 和一般的观点相反, count(*) 比count(1)稍快 ，当然如果可以通过索引检索，对索引列的计数仍旧是最快的. 例如 COUNT(EMPNO) 5.5. 用EXISTS替代IN在许多基于基础表的查询中,为了满足一个条件,往往需要对另一个表进行联接.在这种情况下, 使用EXISTS(或NOT EXISTS)通常将提高查询的效率. –低效 * FROM EMP WHERE EMPNO > 0 AND DEPTNO IN (SELECT DEPTNO FROM DEPT WHERE LOC 1234--高效```SELECT * FROM EMP WHERE EMPNO &gt; 0 AND EXISTS (SELECT ‘X’ FROM DEPT WHERE DEPT.DEPTNO = EMP.DEPTNO AND LOC = ‘MELB’) 5.6.用EXISTS替换DISTINCT当提交一个包含一对多表信息(比如部门表和雇员表)的查询时,避免在SELECT子句中使用DISTINCT. 一般可以考虑用EXIST替换 例如: –低效: DISTINCT DEPT_NO,DEPT_NAME FROM DEPT D,EMP E WHERE D.DEPT_NO 1234--高效: ```SELECT DEPT_NO,DEPT_NAME FROM DEPT D WHERE EXISTS ( SELECT ‘X’ FROM EMP E WHERE E.DEPT_NO = D.DEPT_NO) –EXISTS 使查询更为迅速 5.7. 用&gt;=替代&gt;–如果DEPTNO上有一个索引 –高效： SELECT * FROM EMP WHERE DEPTNO &gt;=4 –低效： SELECT * FROM EMP WHERE DEPTNO &gt;3 两者的区别在于, 前者DBMS将直接跳到第一个DEPT等于4的记录而后者将首先定位到DEPTNO=3的记录并且向前扫描到第一个DEPT大于3的记录. 5.8.应尽量避免在 where 子句中对字段判断!如： select id from t where num is null 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： select id from t where num=0 5.9.应避免在 where 中使用!=或&lt;&gt;操作符将导致引擎放弃使用索引而进行全表扫描。优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。 5.10.应避免在 where 子句中使用 or 连接!否则将导致引擎放弃使用索引而进行全表扫描，如： select id from t where num=10 or num=20 可以这样查询： select id from t where num=10 union all select id from t where num=20 5.11.in 和 not in 也要慎用!因为IN会使系统无法使用索引,而只能直接搜索表中的数据。如： select id from t where num in(1,2,3) 对于连续的数值，能用 between 就不要用 in 了： select id from t where num between 1 and 3 5.12.应避免在 where 中进行表达式操作!这将导致引擎放弃使用索引而进行全表扫描。如： SELECT * FROM T1 WHERE F1/2=100 应改为: SELECT FROM T1 WHERE F1=1002 SELECT * FROM RECORD WHERE SUBSTRING(CARD_NO,1,4)=’5378’ 应改为: SELECT * FROM RECORD WHERE CARD_NO LIKE ‘5378%’ SELECT member_number, first_name, last_name FROM members WHERE DATEDIFF(yy,datofbirth,GETDATE()) &gt; 21 应改为: SELECT member_number, first_name, last_name FROM members WHERE dateofbirth &lt; DATEADD(yy,-21,GETDATE()) 即：任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。 5.13.应避免在where子句中进行函数操作！这将导致引擎放弃使用索引而进行全表扫描。如： select id from t where substring(name,1,3)=’abc’ –name以abc开头的id select id from t where datediff(day,createdate,’2005-11-30’)=0 –‘2005-11-30’生成的id 应改为: select id from t where name like ‘abc%’ select id from t where createdate&gt;=’2005-11-30′ and createdate&lt;’2005-12-1’ 5.14.不要在 where 中的“=”左边运算！进行函数、算术运算或其他表达式运算，系统将可能无法正确使用索引。 5.15.尽量避免向客户端返回大数据量！若数据量过大，应该考虑相应需求是否合理。 5.16. 避免使用不兼容的数据类型！例如float和int、char和varchar、binary和varbinary是不兼容的。数据类型的不兼容可能使优化器无法执行一些本来可以进行的优化操作。例如: name FROM employee WHERE salary > 60000```1234567891011在这条语句中,如salary字段是money型的,则优化器很难对其进行优化,因为60000是个整型数。我们应当在编程时将整型转化成为钱币型,而不要等到运行时转化。#### 5.17.充分利用连接条件！在某种情况下，两个表之间可能不只一个的连接条件，这时在 WHERE 子句中将连接条件完整的写上，有可能大大提高查询速度。例：SELECT SUM(A.AMOUNT) FROM ACCOUNT A,CARD B WHERE A.CARD_NO = B.CARD_NO```SELECT SUM(A.AMOUNT) FROM ACCOUNT A,CARD B WHERE A.CARD_NO = B.CARD_NO AND A.ACCOUNT_NO=B.ACCOUNT_NO 第二句将比第一句执行快得多。 5.18、能用GROUP BY的就不用DISTINCTSELECT DISTINCT OrderID FROM Details WHERE UnitPrice &gt; 10 可改为： SELECT OrderID FROM Details WHERE UnitPrice &gt; 10 GROUP BY OrderID 5.19.能用UNION ALL就不要用UNION！UNION ALL不执行SELECT DISTINCT函数，这样就会减少很多不必要的资源 5.20.尽量不要用SELECT INTO语句！SELECT INOT 语句会导致表锁定，阻止其他用户访问该表。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[版本控制 -- SVN 整合 idea]]></title>
    <url>%2Fblogs%2F25108.html</url>
    <content type="text"><![CDATA[前言现在 GIT 确实是最火的 版本控制。 SVN 有被淘汰的感觉。但是。在小型团队中，不需要这种大范围的代码提交以及修改的情况下。用 SVN 的效率并不会弱于 GIT 。尤其是目前 GIT 偶尔会出现一些小问题。(我不知道大家有没有，不过我在使用的时候，偶尔会产生连接不上 GIT，或者网速奇慢无比的情况。估计是 … 墙？) 1. 前期准备首先打开 svn 官网(http://subversion.apache.org/packages.html#windows)然后找到适合自己的 svn 版本下载。这里，我下载的是 visualSVN，所以以下都以 visualSVN Server为基准然后可以选择个人使用版，免费使用，尊重版权 2. 基本命令注： 以下所有的命令都默认带有前缀 svn svnadmin create 创建版本库 注： svnadmin create .：在当前位置建立版本库 svnserve -d -r 目录: 使用命令svnserve启动服务 checkout 从版本库创建工作副本 用于从另外一台计算机上初始化目录。 update 从版本库更新工作副本 add 添加文件 commit 对版本库进行更改 -m : 添加注释 status 复查变化 revert 修复错误,重置操作,版本回退 -R : 恢复目录 merge 自动处理安全合并 resolve 解决冲突 分支操作 copy 创建分支copy main/ branches/my_branch: 为 main 创建分支 branches/my_branch cd 切换分支cd branches/my_branch: 切换到分支 branches/my_branch merge 融合分支1.cd main - 2. update - 3.merge ../branches/my_branch: 切换到分支main,然后更新，再整合分支 创建标签 copy main/ tags/01：创建新目录tags 查看历史： log: 用来展示svn 的版本作者、日期、路径等等。 diff: 用来显示特定修改的行级详细信息。 cat: 取得在特定版本的某文件显示在当前屏幕。 list: 显示一个目录或某一版本存在的文件。 下面介绍图形界面 visualSVN Server 。 3. visualSVN Server介绍 直接在 visualSVN Server 中 可以完成一切关于SVN的操作，更加的方便。 4. 整合 idea1. 上传至服务端当你写好一个项目，准备开始上传至SVN时，应该怎么办呢首先打开一个新的项目，然后按照图示操作 选择一个仓库，进行上传 然后 share 。会让你选择 模式与 帐户密码 下面完成真正的上传操作 Reformat code 格式化代码，如果是 Web 开发建议不要勾选，因为格式化 JSP 类文件，格式化效果不好。如果都是 Java 类则可以安心格式化。 Rearrange code 重新编排代码，IntelliJ IDEA 支持各种复杂的编排设置选项，这个会在后面说。设置好了编码功能之后，这里就可以尝试勾选这个进行自动编排。 Optimize imports 优化导入包，会在自动去掉没有使用的包。这个建议都勾选，这个只对 Java 类有作用，所以不用担心有副作用。 Perform code analysis 进行代码分析，这个建议不用在提交的时候处理，而是在开发完之后，要专门养成对代码进行分析的习惯。IntelliJ IDEA 集成了代码分析功能。 Check TODO 检查代码中的 TODO。 Cleanup 清除下版本控制系统，去掉一些版本控制系统的错误信息，建议勾选。 注： 这里的 Perform code analysis 是默认勾选的，但是这个有点坑，可能会出现你在代码里写的是对的，完全可以跑起来，但是不能上传的情况，所以，真的不建议大家勾选，其他的，看个人喜好 这样，将服务端的代码就创建好了，下面开始模拟在客户端 checkout 的情况 2. 从服务端整合代码首先设置进入后，是这一个界面 这里是为了，解决以下这种错误的出现1Cannot load supported formats: Cannot run program "svn"; CreateProcess error =2,系统找不到指定的文件 然后，我们继续 在下面的这个框里，写下你在 visualSVN 界面下找到的 url，然后点击 checkout 注意，如果，你设置了权限的话，需要输入，才能连接然后按下图操作 当出现这种情况时，有以下两种方式使用。 继续创建 放弃，导出到对应的项目名称的文件夹下。 这个博主(http://blog.csdn.net/qq_27093465/article/details/74898489)给出了 第二种方法的使用，那我就给出第一种方法的使用。 然后一路确定就可以了最后的界面是这样子的。。。 3. 界面的介绍默认界面 对于没有版本的文件，也就是新创建的文件，右键后选择添加即可。 创建 changelist这里的 changelist 是 idea 独有的一个概念可以将不同的文件归为不同的类别，然后分别提交 我们点击 加号可以创建 changelist 这里，我就不展示了。这里有三个 changelist可以选中其中之一，然后点击提交。这样只会提交这一个 list ，而不会影响到其他的。我认为极大的提高了效率。 当你想要移动文件到其他的分支时，可以右键这个文件，然后选择其他分支。这里我移动到了test_02分支下，这是效果图。 忽视界面下面是针对性的忽视某些文件。 这里更正一下，上下的介绍相反了。。。 对不住各位。 点击加号后，有三个选项 按照详细文件忽视 按照文件夹忽视 按照正则表达式忽视这里我选择三，因为大家上传时，除了第一个人，一般不会将 .iml 文件上传。所以将其忽视。最后的效果如下图 可以看出，这里的 .iml 文件显示为灰黄色，所以不会改变。注： idea 默认会将 target 文件夹收入 ignore 中，所以不用手动设置 . 提交界面再往下走，我们点击 提交。会显示如下的界面。上文虽然简单的介绍过，不过这里再介绍下。 Reformat code 格式化代码，如果是 Web 开发建议不要勾选，因为格式化 JSP 类文件，格式化效果不好。如果都是 Java 类则可以安心格式化。 Rearrange code 重新编排代码，IntelliJ IDEA 支持各种复杂的编排设置选项，这个会在后面说。设置好了编码功能之后，这里就可以尝试勾选这个进行自动编排。 Optimize imports 优化导入包，会在自动去掉没有使用的包。这个建议都勾选，这个只对 Java 类有作用，所以不用担心有副作用。 Perform code analysis 进行代码分析，这个建议不用在提交的时候处理，而是在开发完之后，要专门养成对代码进行分析的习惯。IntelliJ IDEA 集成了代码分析功能。 Check TODO 检查代码中的 TODO。 Cleanup 清除下版本控制系统，去掉一些版本控制系统的错误信息，建议勾选。 update copyright 。。。不认识。 5. 优化。这里可以决定用什么来作 版本控制 然后是选择添加和删除文件时默认的一些设置基本是三个套路 通知你让你选择 默认做，你不知道 默认不做 这里是一些 ignore 的文件。 然后就是关于 subversion 的配置第一个不要 打勾，不然可能会出现问题。第二个是说你是否自己选择 SVN 的目录。这里如果你将 SVN 设置为 环境变量的话，一般不需要选择。第三个默认就好，不会影响项目。 然后还有一个插件，可以帮助关闭SVN。下载这个插件后，重启。就可以使用了。从 VCS 中可以找到这个插件。非常的方便。 总结以上就是我在使用 SVN 时的一些步骤，应付基本的业务使用，应该是没有问题的。至于更深入的使用，我想公司里会有专人负责版本控制的吧。 码字不易。。。 新人打滚求关注，求点赞。撒花，谢谢各位大佬。 下面是我的私人博客 killCode 阅读效果更好哟]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killTools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索为将 -- Solr 从入门到进阶(一)]]></title>
    <url>%2Fblogs%2F27541.html</url>
    <content type="text"><![CDATA[本文首发于 个人博客 初心阁 一、版本介绍tomcat 9JDK 1.8solr 6.6 二、流程介绍 官网下载 solr 6.6 然后解压到文件夹。 将 server/server-webapp 下的 webapp 复制到 tomcat 的 webapp 包下并改名为 solr 打开 在 tomcat 下的 solr 项目， solr ( webapp 改名后的solr ）/WEB-INF/web.xml 文件，在开头找到类似代码，取消注释并修改，如下 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;D:/Programme/0-Java/J_workspace/solr_home&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt; 注：此处是我的 solrhome 的文件位置 ， 你可以自行设置 将 server/lib 下的 metrics-.jar 包 与 dist 下的 solr-dataimporthandler- .jar 包 复制到你在tomcat / webapp 下的 solr /WEB-INF/ lib 目录中。 将 server/resources 目录下的 log4j.properties 文件 拷贝到 tomcat/webapp/solr/WEB-INF/classes 目录下，没有，就自己新建一个。 自己根据上文 web.xml 中配置的 solr/home 信息，建立 solr_home 文件夹 。并将 server / solr 下的文件全部 拷贝到 solr_home 文件夹下。 在 solr_home 目录下建立一个 文件夹，new_core 作为 你 的solr_core。并将 上图中 configsets / sample_techproducts_configs 目录下的 conf 文件夹 拷贝到 new_core 文件夹下。 配置 lib 标签。 将 solr 6.6 压缩包内的 contrib 与 dist 文件夹 复制到 solr_home 文件夹下。 打开 new_core/conf/solrconfig.xml 文件，从中找到如下代码形式。 1&lt;lib dir=&quot;$&#123;solr.install.dir: 将之更改为如下形式 1234567891011121314&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/contrib/extraction/lib&quot; regex=&quot;.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/dist/&quot; regex=&quot;solr-cell-\d.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/contrib/clustering/lib/&quot; regex=&quot;.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/dist/&quot; regex=&quot;solr-clustering-\d.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/contrib/langid/lib/&quot; regex=&quot;.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/dist/&quot; regex=&quot;solr-langid-\d.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/contrib/ltr/lib/&quot; regex=&quot;.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/dist/&quot; regex=&quot;solr-ltr-\d.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/contrib/velocity/lib&quot; regex=&quot;.*\.jar&quot; /&gt;&lt;lib dir=&quot;$&#123;solr.install.dir:..&#125;/dist/&quot; regex=&quot;solr-velocity-\d.*\.jar&quot; /&gt; 解释一下，这里的根目录是 你自身的 solr_core 目录。对我来说 ，就是 new_core 所在的目录。 所以 12../ == solr_home 目录 成果展示打开http://localhost:8080/solr/index.html 会出现如下画面 三、可能出现的异常根据这位博主的文章http://www.jianshu.com/p/dd7a59b3f0b5 总结如下： 1.启动tomcat时如果报下面的错误： 1234567891011121314151617181920212223严重: Exception starting filter SolrRequestFilterjava.lang.NoClassDefFoundError: com/codahale/metrics/MetricSetat java.lang.Class.getDeclaredConstructors0(Native Method)at java.lang.Class.privateGetDeclaredConstructors(Class.java:2671)at java.lang.Class.getConstructor0(Class.java:3075)at java.lang.Class.newInstance(Class.java:412)at org.apache.catalina.core.DefaultInstanceManager.newInstance(DefaultInstanceManager.java:119)at org.apache.catalina.core.ApplicationFilterConfig.getFilter(ApplicationFilterConfig.java:258)at org.apache.catalina.core.ApplicationFilterConfig.&lt;init&gt;(ApplicationFilterConfig.java:105)at org.apache.catalina.core.StandardContext.filterStart(StandardContext.java:4700)at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5340)at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:145)at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:753)at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:729)at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:717)at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1092)at org.apache.catalina.startup.HostConfig$DeployDirectory.run(HostConfig.java:1834)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.ClassNotFoundException:com.codahale.metrics.MetricSetat org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1333)at org.apache.catalina.loader.WebappClassLoaderBase.loadClass(WebappClassLoaderBase.java:1167)... 20 more 请把solr-6.4.1/server/lib下的metrics-core-3.1.2.jar，metrics-ganglia-3.1.2.jar,metrics-graphite-3.1.2.jar,metrics-jetty9-3.1.2.jar,metrics-jvm-3.1.2.jar这几个jar包放到tomcat下的solr项目的WEB-INF/lib目录下。 2.访问http://localhost:8080/solr/index.html时如果报下面的错误： 1HTTP Status 403 - Access to the requested resource has been denied 把tomcat下的solr项目的web.xml文件中 123456789101112131415&lt;security-constraint&gt; &lt;web-resource-collection&gt; &lt;web-resource-name&gt;Disable TRACE&lt;/web-resource-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;http-method&gt;TRACE&lt;/http-method&gt; &lt;/web-resource-collection&gt; &lt;auth-constraint/&gt;&lt;/security-constraint&gt;&lt;security-constraint&gt; &lt;web-resource-collection&gt; &lt;web-resource-name&gt;Enable everything but TRACE&lt;/web-resource-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;http-method-omission&gt;TRACE&lt;/http-method-omission&gt; &lt;/web-resource-collection&gt;&lt;/security-constraint&gt; 这段注释掉。这段配置限制了对solr资源的访问，注释掉就可以访问了。 3.java.lang.NoSuchMethodError: 解决：solr5.5以上版本在tomcat8下运行由于solr5.5.0和solr5.5.1 版本部署在tomcat7下的时候，会报Java.lang.NoSuchMethodError: javax.servlet.ServletInputStream.isFinished()Z的错误，这个是serverlet3.1才有的方法。 4.javax.servlet.ServletInputStream.isFinished 解决：solr5版本以上的部署最好使用JDK1.8solr5版本以上的部署最好使用JDK1.8，虽然官网没有明确表示solr5必须是要使用JDK1.8，但是其中一部分功能锁需求的JDK版本在JDK1.7以下是没有的比如：Java.lang.NoSuchMethodError: javax.servlet.ServletInputStream.isFinished()Z我是在全量索引的时候发生的此异常提示：找不到ServletInputStream类下面的isFinished()方法，那么现在我们找到该类ServletInputStream如果在这个类下面没有isFinished()方法，那就是JAR包问题，这个类所在的jar包是servlet-api.jar 5.待解决： web.xml 文件中 的 标签失效的原因 。 正常部署后，直接访问 localhost:8080/solr 应该就可以使用，但是，会出现不能加载 UI 的说明。 只有访问 localhost:8080/solr/index.html 才可以正常加载。 分析web.xml 文件，发现一段 servlet 配置12345678&lt;servlet&gt; &lt;servlet-name&gt;LoadAdminUI&lt;/servlet-name&gt; &lt;servlet-class&gt;org.apache.solr.servlet.LoadAdminUiServlet&lt;/servlet-class&gt;&lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;LoadAdminUI&lt;/servlet-name&gt; &lt;url-pattern&gt;/index.html&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 但是，自己太菜，分析不出原因。所以还需要，之后的学习中多注意。 四、与中文分词器的适配1.smart-cn从 solr-6.6.0/contrib/analysis-extras/lucene-libs 下拷贝 lucene-analyzers-smartcn-6.6.0 到 apache-tomcat-9.0.0.M20/webapps/solr/WEB-INF/lib 目录下。 打开 solrhome\new_core\conf 下的managed-scheme 文档 加入以下内容 123&lt;fieldType name=&quot;text_sm&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.apache.lucene.analysis.cn.smart.SmartChineseAnalyzer&quot; /&gt;&lt;/fieldType&gt; 或者可以使用TokenizerFactory12345678&lt;fieldType name=&quot;text_sm&quot; class=&quot;solr.TextField&quot; &gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;org.apache.lucene.analysis.cn.smart.HMMChineseTokenizerFactory&quot;/&gt; &lt;/analyzer&gt;&lt;/fieldType&gt; 2.IKAnalyzer这里有最新适配 solr6.6 的 IKAnalyzer,这里是 适配攻略进入可下载. 下载地址下载后，将IKAnalyzer.jar 包 拷贝到 apache-tomcat-9.0.0.M20/webapps/solr/WEB-INF/lib 目录下 打开 solrhome\new_core\conf 下的managed-scheme 文档 加入以下内容 123&lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer class=&quot;org.wltea.analyzer.lucene.IKAnalyzer&quot; /&gt;&lt;/fieldType&gt; 或者可以使用TokenizerFactory 12345678&lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot;/&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;org.wltea.analyzer.lucene.IKTokenizerFactory&quot;/&gt; &lt;/analyzer&gt;&lt;/fieldType&gt; 成果展示 结语以上就是对 solr 进行的一些简单操作，下一篇文章将会介绍如何将 solr 与 java 、 mysql 数据库结合起来，使用。 喜欢的话可以点一下收藏，与关注哦~，码字不易。谢谢~~~]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逐梦Offer -- 6 个月学习归纳[整合版]]]></title>
    <url>%2Fblogs%2F93.html</url>
    <content type="text"><![CDATA[2. Java 基础2.1 引用强引用软引用 ：即将发生内存溢出时，会对这些对象列进回收范围内，进行第二次回收弱引用 : 只能生存到下一次垃圾收集之前虚引用 ：无法通过虚引用取得一个对象的实例，唯一目的是为了在这个对象被收集器回收时收到 一个系统通知 2.2 重载时的特征签名Java代码层面的特征签名与字节码层面的特征签名不同。 2.3 动态代理JDK ：JDK中的动态代理是通过反射类Proxy以及InvocationHandler回调接口实现的，但是，JDK中所要进行动态代理的类必须要实现一个接口，也就是说只能对该类所实现接口中定义的方法进行代理，这在实际编程中具有一定的局限性，而且使用反射的效率也并不是很高。CGLIB ：使用CGLib实现动态代理，完全不受代理类必须实现接口的限制，而且CGLib底层采用ASM字节码生成框架，使用字节码技术生成代理类，比使用Java反射效率要高。唯一需要注意的是，CGLib不能对声明为final的方法进行代理，因为CGLib原理是动态生成被代理类的子类。 2.4 输入输出流1. NIO与IO的区别一.IO是面向流的，NIO是面向缓冲区的。二.IO的各种流是阻塞的，NIO是非阻塞模式。三.Java NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。 2. 相关类1、FileChannel1FileChannel fc = new FileOutputStream(&quot;data.txt&quot;).getChannel; 2、FileLock1234567// 对整个文件加锁FileLock fl = new FileOutputStream(&quot;data.txt&quot;).getChannel.tryLock();// 对文件的一部分加锁tryLock(long position, long size, boolean shared);lock(long position, long size, boolean shared);// 检查锁的类型FileLock.isShared(); 3、ByteBuffer1234567// 用于写时 OutputStreamfc.write(ByteBuffer.wrap(&quot;somethind&quot;.getBytes()));// 用于读时 InputStreamByteBuffer buff = ByteBuffer.allocate(1024);fc.read(buff);// 用于转化buff.asXxBuffer; 细节 : 四个索引 1，mark 2，position 3, limit 4, capacity;方法：12345678910mark() -- 将mark 设置为 postionposition() -- 返回postion 值position(int pos) -- 设置 。。 limit() -- 返回limit 值limit(int lim) capacity()flip() -- 将limit 设置为 position ，position设置为0，用于准备从缓冲区读取已经写入的数据clear() -- 清空缓冲区，将position 设置为0，limit设置为 capacity ，用于覆写缓冲区。remaining()hasRemaining() 4、 MappedByteBuffer 内存映射文件12MappedByteBuffer out = new RandomAccessFile(&quot;test.dat&quot;,&quot;rw&quot;) .getChannel().map(FileChannel.MapMode.READ_WRITE(模式),0(位置),length(长度)); 2.5 序列化与反序列化 把对象转换为字节序列的过程称为对象的序列化。把字节序列恢复为对象的过程称为对象的反序列化。对象的序列化主要有两种用途：一.把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中；二.在网络上传送对象的字节序列。当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。发送方需要把这个Java对象转换为字节序列，才能在网络上传送；接收方则需要把字节序列再恢复为Java对象。 1、Serializable – &gt; ObjectOutputStream -&gt; writeObject();12ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(Bean.out));out.writeObject(Bean); 2、Serializable – &gt; ObjectInputStream -&gt; readObject();12ObjectInputStream in = new ObjectInputStream(new FileInputStream(Bean.out));Bean bean = in.writeObject(Bean); 3、transient + Serializable == Externalizable xml 解析 的方式 方式 原理 优点 缺点 DOM(Document Object Model) 将结点形成树状结构 方便增删改减 文件过大，内存容易溢出 SAX(Simple API for XML) 基于事件驱动 不会产生内存溢出 不能增删改 开发包： JAXP 与 DOM4J Statement 与 PreparedStatement 之间的区别 preparedStatement 会使用 预编译 ，以及批处理。 statement 不会。所以每次数据库进行查询时，preparedStatement 可以直接使用 sql 语句。 statement 不行。 但是，如果只是使用一次的话， preparedStatement 不会带来性能提升。不如使用 statement 方便。 preparedStatement 可以使用 占位符 ？，然后再赋值，相对于 statement 更为的灵活 preparedStatement 在导入参数的时候，会进行强制性的类型转换。所以在查询，更新的时候，与底层数据库类型一致，不容易出现问题。更为的安全。 api 1234567891011121314Class.forName("com.mysql.jdbc.Driver");Connection conn = (Connection)DriverManager.getConnection("jdbc:mysql://localhost:3306",username,password);PreparedStatement pstmt = conn.prepareStatement(sql);int rows = pstmt.executeUpdate();ResultSet rs = pstmt.executeQuery();// 列数统计int col = rs.getMetaData.getColumnCount();while(rs.next)&#123; for(int i = 1; i&lt;=col;i++)&#123; System.out.println(rs.getString(i)); &#125;&#125; JSP 与 Servlet 3. 多线程线程安全的单例模式 – （DCL）123456789101112131415161718public class Singleton&#123; private volatile static Singleton instance; public static Singleton getInstance()&#123; if(instance == null)&#123; synchronized(Singleton.class)&#123; if(instance == null)&#123; instance == new Singleton(); &#125; &#125; &#125; return instance; &#125; public Singleton()&#123; Singleton.getInstance(); &#125;&#125; 线程池 newFixedThreadPool 固定长度的线程池 newCachedThreadPool 可缓存的线程池 规模不受限制 newSingleThreadExecutor 单个工作者线程来执行任务 newScheduledThreadPool 固定长度的线程池，并且以延迟或定时的方式来执行。 基础框架 Semaphore 信号量 acquire() release() CountDownLatch 闭锁 // 等待事件的完成 await() countDown() CyclicBarrier 栅栏 // 等待线程的到达 Exchanger 两方栅栏 exchanger() FutureTask new Thread(ft); – runnable ft.get(); – future Fork-Join框架 原子性、可见性与有序性 原子性 read 、write assign 、store load 、use lock unlock – &gt; monitorenter 、 monitorexit2 . 可见性 volatile synchronized final 有序性 volatile(内存屏障) synchronized 必须 load &lt; – &gt; use assign &lt; – &gt; store 先行发生原则（happens - before) 程序次序原则 线程启动、终止、中断原则 volatlie 变量原则 write –&gt; read 管程锁原则 对象终结原则 传递性 a-&gt;b b-&gt;c –&gt; a-&gt;c 偏向锁、轻量级锁、重量级锁偏向所锁，轻量级锁都是乐观锁，重量级锁是悲观锁。 一个对象刚开始实例化的时候，没有任何线程来访问它的时候。它是可偏向的，意味着，它现在认为只可能有一个线程来访问它，所以当第一个线程来访问它的时候，它会偏向这个线程，此时，对象持有偏向锁。偏向第一个线程，这个线程在修改对象头成为偏向锁的时候使用CAS操作，并将对象头中的ThreadID改成自己的ID，之后再次访问这个对象时，只需要对比ID，不需要再使用CAS在进行操作。 一旦有第二个线程访问这个对象，因为偏向锁不会主动释放，所以第二个线程可以看到对象时偏向状态，这时表明在这个对象上已经存在竞争了，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程，如果原来的线程依然存活，则马上执行那个线程的操作栈，检查该对象的使用情况，如果仍然需要持有偏向锁，则偏向锁升级为轻量级锁，（偏向锁就是这个时候升级为轻量级锁的）。如果不存在使用了，则可以将对象回复成无锁状态，然后重新偏向。 轻量级锁认为竞争存在，但是竞争的程度很轻，一般两个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。 但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。 偏向锁偏向锁标志位 01同时用CAS 操作将获取到这个锁的线程ID 记录到对象的 Mark Word 中。以后每次这个线程进入这个锁相关的同步块时，都不需要任何同步操作。 轻量级锁轻量级锁 00如果此同步对象没有被锁定(锁标志位 为“01”)在当前线程中栈帧中建立锁记录(Lock Record) 的空间，存储锁对象的 Mark Word 拷贝（官方把这份拷贝加了一个 Dispaced 前缀）.CAS 操作尝试将 对象的 Mark Word 更新为指向 Lock Record 的指针。 并将标志位 转变为 “00” 5. 框架5.1 SSH 与 SSMspring 的架构spring bean1、 加载过程2、 实例化3、 注入方式 spring 中的 IOC 与 AOPspring 事务1、事务事务:是逻辑上一组操作，要么全都成功，要么全都失败.事务特性:ACID: 原子性(Atomic):事务不可分割 一致性(Consistency):事务执行的前后，数据完整性保持一致. 隔离性(Isolation):一个事务执行的时候，不应该受到其他事务的打扰 持久性(Durability):一旦结束，数据就永久的保存到数据库. 如果不考虑隔离性: 脏读:一个事务读到另一个事务未提交数据 不可重复读:一个事务只能看到已经提交事务做出的修改。所以当另一个事务更新数据（update），导致一个事务多次查询结果不一致 幻读:当一个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入新的记录（insert），导致一个事务多次查询结果不一致 事务的隔离级别: 未提交读:以上情况都有可能发生。 已提交读:避免脏读，但不可重复读，幻读是有可能发生。 可重复读:避免脏读，不可重复读，但是幻读有可能发生。 串行的:避免以上所有情况. Spring 中的代码解析：1234PlatformTransactionManager:平台事务管理器.commit(TransactionStatus status) getTransaction(TransactionDefinition definition) rollback(TransactionStatus status) TransactionDefinition:事务定义1234567891011121314ISOLation_XXX:事务隔离级别.ISOLATION_DEFAULT:默认级别. -- Mysql repeatable_read ISOLATION_READ_UNCOMMITTEDISOLATION_READ_COMMITTED ISOLATION_REPEATABLE_READ ISOLATION_SERIALIZABLE PROPAGATION_XXX:事务的传播行为.(不是JDBC中有的，为了解决实际开发问题.)过期时间:TransactionStatus:事务状态是否有保存点是否一个新的事务事务是否已经提交 关系:PlatformTransactionManager通过TransactionDefinition设置事务相关信息管理事务，管理事务过程中，产生一些事务状态:状态由TransactionStatus记录. 2、事务的传播行为:(不是JDBC事务管理，用来解决实际开发的问题.)传播行为：解决业务层之间的调用的事务的关系. PROPAGATION_REQUIRED :支持当前事务，如果不存在 就新建一个 A,B 如果A有事务，B使用A的事务，如果A没有事务，B就开启一个新的事务.(A,B是在一个事务中。) PROPAGATION_SUPPORTS :支持当前事务，如果不存在，就不使用事务 A,B 如果A有事务，B使用A的事务，如果A没有事务，B就不使用事务. PROPAGATION_MANDATORY :支持当前事务，如果不存在，抛出异常 A,B 如果A有事务，B使用A的事务，如果A没有事务，抛出异常. PROPAGATION_REQUIRES_NEW 如果有事务存在，挂起当前事务，创建一个新的事务 A,B 如果A有事务，B将A的事务挂起，重新创建一个新的事务.(A,B不在一个事务中.事务互不影响.) PROPAGATION_NESTED 如果当前事务存在，则嵌套事务执行 基于SavePoint技术.A,B A有事务，A执行之后，将A事务执行之后的内容保存到SavePoint.B事务有异常的话，用户需要自己设置事务提交还是回滚. PROPAGATION_NOT_SUPPORTED 以非事务方式运行，如果有事务存在，挂起当前事务 A,B 非事务的方式运行，A有事务，就会挂起当前的事务. PROPAGATION_NEVER 以非事务方式运行，如果有事务存在，抛出异常 SpringMVC 与 Struts2 的原理SpringMVC 与 Struts2 区别1、 Struts2是类级别的拦截， 一个类对应一个request上下文， SpringMVC是方法级别的拦截，一个方法对应一个request上下文，而方法同时又跟一个url对应, 所以说从架构本身上SpringMVC就容易实现restful url, 而struts2的架构实现起来要费劲，因为Struts2中Action的一个方法可以对应一个url，而其类内的属性被所有方法共享，这也就无法用注解或其他方式标识其所属方法了。 举例： 12345678910// springmvc@requestMapping(&quot;/test/&#123;id&#125;&quot;)public String springmvcTest(@pathVariable(&quot;id&quot;) int id);// struts2public class strutsToTest&#123; int id; public String test01(int id); public String test02(int id);&#125; 可以看到 struts2 的 id 属性是被所有的方法共享的，这样就不能将 id 标识为单独的restful url 的值。2、 由上边原因，SpringMVC的方法之间基本上独立的，独享request response数据，请求数据通过参数获取，处理结果通过ModelMap交回给框架，方法之间不共享变量， 而Struts2搞的就比较乱，虽然方法之间也是独立的，但其所有Action变量是共享的，这不会影响程序运行，却给我们编码 读程序时带来麻烦，每次来了请求就创建一个Action，一个Action对象对应一个request上下文。3、 由于Struts2需要针对每个request进行封装，把request，session等servlet生命周期的变量封装成一个一个Map，供给每个Action使用，并保证线程安全，所以在原则上，是比较耗费内存的。4、 拦截器实现机制上，Struts2有以自己的interceptor机制， SpringMVC用的是独立的AOP方式，这样导致Struts2的配置文件量还是比SpringMVC大。5、 SpringMVC的入口是servlet，而Struts2是filter（这里要指出，filter和servlet是不同的。以前认为filter是servlet的一种特殊），这就导致了二者的机制不同，这里就牵涉到servlet和filter的区别了。6、 SpringMVC集成了Ajax，使用非常方便，只需一个注解@ResponseBody就可以实现，然后直接返回响应文本即可， 而Struts2拦截器集成了Ajax，在Action中处理时一般必须安装插件或者自己写代码集成进去，使用起来也相对不方便。7、 SpringMVC验证支持JSR303，处理起来相对更加灵活方便，这里介绍一下。springmvc使用的是Hibernate Validator（和Hibernate的ORM）进行校验。 通过 在 HandlerAdapter 中加入 自定义绑定 WebBinder (在 自动注解下前面都可以省略) -&gt; 校验器 validator -&gt; 校验文件 messageSource 的设置。 可以使用 相关的注解 而Struts2是通过自己的inteceptor (name = “params” .. “validation”) 提供。 有一套完备的 validator 供开发者使用。8、SpringMVC开发效率和性能高于Struts2。 6. 数据库基础知识范式mysqlmysql的逻辑架构mysql的事务1、事务事务:是逻辑上一组操作，要么全都成功，要么全都失败.事务特性:ACID: 原子性(Atomic):事务不可分割 一致性(Consistency):事务执行的前后，数据完整性保持一致. 隔离性(Isolation):一个事务执行的时候，不应该受到其他事务的打扰 持久性(Durability):一旦结束，数据就永久的保存到数据库. 如果不考虑隔离性: 事务的隔离级别: 未提交读:以上情况都有可能发生。 脏读:一个事务读到另一个事务未提交数据 已提交读:避免脏读，但不可重复读，幻读是有可能发生。 不可重复读:一个事务只能看到已经提交事务做出的修改。所以当另一个事务更新数据（update），导致一个事务多次查询结果不一致 可重复读:避免脏读，不可重复读，但是幻读有可能发生。 幻读:当一个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入新的记录（insert），导致一个事务多次查询结果不一致 不过 mysql 中存在 多版本并发控制 (MVCC ，Multiversion Concurrency Control) ： 在每行记录的后面 保存两个隐藏的列 1、创建时间 2、过期时间 （实际为当前系统的版本号，每开启一个新的事务，版本号就会递增）。 SELECT INSERT DELETE UPDATE只在 REPEATABLE_READ 与 READ_CONMMITED 两个隔离级别下工作。 串行的:避免以上所有情况 mysql的主从复制redis 7. 服务器nginx8. 函数式编程递归优化 ： 尾递优化最后一步是纯净的函数式。 1234567891011// 递归式static long factorialRecursive(long n)&#123; return n==1 ? 1 : n*factorialRecursive(n-1);&#125;// 纯净的函数式static long factorialTailRecursive(long n)&#123; return factorialHelper(1,n);static long factorialHelper(long acc, long n)&#123; return n==1?acc:factorialHelper(acc*n,n-1);&#125;&#125;]]></content>
      <categories>
        <category>Interview</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>interview</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机基础]]></title>
    <url>%2Fblogs%2Fc783f2ce.html</url>
    <content type="text"><![CDATA[0. 计算机基础0.1 深入理解计算机系统寄存器 ： CPU 中有 16 个存储 64位值的 通用目的寄存器。 嵌套32位 ， 16位 ， 8位。%rax 返回值 %rsp 指针 %rcx %rdx %rsi %rdi 第四、三、二、一个参数。操作数 ： 立即数，寄存器，内存引用 。寻址模式 ：Imm(rb,ri,s) Imm 立即数偏移，rb基址寄存器，ri变址寄存器，s比例因子.条件码 ：CF,XF,SF,OF 通过组合确定算术或逻辑操作。对抗缓冲区溢出攻击： 1. 栈随机化：程序开始前，插入一段随机大小的空间 2. 栈破坏检测：随机在栈帧中插入值，每次恢复状态和返回函数前检测 3. 限制可执行代码区域：通过 读、写、执行 权限执行。 处理器体系结构ALU : 算术与逻辑单元指令 ： 整数操作，跳转，条件传送，call指令返回地址，入栈出栈，指令停止。顺序 ： 取指，译码，执行，访存，写回，更新PC。流水线 ： 数据冒险：暂停、转发、加载/使用冒险 3.2现代处理器ICU(instruction controll unit) 指令控制单元：EU(executable unit) 执行单元: 分支，算术运算，加载，存储 – &gt; 数据高速缓存 存储器层次结构SRAM（static random access memory) 静态随机访问存储器 – 高速缓存 L1 , L2 ,L3DRAM : DDR(Double Data-Rate Synchronous DRAM ) 双倍速率同步 RAM – 主存存储速度 ： SRAM &gt; DRAM ROM (Read-Only Memory) 只读存储器EPROM –&gt; 闪存(flash memory) –&gt; SSD (solid state disk) 磁盘 - 容量: 记录密度，磁道密度，面密度（前两者的乘积）。 - 访问时间：寻道（传送臂定位磁道），旋转（读/写头定位扇区），传送（读/写头 读写内容)。 - 逻辑块号: 盘面，磁道，扇区 - 主机总线适配器 - DMA (Direct memory access) 直接内存访问： 通过磁盘控制器，将逻辑块号翻译成 扇区地址传给 主存。 - 局部性:时间局部性(同一个内存位置在一段时间内多次使用) 、 空间局部性(内存使用是 相近的) 缓存 虚拟内存MMU ： 链接静态链接：符号解析与重定位可重定位目标文件：与静态链接库（archive 存档文件），在符号解析阶段一同解析，然后将重定位节和符号定义，与节中的符号引用，最终组成可执行目标文件。可执行目标文件：加载阶段，与动态链接库的共享目标文件一起，动态加载。共享目标文件：共享库 DLL(dynaic linker library) 0.2 linux 知识 时间、FHS type(判断) \info\man shutdown\reboot\halt\poweroff date\hwclock cd\mkdir\pwd\rm\rmdir cp\mv history echo 用户 alias file/cat/head useradd，userdel passwd，gpasswd usermod,chsh,chfn groupadd,groupmod 文件 chown(修改文件的属主与属组) chmod(修改文件的权限) 系统 ps -aux|grep .. systemctl nmgui]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索为将 -- IKAnalyzer中文搜词器]]></title>
    <url>%2Fblogs%2F47564.html</url>
    <content type="text"><![CDATA[前言在中文分词器中， IKAnalyzer 做的是相对不错的，有着细度分割和智能使用两个模式 。但是，这个版本因为太陈旧，作者不再维护，（项目估计是。。。），所以与现在的Lucene 6.6 版本差距有些大。所以，我就根据网上各位大神的文章，加上自己对 API 与源码的阅读，稍微的进行了改动，可以简单的运行。注： 这里的简单是指，可以简单的运行源码 中的简单案例。 正文项目介绍 IKAnaylzer版本： IK Analyzer 2012FF感谢提供的分词源码 http://git.oschina.net/wltea/IK-Analyzer-2012FF lucene 版本：lucene 6.60 代码改动1. 对IKTokenizer的改动源码123456789101112/** * Lucene 4.0 Tokenizer适配器类构造函数 * @param in * @param useSmart */public IKTokenizer(Reader in, boolean useSmart) &#123; super(in); offsetAtt = addAttribute(OffsetAttribute.class); termAtt = addAttribute(CharTermAttribute.class); typeAtt = addAttribute(TypeAttribute.class); _IKImplement = new IKSegmenter(input, useSmart);&#125; 经查阅 lucene 源码Tokenizer类的构造器已经不再接收 Reader 源码如下12345678910protected Tokenizer() &#123; this.input = ILLEGAL_STATE_READER; this.inputPending = ILLEGAL_STATE_READER;&#125;protected Tokenizer(AttributeFactory factory) &#123; super(factory); this.input = ILLEGAL_STATE_READER; this.inputPending = ILLEGAL_STATE_READER;&#125; 因此改动 IKTokenizer 类 ，如下123456789public IKTokenizer( boolean useSmart) &#123; super(); offsetAtt = addAttribute(OffsetAttribute.class); termAtt = addAttribute(CharTermAttribute.class); typeAtt = addAttribute(TypeAttribute.class); //传入 IKSegmenter 的 input Reader 流，会被 父类 Tokenizer 类的无参构造器 //初始化为 this.input = ILLEGAL_STATE_READER; _IKImplement = new IKSegmenter(input, useSmart);&#125; 去除了 Reader 形参 。 默认调用 父类 的 无参构造函数 Tokenizer()注：在该博客下发现，还需要配置分词器工厂类，因此还要多增加一段构造器代码，如下12345678//方便创建 工厂类public IKTokenizer(AttributeFactory factory, boolean useSmart) &#123; super(factory); offsetAtt = addAttribute(OffsetAttribute.class); termAtt = addAttribute(CharTermAttribute.class); typeAtt = addAttribute(TypeAttribute.class); _IKImplement = new IKSegmenter(input, useSmart);&#125; 2. 对IKAnalyzer 的改动源码12345678/** * 重载Analyzer接口，构造分词组件 */@Overrideprotected TokenStreamComponents createComponents(String fieldName, final Reader in) &#123; Tokenizer _IKTokenizer = new IKTokenizer(in, this.useSmart()); return new TokenStreamComponents(_IKTokenizer);&#125; lucene 6.6 关于 Analyzer 接口中 关于 createComponents() 方法的源码1protected abstract Analyzer.TokenStreamComponents createComponents(String var1); 结合上文中对 IKTokenizer 源码的改动，因此需要去除 参数 Reader in改动的代码 如下：12345678/** * 重载Analyzer接口，构造分词组件 */@Overrideprotected TokenStreamComponents createComponents(String fieldName) &#123; Tokenizer _IKTokenizer = new IKTokenizer(this.useSmart()); return new Analyzer.TokenStreamComponents(_IKTokenizer);&#125; 3. 对SWMCQueryBuilder 的改动源码如下：12345// 借助lucene queryparser 生成SWMC QueryQueryParser qp = new QueryParser(Version.LUCENE_43, fieldName, new StandardAnalyzer( Version.LUCENE_43));qp.setDefaultOperator(QueryParser.AND_OPERATOR);qp.setAutoGeneratePhraseQueries(true); 由于新版本的 lucene 已经不在使用 Version 类 进行定义，（我的上一篇lucene6.6 学习心得说的很清楚）因此需要将之移除。移除后，改动版本如下：1234//借助lucene queryparser 生成SWMC QueryQueryParser qp = new QueryParser(fieldName, new StandardAnalyzer());qp.setDefaultOperator(QueryParser.AND_OPERATOR);qp.setAutoGeneratePhraseQueries(true); 4. 对IKQueryExpressionParser 的改动IKQueryExpressionParser 类中方法 BooleanQuery ，在近期的 lucene 中有了较大改动，不知道的话，可以 查阅我的上一篇文章lucene6.6 学习心得.因此源码中对 IKQueryExpressionParser 类中关于 BooleanQuery 的方法都需要进行更改。因为方法中代码过多 ， 因此，我选取其中比较关键的几个地方，进行展示。关键源码如下：12345678private Query toBooleanQuery(Element op) &#123;BooleanQuery resultQuery = new BooleanQuery();Query q2 = this.querys.pop();Query q1 = this.querys.pop();BooleanClause[] clauses = ((BooleanQuery) q1).getClauses();resultQuery.add(c);return resultQuery;&#125; 改动代码如下：1.数组版本 1234567891011121314151617181920private Query toBooleanQuery(Element op)&#123;BooleanQuery.Builder builder = new BooleanQuery.Builder();Query q2 = this.querys.pop(); Query q1 = this.querys.pop(); //因为，我看源码，并没有发现会增删的地方 ，于是直接转成了数组 //迭代器版本的在下文if(q1 instanceof BooleanQuery)&#123; BooleanClause[] clauses =(BooleanClause[]) ((BooleanQuery)q1).clauses().toArray(); if(clauses.length &gt; 0 &amp;&amp; clauses[0].getOccur() == Occur.MUST)&#123; for(BooleanClause c : clauses)&#123; builder.add(c); &#125; &#125;else&#123; builder.add(q1,Occur.MUST); &#125; return builder.build();&#125; 2.迭代器版本 12345678910111213141516171819private Query toBooleanQuery(Element op)&#123;BooleanQuery.Builder builder = new BooleanQuery.Builder();Query q2 = this.querys.pop(); Query q1 = this.querys.pop();if(q1 instanceof BooleanQuery)&#123; Iterator&lt;BooleanClause&gt; clauses = ((BooleanQuery) q1).iterator(); while (clauses.hasNext()) &#123; BooleanClause clause = clauses.next(); if (clause.getOccur() == Occur.MUST) &#123; builder.add(clause); &#125; else &#123; builder.add(q1,Occur.MUST); &#125;&#125; return builder.build();&#125; 5. 项目运行打开包中的测试代码1.IKAnalzyerDemo运行结果如下图 2.LuceneIndexAndSearchDemo运行结果如下图 6. 源码与整合包的下载源码与整合包 已经上传至我的 GitHub 上，有兴趣的可以去那里下载，不嫌弃的话，Star 一下 ，也是可以的哦~]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis逆向工程]]></title>
    <url>%2Fblogs%2F51669.html</url>
    <content type="text"><![CDATA[前言为了方便使用 Mybatis 的开发，我在做一个项目的时候，在网上查阅资料，发现了这个神奇的工具，逆向工程，可以很快速的将一些基本的东西格式化的拷贝出来，很方便。所以，特意，整理出来，让大家一起看看。 pom 文件12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;sqlGenerator&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.5&lt;/version&gt; &lt;configuration&gt; &lt;!-- 文件位置 --&gt; &lt;configurationFile&gt;$&#123;basedir&#125;/src/main/resources/generator/generatorConfig.xml&lt;/configurationFile&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;overwrite&gt;true&lt;/overwrite&gt; &lt;/configuration&gt; &lt;!-- 单独配置依赖 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.21&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; generatorConfig.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt;&lt;generatorConfiguration&gt; &lt;!-- targetRuntime是一个很重要的选项，与下文生成 example 有关 --&gt; &lt;context id=&quot;testTables&quot; targetRuntime=&quot;MyBatis3&quot;&gt; &lt;commentGenerator&gt; &lt;!-- 是否去除自动生成的注释 true：是 ： false:否 --&gt; &lt;property name=&quot;suppressAllComments&quot; value=&quot;false&quot; /&gt; &lt;/commentGenerator&gt; &lt;!--数据库连接的信息：驱动类、连接地址、用户名、密码 --&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://localhost:3306/test&quot; userId=&quot;root&quot; password=&quot;1996915&quot;&gt; &lt;/jdbcConnection&gt; &lt;!-- 默认false，把JDBC DECIMAL 和 NUMERIC 类型解析为 Integer，为 true时把JDBC DECIMAL 和 NUMERIC 类型解析为java.math.BigDecimal --&gt; &lt;javaTypeResolver&gt; &lt;property name=&quot;forceBigDecimals&quot; value=&quot;false&quot; /&gt; &lt;/javaTypeResolver&gt; &lt;!-- targetProject:生成PO类的位置 --&gt; &lt;javaModelGenerator targetPackage=&quot;com.killcode.pojo&quot; targetProject=&quot;.\src&quot;&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;!-- 从数据库返回的值被清理前后的空格 --&gt; &lt;property name=&quot;trimStrings&quot; value=&quot;true&quot; /&gt; &lt;/javaModelGenerator&gt; &lt;!-- targetProject:mapper映射文件生成的位置 --&gt; &lt;sqlMapGenerator targetPackage=&quot;com.killcode.mapper&quot; targetProject=&quot;.\src&quot;&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;/sqlMapGenerator&gt; &lt;!-- targetPackage：mapper接口生成的位置 --&gt; &lt;javaClientGenerator type=&quot;XMLMAPPER&quot; targetPackage=&quot;com.killcode.mapper&quot; targetProject=&quot;.\src&quot;&gt; &lt;!-- enableSubPackages:是否让schema作为包的后缀 --&gt; &lt;property name=&quot;enableSubPackages&quot; value=&quot;false&quot; /&gt; &lt;/javaClientGenerator&gt; &lt;!-- 指定数据库表 --&gt; &lt;table schema=&quot;&quot; tableName=&quot;one&quot;&gt;&lt;/table&gt; &lt;!-- 有些表的字段需要指定java类型 &lt;table schema=&quot;&quot; tableName=&quot;&quot;&gt; &lt;columnOverride column=&quot;&quot; javaType=&quot;&quot; /&gt; &lt;/table&gt; --&gt; &lt;/context&gt;&lt;/generatorConfiguration&gt; 结果展示]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killJava</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[killBase系列 -- C/S 与 B/S 架构的区别]]></title>
    <url>%2Fblogs%2F3153.html</url>
    <content type="text"><![CDATA[一、C/S 架构1、 概念C/S 架构是一种典型的两层架构，其全程是Client/Server，即客户端服务器端架构，其客户端包含一个或多个在用户的电脑上运行的程序，而服务器端有两种，一种是数据库服务器端，客户端通过数据库连接访问服务器端的数据；另一种是Socket服务器端，服务器端的程序通过Socket与客户端的程序通信。C/S 架构也可以看做是胖客户端架构。因为客户端需要实现绝大多数的业务逻辑和界面展示。这种架构中，作为客户端的部分需要承受很大的压力，因为显示逻辑和事务处理都包含在其中，通过与数据库的交互（通常是SQL或存储过程的实现）来达到持久化数据，以此满足实际项目的需要。2 、优点和缺点优点：2.1 C/S架构的界面和操作可以很丰富。2.2 安全性能可以很容易保证，实现多层认证也不难。2.3 由于只有一层交互，因此响应速度较快。缺点：2.4 适用面窄，通常用于局域网中。2.5 用户群固定。由于程序需要安装才可使用，因此不适合面向一些不可知的用户。2.6 维护成本高，发生一次升级，则所有客户端的程序都需要改变。 二、B/S架构1、概念B/S架构的全称为Browser/Server，即浏览器/服务器结构。Browser指的是Web浏览器，极少数事务逻辑在前端实现，但主要事务逻辑在服务器端实现，Browser客户端，WebApp服务器端和DB端构成所谓的三层架构。B/S架构的系统无须特别安装，只有Web浏览器即可。B/S架构中，显示逻辑交给了Web浏览器，事务处理逻辑在放在了WebApp上，这样就避免了庞大的胖客户端，减少了客户端的压力。因为客户端包含的逻辑很少，因此也被成为瘦客户端。2 、优点和缺点优点：1）客户端无需安装，有Web浏览器即可。2）BS架构可以直接放在广域网上，通过一定的权限控制实现多客户访问的目的，交互性较强。3）BS架构无需升级多个客户端，升级服务器即可。缺点：1）在跨浏览器上，BS架构不尽如人意。2）表现要达到CS程序的程度需要花费不少精力。3）在速度和安全性上需要花费巨大的设计成本，这是BS架构的最大问题。4）客户端服务器端的交互是请求-响应模式，通常需要刷新页面，这并不是客户乐意看到的。（在Ajax风行后此问题得到了一定程度的缓解） 三、B/S对C/S的改进和扩展正如前文所说，C/S和B/S都可以进行同样的业务处理，但是B/S随着Internet技术的兴起，是对C/S结构的一种改进或者扩展的结构。相对于C/S，B/S具有如下优势：1、分布性：可以随时进行查询、浏览等业务2、业务扩展方便：增加网页即可增加服务器功能3、维护简单方便：改变网页，即可实现所有用户同步更新4、开发简单，共享性强，成本低，数据可以持久存储在云端而不必担心数据的丢失。]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>killBase</tag>
      </tags>
  </entry>
</search>
